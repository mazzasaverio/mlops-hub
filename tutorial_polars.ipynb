{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Series are a 1-dimensional data structure. Within a series all elements have the same Data Type .\n",
    "s = pl.Series(\"a\", [1, 2, 3, 4, 5])\n",
    "\n",
    "# A DataFrame is a 2-dimensional data structure that is backed by a Series,\n",
    "# and it can be seen as an abstraction of a collection (e.g. list) of Series. Operations\n",
    "# that can be executed on a DataFrame are very similar to what is done in a SQL like query.\n",
    "# You can GROUP BY, JOIN, PIVOT, but also define custom functions.\n",
    "\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"integer\": [1, 2, 3, 4, 5],\n",
    "        \"date\": [\n",
    "            datetime(2022, 1, 1),\n",
    "            datetime(2022, 1, 2),\n",
    "            datetime(2022, 1, 3),\n",
    "            datetime(2022, 1, 4),\n",
    "            datetime(2022, 1, 5),\n",
    "        ],\n",
    "        \"float\": [4.0, 5.0, 6.0, 7.0, 8.0],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Polars has developed its own Domain Specific Language (DSL) for transforming data.\n",
    "# The language is very easy to use and allows for complex queries that remain human\n",
    "# readable. The two core components of the language are Contexts and Expressions,\n",
    "# the latter we will cover in the next section.\n",
    "\n",
    "# A context, as implied by the name, refers to the context in which an expression needs\n",
    "# to be evaluated. There are three main contexts 1:\n",
    "\n",
    "# Selection: df.select([..]), df.with_columns([..])\n",
    "# Filtering: df.filter()\n",
    "# Group by / Aggregation: df.group_by(..).agg([..])\n",
    "# The examples below are performed on the following DataFrame:\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"nrs\": [1, 2, 3, None, 5],\n",
    "        \"names\": [\"foo\", \"ham\", \"spam\", \"egg\", None],\n",
    "        \"random\": np.random.rand(5),\n",
    "        \"groups\": [\"A\", \"A\", \"B\", \"C\", \"B\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Select\n",
    "# In the select context the selection applies expressions over columns.\n",
    "# The expressions in this context must produce Series that are all the same length or have a length of 1.\n",
    "\n",
    "# A Series of a length of 1 will be broadcasted to match the height of the DataFrame.\n",
    "# Note that a select may produce new columns that are aggregations, combinations of expressions, or literals.\n",
    "\n",
    "out = df.select(\n",
    "    pl.sum(\"nrs\"),\n",
    "    pl.col(\"names\").sort(),\n",
    "    pl.col(\"names\").first().alias(\"first name\"),\n",
    "    (pl.mean(\"nrs\") * 10).alias(\"10xnrs\"),\n",
    ")\n",
    "\n",
    "# As you can see from the query the select context is very powerful and allows\n",
    "# you to perform arbitrary expressions independent (and in parallel) of each other.\n",
    "\n",
    "# Similarly to the select statement there is the with_columns statement which also\n",
    "# is an entrance to the selection context. The main difference is that with_columns retains\n",
    "# the original columns and adds new ones while select drops the original columns.\n",
    "df = df.with_columns(\n",
    "    pl.sum(\"nrs\").alias(\"nrs_sum\"),\n",
    "    pl.col(\"random\").count().alias(\"count\"),\n",
    ")\n",
    "# Filter\n",
    "# In the filter context you filter the existing dataframe based on arbitrary expression which evaluates to the Boolean data type.\n",
    "\n",
    "out = df.filter(pl.col(\"nrs\") > 2)\n",
    "\n",
    "# Group by / aggregation\n",
    "# In the group_by context, expressions work on groups and thus may yield results of any length (a group may have many members).\n",
    "\n",
    "\n",
    "out = df.group_by(\"groups\").agg(\n",
    "    pl.sum(\"nrs\"),  # sum nrs by groups\n",
    "    pl.col(\"random\").count().alias(\"count\"),  # count group members\n",
    "    # sum random where name != null\n",
    "    pl.col(\"random\").filter(pl.col(\"names\").is_not_null()).sum().name.suffix(\"_sum\"),\n",
    "    pl.col(\"names\").reverse().alias(\"reversed names\"),\n",
    ")\n",
    "\n",
    "# As you can see from the result all expressions are applied to the group defined by the group_by context.\n",
    "# Besides the standard group_by, group_by_dynamic, and group_by_rolling are also entrances to the group by context.\n",
    "\n",
    "\n",
    "# Expressions\n",
    "# Polars has a powerful concept called expressions that is central to its very fast performance.\n",
    "\n",
    "# Expressions are at the core of many data science operations:\n",
    "\n",
    "# taking a sample of rows from a column\n",
    "# multiplying values in a column\n",
    "# extracting a column of years from dates\n",
    "# convert a column of strings to lowercase\n",
    "# and so on!\n",
    "\n",
    "\n",
    "# However, expressions are also used within other operations:\n",
    "\n",
    "# taking the mean of a group in a group_by operation\n",
    "# calculating the size of groups in a group_by operation\n",
    "# taking the sum horizontally across columns\n",
    "# Polars performs these core data transformations very quickly by:\n",
    "\n",
    "# automatic query optimization on each expression\n",
    "# automatic parallelization of expressions on many columns\n",
    "# Polars expressions are a mapping from a series to a series\n",
    "# (or mathematically Fn(Series) -> Series). As expressions have a Series as an input\n",
    "# and a Series as an output then it is straightforward to do a sequence of\n",
    "# expressions (similar to method chaining in Pandas).\n",
    "\n",
    "# Examples\n",
    "# The following is an expression:\n",
    "\n",
    "pl.col(\"foo\").sort().head(2)\n",
    "\n",
    "# The snippet above says:\n",
    "\n",
    "# Select column \"foo\"\n",
    "# Then sort the column (not in reversed order)\n",
    "# Then take the first two values of the sorted output\n",
    "# The power of expressions is that every expression produces\n",
    "# a new expression, and that they can be piped together. You can run an\n",
    "# expression by passing them to one of Polars execution contexts.\n",
    "\n",
    "# Here we run two expressions by running df.select:\n",
    "\n",
    "df.select(pl.col(\"foo\").sort().head(2), pl.col(\"bar\").filter(pl.col(\"foo\") == 1).sum())\n",
    "\n",
    "# All expressions are run in parallel, meaning that separate Polars expressions are embarrassingly parallel.\n",
    "# Note that within an expression there may be more parallelization going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
