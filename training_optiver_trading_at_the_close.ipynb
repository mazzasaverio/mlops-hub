{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Kaggle package is already installed.\n",
      "Directory /home/sam/github/mlops-hub/data/kaggle_optiver_trading_at_the_close already exists.\n",
      "File XTrIntCmpNewFtre.parquet already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "# Built-in modules\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# External general-purpose modules\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "\n",
    "# Logging and optimization modules\n",
    "from loguru import logger\n",
    "import mlflow\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "\n",
    "# Machine learning and model validation modules\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import log_evaluation, early_stopping, LGBMRegressor as LGBMR\n",
    "\n",
    "# Custom modules\n",
    "from src.utils.utils_kaggle import get_data\n",
    "from src.utils.utils_general import get_project_directory, load_config\n",
    "from src.experiments.mlflow_optuna_init import initialize_mlflow, initialize_optuna\n",
    "from src.validation.cv_setup import initialize_cv_method\n",
    "from src.experiments.optuna_objective import objective\n",
    "from src.validation.model_validation import CombPurgedKFoldCV\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Auto-reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get project directory and load configuration\n",
    "path_project_directory = get_project_directory()\n",
    "config_path = os.path.join(path_project_directory, \"config/train_config.yaml\")\n",
    "config = load_config(config_path)\n",
    "\n",
    "# Define paths\n",
    "dataset_path = os.path.join(path_project_directory, \"data/processed/synthetic_ticker_data.csv\")\n",
    "path_experiments_storage = os.path.join(path_project_directory, \"data/experiments_storage\")\n",
    "\n",
    "# Kaggle dataset parameters\n",
    "kaggle_json_path = os.path.join(path_project_directory, \"kaggle.json\")\n",
    "\n",
    "dest_folder = os.path.join(path_project_directory, \"data/kaggle_optiver_trading_at_the_close\")\n",
    "dataset_name = \"ravi20076/optiver-memoryreduceddatasets\"\n",
    "specific_file = \"XTrIntCmpNewFtre.parquet\"\n",
    "\n",
    "# Download data from Kaggle\n",
    "get_data(kaggle_json_path, dest_folder, dataset_name=dataset_name, specific_file=specific_file)\n",
    "\n",
    "# Initialize MLFlow and Optuna\n",
    "initialize_mlflow(path_experiments_storage, config)\n",
    "study = initialize_optuna(path_experiments_storage, config)\n",
    "\n",
    "# Configure Optuna logging\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Configure Loguru\n",
    "logger.add(\"objective_logs.log\", format=\"{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}\")\n",
    "\n",
    "# Initialize MLflow callback\n",
    "mlflow_callback = MLflowCallback(tracking_uri=mlflow.get_tracking_uri(), metric_name=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sam/github/mlops-hub/../kaggle.json'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sam/github/mlops-hub'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(path_project_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/miniconda3/envs/training/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2023-10-21 11:03:39,712] Using an existing study with name 'Default_Study_Name' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/sam/.kaggle/kaggle.json'\n",
      "Kaggle package is already installed.\n",
      "Directory /home/sam/github/mlops-hub/data/kaggle_optiver_trading_at_the_close already exists.\n",
      "File XTrIntCmpNewFtre.parquet already exists. Skipping download.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_148752/2375695542.py:69: ExperimentalWarning: MLflowCallback is experimental (supported from v1.4.0). The interface can change in the future.\n",
      "  mlflow_callback = MLflowCallback(tracking_uri=mlflow.get_tracking_uri(), metric_name=\"mae\")\n"
     ]
    }
   ],
   "source": [
    "# Constants and Settings\n",
    "debug = True\n",
    "testing_sample = 1000\n",
    "gpu_switch = \"OFF\"\n",
    "n_splits = 3\n",
    "n_test_split = 1\n",
    "embargo_td = 100\n",
    "state = 42\n",
    "cv_mthd = \"KF\"  # \"KF\" or \"PurgedKF\"\n",
    "n_repeats = 1\n",
    "model_mthd = \"LGBMR\"\n",
    "nbrnd_erly_stp = 1000\n",
    "\n",
    "# Data Loading\n",
    "if debug:\n",
    "    X = pd.read_parquet(\n",
    "        os.path.join(\n",
    "            path_project_directory,\n",
    "            \"data/kaggle_optiver_trading_at_the_close/XTrIntCmpNewFtre.parquet\",\n",
    "        )\n",
    "    ).sample(n=testing_sample)\n",
    "else:\n",
    "    X = pd.read_parquet(\n",
    "        os.path.join(\n",
    "            path_project_directory,\n",
    "            \"data/kaggle_optiver_trading_at_the_close/XTrIntCmpNewFtre.parquet\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "y = (\n",
    "    pd.read_parquet(\n",
    "        os.path.join(\n",
    "            path_project_directory,\n",
    "            \"data/kaggle_optiver_trading_at_the_close/Ytrain.parquet\",\n",
    "        )\n",
    "    )\n",
    "    .loc[X.index]\n",
    "    .squeeze()\n",
    ")\n",
    "\n",
    "# Logging Data Shapes\n",
    "print(f\"X: {X.shape}, y: {y.shape[0]}\")\n",
    "\n",
    "# Cross-Validation Setup\n",
    "all_cv = {\"KF\": KFold(n_splits=n_splits, shuffle=True, random_state=state)}\n",
    "cv = all_cv[cv_mthd]\n",
    "\n",
    "# Model Setup\n",
    "dict_models = {\n",
    "    \"LGBMR\": LGBMR(\n",
    "        device=\"gpu\" if gpu_switch == \"ON\" else \"cpu\",\n",
    "        objective=\"regression_l1\",\n",
    "        boosting_type=\"gbdt\",\n",
    "        random_state=state,\n",
    "        colsample_bytree=0.7,\n",
    "        subsample=0.65,\n",
    "        learning_rate=0.065,\n",
    "        max_depth=6,\n",
    "        n_estimators=500,\n",
    "        verbose=-1,\n",
    "        num_leaves=150,\n",
    "        reg_alpha=0.01,\n",
    "        reg_lambda=3.25,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "}\n",
    "\n",
    "model = dict_models[model_mthd]\n",
    "\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    try:\n",
    "        with mlflow.start_run() as run:\n",
    "            mae_list = []\n",
    "            n_estimators = trial.suggest_int(\"n_estimators\", 100, 500)\n",
    "            learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.1)\n",
    "            model.set_params(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "\n",
    "            logger.info(\n",
    "                colored(\"------------------------------------------------\", \"blue\")\n",
    "            )\n",
    "            logger.info(\n",
    "                colored(\n",
    "                    f\"Trial {trial.number:<4} | n_estimators: {n_estimators:<4} | learning_rate: {learning_rate:<10}\",\n",
    "                    \"green\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            logger.info(f\"{'Fold':<5} {'|':<2} {'MAE':<20}\")\n",
    "            logger.info(f\"{'-----':<5} {'|':<2} {'--------------------':<20}\")\n",
    "\n",
    "            for fold_n, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "                X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "                y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "                model.fit(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    eval_metric=\"mae\",\n",
    "                    callbacks=[\n",
    "                        log_evaluation(0),\n",
    "                        early_stopping(nbrnd_erly_stp, verbose=False),\n",
    "                    ],\n",
    "                )\n",
    "\n",
    "                fold_mae = model.best_score_[\"valid_0\"][\"l1\"]\n",
    "                mae_list.append(fold_mae)\n",
    "                logger.info(f\"{fold_n + 1:<5} {'|':<2} {fold_mae:<20}\")\n",
    "\n",
    "            avg_mae = sum(mae_list) / len(mae_list)\n",
    "            logger.warning(colored(f\"Average MAE: {avg_mae}\", \"yellow\"))\n",
    "            mlflow.log_metric(\"mae\", avg_mae)\n",
    "            mlflow.log_params(\n",
    "                {\"n_estimators\": n_estimators, \"learning_rate\": learning_rate}\n",
    "            )\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "            return avg_mae\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An exception occurred: {e}\")\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "# Suppress warnings from Optuna and other libraries\n",
    "warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning)\n",
    "\n",
    "# Run the Optuna study\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"Your Study Name\",\n",
    "    storage=\"sqlite:///example.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(lambda trial: objective(trial, X, y), n_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
