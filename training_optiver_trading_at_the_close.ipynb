{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/miniconda3/envs/training/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Built-in modules\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# External general-purpose modules\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "\n",
    "# Logging and optimization modules\n",
    "from loguru import logger\n",
    "import mlflow\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "\n",
    "# Machine learning and model validation modules\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import log_evaluation, early_stopping, LGBMRegressor as LGBMR\n",
    "\n",
    "# Custom modules\n",
    "from src.utils.utils_kaggle import get_data\n",
    "from src.utils.utils_general import get_project_directory, load_config\n",
    "from src.experiments.mlflow_optuna_init import initialize_mlflow, initialize_optuna\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Auto-reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get project directory and load configuration\n",
    "path_project_directory = get_project_directory()\n",
    "config_path = os.path.join(path_project_directory, \"config/train_config.yaml\")\n",
    "config = load_config(config_path)\n",
    "\n",
    "# Define paths\n",
    "dataset_path = os.path.join(\n",
    "    path_project_directory, \"data/processed/synthetic_ticker_data.csv\"\n",
    ")\n",
    "path_experiments_storage = os.path.join(\n",
    "    path_project_directory, \"data/experiments_storage\"\n",
    ")\n",
    "\n",
    "# Kaggle dataset parameters\n",
    "kaggle_json_path = os.path.join(path_project_directory, \"kaggle.json\")\n",
    "\n",
    "dest_folder = os.path.join(\n",
    "    path_project_directory, \"data/kaggle_optiver_trading_at_the_close\"\n",
    ")\n",
    "dataset_name = \"ravi20076/optiver-memoryreduceddatasets\"\n",
    "specific_file = \"XTrIntCmpNewFtre.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from Kaggle\n",
    "get_data(\n",
    "    kaggle_json_path,\n",
    "    dest_folder,\n",
    "    dataset_name=dataset_name,\n",
    "    specific_file=specific_file,\n",
    ")\n",
    "\n",
    "# Initialize MLFlow and Optuna\n",
    "initialize_mlflow(path_experiments_storage, config)\n",
    "study = initialize_optuna(path_experiments_storage, config)\n",
    "\n",
    "# Configure Optuna logging\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Configure Loguru\n",
    "logger.add(\n",
    "    \"objective_logs.log\", format=\"{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}\"\n",
    ")\n",
    "\n",
    "# Initialize MLflow callback\n",
    "mlflow_callback = MLflowCallback(\n",
    "    tracking_uri=mlflow.get_tracking_uri(), metric_name=\"mae\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df):\n",
    "    features = [\n",
    "        \"seconds_in_bucket\",\n",
    "        \"imbalance_buy_sell_flag\",\n",
    "        \"imbalance_size\",\n",
    "        \"matched_size\",\n",
    "        \"bid_size\",\n",
    "        \"ask_size\",\n",
    "        \"reference_price\",\n",
    "        \"far_price\",\n",
    "        \"near_price\",\n",
    "        \"ask_price\",\n",
    "        \"bid_price\",\n",
    "        \"wap\",\n",
    "        \"imb_s1\",\n",
    "        \"imb_s2\",\n",
    "    ]\n",
    "\n",
    "    df[\"imb_s1\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
    "    df[\"imb_s2\"] = df.eval(\n",
    "        \"(imbalance_size-matched_size)/(matched_size+imbalance_size)\"\n",
    "    )\n",
    "\n",
    "    prices = [\n",
    "        \"reference_price\",\n",
    "        \"far_price\",\n",
    "        \"near_price\",\n",
    "        \"ask_price\",\n",
    "        \"bid_price\",\n",
    "        \"wap\",\n",
    "    ]\n",
    "\n",
    "    for i, a in enumerate(prices):\n",
    "        for j, b in enumerate(prices):\n",
    "            if i > j:\n",
    "                df[f\"{a}_{b}_imb\"] = df.eval(f\"({a}-{b})/({a}+{b})\")\n",
    "                features.append(f\"{a}_{b}_imb\")\n",
    "\n",
    "    for i, a in enumerate(prices):\n",
    "        for j, b in enumerate(prices):\n",
    "            for k, c in enumerate(prices):\n",
    "                if i > j and j > k:\n",
    "                    max_ = df[[a, b, c]].max(axis=1)\n",
    "                    min_ = df[[a, b, c]].min(axis=1)\n",
    "                    mid_ = df[[a, b, c]].sum(axis=1) - min_ - max_\n",
    "\n",
    "                    df[f\"{a}_{b}_{c}_imb2\"] = (max_ - mid_) / (mid_ - min_)\n",
    "                    features.append(f\"{a}_{b}_{c}_imb2\")\n",
    "\n",
    "    return df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\n",
    "    os.path.join(\n",
    "        path_project_directory, \"data/kaggle_optiver_trading_at_the_close/train.csv\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = generate_features(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for test, revealed_targets, sample_prediction in iter_test:\n",
    "    feat = generate_features(test)\n",
    "\n",
    "    sample_prediction[\"target\"] = np.mean([model.predict(feat) for model in models], 0)\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv( path_project_directory'/kaggle/input/optiver-trading-at-the-close/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Settings\n",
    "debug = True\n",
    "testing_sample = 1000\n",
    "gpu_switch = \"OFF\"\n",
    "n_splits = 3\n",
    "n_test_split = 1\n",
    "embargo_td = 100\n",
    "state = 42\n",
    "cv_mthd = \"KF\"  # \"KF\" or \"PurgedKF\"\n",
    "n_repeats = 1\n",
    "model_mthd = \"LGBMR\"\n",
    "nbrnd_erly_stp = 1000\n",
    "\n",
    "# Data Loading\n",
    "if debug:\n",
    "    X = pd.read_parquet(\n",
    "        os.path.join(\n",
    "            path_project_directory,\n",
    "            \"data/kaggle_optiver_trading_at_the_close/XTrIntCmpNewFtre.parquet\",\n",
    "        )\n",
    "    ).sample(n=testing_sample)\n",
    "else:\n",
    "    X = pd.read_parquet(\n",
    "        os.path.join(\n",
    "            path_project_directory,\n",
    "            \"data/kaggle_optiver_trading_at_the_close/XTrIntCmpNewFtre.parquet\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "y = (\n",
    "    pd.read_parquet(\n",
    "        os.path.join(\n",
    "            path_project_directory,\n",
    "            \"data/kaggle_optiver_trading_at_the_close/Ytrain.parquet\",\n",
    "        )\n",
    "    )\n",
    "    .loc[X.index]\n",
    "    .squeeze()\n",
    ")\n",
    "\n",
    "# Logging Data Shapes\n",
    "print(f\"X: {X.shape}, y: {y.shape[0]}\")\n",
    "\n",
    "# Cross-Validation Setup\n",
    "all_cv = {\"KF\": KFold(n_splits=n_splits, shuffle=True, random_state=state)}\n",
    "cv = all_cv[cv_mthd]\n",
    "\n",
    "# Model Setup\n",
    "dict_models = {\n",
    "    \"LGBMR\": LGBMR(\n",
    "        device=\"gpu\" if gpu_switch == \"ON\" else \"cpu\",\n",
    "        objective=\"regression_l1\",\n",
    "        boosting_type=\"gbdt\",\n",
    "        random_state=state,\n",
    "        colsample_bytree=0.7,\n",
    "        subsample=0.65,\n",
    "        learning_rate=0.065,\n",
    "        max_depth=6,\n",
    "        n_estimators=500,\n",
    "        verbose=-1,\n",
    "        num_leaves=150,\n",
    "        reg_alpha=0.01,\n",
    "        reg_lambda=3.25,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "}\n",
    "\n",
    "model = dict_models[model_mthd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-21 11:19:32.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1m\u001b[34m------------------------------------------------\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:32.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1m\u001b[32mTrial 78   | n_estimators: 150  | learning_rate: 0.010518498605383094\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:32.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mFold  |  MAE                 \u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:32.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m----- |  --------------------\u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:32.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1m1     |  6.346515089764429   \u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:32.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1m2     |  6.544533798190073   \u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:32.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1m3     |  6.148576132486202   \u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:32.476\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m42\u001b[0m - \u001b[33m\u001b[1m\u001b[33mAverage MAE: 6.3465416734802345\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:33.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1m\u001b[34m------------------------------------------------\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:33.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1m\u001b[32mTrial 79   | n_estimators: 160  | learning_rate: 0.011309922201427684\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:33.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mFold  |  MAE                 \u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:33.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m----- |  --------------------\u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:33.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1m1     |  6.343971676259951   \u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:33.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1m2     |  6.536933882826917   \u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:33.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1m3     |  6.147778492465223   \u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:33.863\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m42\u001b[0m - \u001b[33m\u001b[1m\u001b[33mAverage MAE: 6.342894683850697\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:34.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1m\u001b[34m------------------------------------------------\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:34.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1m\u001b[32mTrial 80   | n_estimators: 163  | learning_rate: 0.011843046604696643\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:34.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mFold  |  MAE                 \u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:34.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m----- |  --------------------\u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:35.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1m1     |  6.343743623381834   \u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:35.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1m2     |  6.5434227035141745  \u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:35.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1m3     |  6.132559182870816   \u001b[0m\n",
      "\u001b[32m2023-10-21 11:19:35.161\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m42\u001b[0m - \u001b[33m\u001b[1m\u001b[33mAverage MAE: 6.339908503255607\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X, y):\n",
    "    try:\n",
    "        with mlflow.start_run() as run:\n",
    "            mae_list = []\n",
    "            n_estimators = trial.suggest_int(\"n_estimators\", 100, 500)\n",
    "            learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.1)\n",
    "            model.set_params(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "\n",
    "            logger.info(\n",
    "                colored(\"------------------------------------------------\", \"blue\")\n",
    "            )\n",
    "            logger.info(\n",
    "                colored(\n",
    "                    f\"Trial {trial.number:<4} | n_estimators: {n_estimators:<4} | learning_rate: {learning_rate:<10}\",\n",
    "                    \"green\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            logger.info(f\"{'Fold':<5} {'|':<2} {'MAE':<20}\")\n",
    "            logger.info(f\"{'-----':<5} {'|':<2} {'--------------------':<20}\")\n",
    "\n",
    "            for fold_n, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "                X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "                y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "                model.fit(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    eval_metric=\"mae\",\n",
    "                    callbacks=[\n",
    "                        log_evaluation(0),\n",
    "                        early_stopping(nbrnd_erly_stp, verbose=False),\n",
    "                    ],\n",
    "                )\n",
    "\n",
    "                fold_mae = model.best_score_[\"valid_0\"][\"l1\"]\n",
    "                mae_list.append(fold_mae)\n",
    "                logger.info(f\"{fold_n + 1:<5} {'|':<2} {fold_mae:<20}\")\n",
    "\n",
    "            avg_mae = sum(mae_list) / len(mae_list)\n",
    "            logger.warning(colored(f\"Average MAE: {avg_mae}\", \"yellow\"))\n",
    "            mlflow.log_metric(\"mae\", avg_mae)\n",
    "            mlflow.log_params(\n",
    "                {\"n_estimators\": n_estimators, \"learning_rate\": learning_rate}\n",
    "            )\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "            return avg_mae\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An exception occurred: {e}\")\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "# Suppress warnings from Optuna and other libraries\n",
    "warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning)\n",
    "\n",
    "# Run the Optuna study\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"Your Study Name\",\n",
    "    storage=\"sqlite:///data/optuna.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(lambda trial: objective(trial, X, y), n_trials=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
