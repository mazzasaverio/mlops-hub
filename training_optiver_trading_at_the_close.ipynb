{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/21 21:25:05 INFO mlflow.tracking.fluent: Experiment with name 'Default_Experiment2' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-21 21:25:34.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1m\u001b[34m------------------------------------------------\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:34.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1m\u001b[32mTrial 6    | n_estimators: 237  | learning_rate: 0.08549053734229291\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:34.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mFold  |  MAE                 \u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:34.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m154\u001b[0m - \u001b[1m----- |  --------------------\u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:34.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1m1     |  6.5699646311969335  \u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:34.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1m2     |  6.220175976074886   \u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:34.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1m3     |  6.667523581686927   \u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:34.293\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m176\u001b[0m - \u001b[33m\u001b[1m\u001b[33mAverage MAE: 6.485888062986248\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:35.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1m\u001b[34m------------------------------------------------\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:35.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1m\u001b[32mTrial 7    | n_estimators: 494  | learning_rate: 0.013107418093234924\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:35.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mFold  |  MAE                 \u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:35.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m154\u001b[0m - \u001b[1m----- |  --------------------\u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:35.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1m1     |  6.59951932121003    \u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:35.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1m2     |  6.224380023957826   \u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:36.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1m3     |  6.681089849027159   \u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:36.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m176\u001b[0m - \u001b[33m\u001b[1m\u001b[33mAverage MAE: 6.501663064731672\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:37.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1m\u001b[34m------------------------------------------------\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:37.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1m\u001b[32mTrial 8    | n_estimators: 326  | learning_rate: 0.029206515853172355\u001b[0m\u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:37.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mFold  |  MAE                 \u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:37.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m154\u001b[0m - \u001b[1m----- |  --------------------\u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:37.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1m1     |  6.599252611177796   \u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:37.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1m2     |  6.2246249933223154  \u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:37.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1m3     |  6.683158283630053   \u001b[0m\n",
      "\u001b[32m2023-10-21 21:25:37.619\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m176\u001b[0m - \u001b[33m\u001b[1m\u001b[33mAverage MAE: 6.502345296043388\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Built-in modules\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# External general-purpose modules\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "\n",
    "# Logging and optimization modules\n",
    "from loguru import logger\n",
    "import mlflow\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "\n",
    "# Machine learning and model validation modules\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import log_evaluation, early_stopping, LGBMRegressor as LGBMR\n",
    "\n",
    "# Custom modules\n",
    "from src.utils.utils_kaggle import get_data\n",
    "from src.utils.utils_general import get_project_directory, load_config\n",
    "from src.experiments.mlflow_optuna_init import initialize_optuna\n",
    "from src.feat_engineering.fe_opriver_trading_at_the_close import generate_features\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Auto-reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Optuna logging\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Configure Loguru\n",
    "logger.add(\n",
    "    \"objective_logs.log\", format=\"{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}\"\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize MLflow callback\n",
    "mlflow_callback = MLflowCallback(\n",
    "    tracking_uri=mlflow.get_tracking_uri(), metric_name=\"mae\"\n",
    ")\n",
    "\n",
    "name_folder_data_project = \"kaggle_optiver_trading_at_the_close\"\n",
    "\n",
    "file_name_df_train = \"train.csv\"\n",
    "file_name_df_test = \"test.csv\"\n",
    "\n",
    "download_kaggle_data = False\n",
    "\n",
    "#####################################################################################\n",
    "path_project_dir = get_project_directory()\n",
    "path_data_dir = os.path.join(path_project_dir, \"data\")\n",
    "path_config_dir = os.path.join(path_project_dir, \"config\")\n",
    "\n",
    "path_data_project_dir = os.path.join(path_data_dir, name_folder_data_project)\n",
    "\n",
    "path_experiments_storage = os.path.join(path_data_project_dir, \"experiments_storage\")\n",
    "\n",
    "path_config_train = os.path.join(path_config_dir, \"train_config.yaml\")\n",
    "path_dataset_train = os.path.join(path_data_project_dir, file_name_df_train)\n",
    "path_dataset_test = os.path.join(path_data_project_dir, file_name_df_test)\n",
    "\n",
    "config = load_config(path_config_train)\n",
    "\n",
    "if download_kaggle_data:\n",
    "    dataset_name = \"ravi20076/optiver-memoryreduceddatasets\"\n",
    "    kaggle_json_path = os.path.join(path_project_dir, \"kaggle.json\")\n",
    "    get_data(\n",
    "        kaggle_json_path,\n",
    "        path_data_project_dir,\n",
    "        dataset_name=dataset_name,\n",
    "        specific_file=None,\n",
    "    )\n",
    "# Constants and Settings\n",
    "debug = True\n",
    "testing_sample = 1000\n",
    "gpu_switch = \"OFF\"\n",
    "n_splits = 3\n",
    "n_test_split = 1\n",
    "embargo_td = 100\n",
    "state = 42\n",
    "cv_mthd = \"KF\"  # \"KF\" or \"PurgedKF\"\n",
    "n_repeats = 1\n",
    "model_mthd = \"LGBMR\"\n",
    "nbrnd_erly_stp = 1000\n",
    "mlflow.set_tracking_uri(path_experiments_storage)\n",
    "mlflow.set_experiment(config.get('experiment_name', 'Default_Experiment2'))\n",
    "study = initialize_optuna(path_experiments_storage, config)\n",
    "df_train_raw = pd.read_csv(path_dataset_train)\n",
    "df_test_raw = pd.read_csv(path_dataset_test)\n",
    "df_train = generate_features(df_train_raw)\n",
    "\n",
    "if debug:\n",
    "    X_train = df_train.sample(n=testing_sample)\n",
    "else:\n",
    "    X_train = df_train.copy()\n",
    "\n",
    "y_train = df_train_raw[\"target\"].loc[X_train.index].squeeze()\n",
    "del df_train_raw, df_test_raw\n",
    "# Cross-Validation Setup\n",
    "all_cv = {\"KF\": KFold(n_splits=n_splits, shuffle=True, random_state=state)}\n",
    "cv = all_cv[cv_mthd]\n",
    "\n",
    "# Model Setup\n",
    "dict_models = {\n",
    "    \"LGBMR\": LGBMR(\n",
    "        device=\"gpu\" if gpu_switch == \"ON\" else \"cpu\",\n",
    "        objective=\"regression_l1\",\n",
    "        boosting_type=\"gbdt\",\n",
    "        random_state=state,\n",
    "        colsample_bytree=0.7,\n",
    "        subsample=0.65,\n",
    "        learning_rate=0.065,\n",
    "        max_depth=6,\n",
    "        n_estimators=500,\n",
    "        verbose=-1,\n",
    "        num_leaves=150,\n",
    "        reg_alpha=0.01,\n",
    "        reg_lambda=3.25,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "}\n",
    "\n",
    "model = dict_models[model_mthd]\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    try:\n",
    "        with mlflow.start_run() as run:\n",
    "            mae_list = []\n",
    "            n_estimators = trial.suggest_int(\"n_estimators\", 100, 500)\n",
    "            learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.1)\n",
    "            model.set_params(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "\n",
    "            logger.info(\n",
    "                colored(\"------------------------------------------------\", \"blue\")\n",
    "            )\n",
    "            logger.info(\n",
    "                colored(\n",
    "                    f\"Trial {trial.number:<4} | n_estimators: {n_estimators:<4} | learning_rate: {learning_rate:<10}\",\n",
    "                    \"green\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            logger.info(f\"{'Fold':<5} {'|':<2} {'MAE':<20}\")\n",
    "            logger.info(f\"{'-----':<5} {'|':<2} {'--------------------':<20}\")\n",
    "\n",
    "            for fold_n, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "                X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "                y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "                model.fit(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    eval_metric=\"mae\",\n",
    "                    callbacks=[\n",
    "                        log_evaluation(0),\n",
    "                        early_stopping(nbrnd_erly_stp, verbose=False),\n",
    "                    ],\n",
    "                )\n",
    "\n",
    "                fold_mae = model.best_score_[\"valid_0\"][\"l1\"]\n",
    "                mae_list.append(fold_mae)\n",
    "                logger.info(f\"{fold_n + 1:<5} {'|':<2} {fold_mae:<20}\")\n",
    "\n",
    "            avg_mae = sum(mae_list) / len(mae_list)\n",
    "            logger.warning(colored(f\"Average MAE: {avg_mae}\", \"yellow\"))\n",
    "            mlflow.log_metric(\"mae\", avg_mae)\n",
    "            mlflow.log_params(\n",
    "                {\"n_estimators\": n_estimators, \"learning_rate\": learning_rate}\n",
    "            )\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "            return avg_mae\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An exception occurred: {e}\")\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "# Suppress warnings from Optuna and other libraries\n",
    "warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning)\n",
    "\n",
    "# Run the Optuna study\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"Your Study Name\",\n",
    "    storage=\"sqlite:///data/kaggle_optiver_trading_at_the_close/experiments_storage/optuna.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
