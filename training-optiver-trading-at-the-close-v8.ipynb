{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff2ed02c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:12.424688Z",
     "iopub.status.busy": "2023-11-14T14:56:12.423824Z",
     "iopub.status.idle": "2023-11-14T14:56:18.929983Z",
     "shell.execute_reply": "2023-11-14T14:56:18.928915Z"
    },
    "papermill": {
     "duration": 6.524524,
     "end_time": "2023-11-14T14:56:18.932693",
     "exception": false,
     "start_time": "2023-11-14T14:56:12.408169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants and Configuration Variables\n",
    "DEBUG = False\n",
    "TRAIN = False\n",
    "TUNING = True\n",
    "OVERWRITE_PROCESSED_DATA = True\n",
    "N_TRIALS = 10\n",
    "STATE = 42\n",
    "\n",
    "gpu_switch = \"OFF\"\n",
    "N_SPLITS = 7\n",
    "N_TEST_SPLITS = 1\n",
    "N_PURGE = 11\n",
    "N_EMBARGO = 11\n",
    "\n",
    "\n",
    "VERSION_NB = 11\n",
    "EXPERIMENT_PURPOSE = \"optiver_trading_at_the_close\"\n",
    "\n",
    "\n",
    "# RECORD ENSAMBLE MODEL\n",
    "model_paths = [\n",
    "    \"s3://mlflow-v1/kaggle_optiver_trading_at_the_close/0f6ce4df6744464bbd4123566a088d27/artifacts/LGBMR_0_20231114_095007/model.pkl\",\n",
    "    \"s3://mlflow-v1/kaggle_optiver_trading_at_the_close/47d294f60f9642248cb2d0fb8ccd9bf6/artifacts/LGBMR_0_20231114_100521/model.pkl\",\n",
    "    \"s3://mlflow-v1/kaggle_optiver_trading_at_the_close/9431eeeeaf6b4690a6a11d9b9d0ad52a/artifacts/LGBMR_0_20231114_101915/model.pkl\",\n",
    "    \"s3://mlflow-v1/kaggle_optiver_trading_at_the_close/e603fb30d1b04756b34e443325924da4/artifacts/LGBMR_0_20231114_103413/model.pkl\",\n",
    "    \"s3://mlflow-v1/kaggle_optiver_trading_at_the_close/748ddac91acf4ead85cc0f567d053596/artifacts/LGBMR_0_20231114_104931/model.pkl\",\n",
    "    \"s3://mlflow-v1/kaggle_optiver_trading_at_the_close/814b2dc76eb14d57a80a79e100c50c3a/artifacts/LGBMR_0_20231114_110439/model.pkl\",\n",
    "    \"s3://mlflow-v1/kaggle_optiver_trading_at_the_close/5ab9ade2bcdb46e8bd86ae1e5f8f2df4/artifacts/LGBMR_0_20231114_111703/model.pkl\"\n",
    "]\n",
    "\n",
    "# Define the model name for registration in MLflow\n",
    "\n",
    "model_name = f\"ensemble_model (7)\"\n",
    "folder_model = f'models-v8'\n",
    "model_name_artifict = f\"ensemble_model (7).pkl\"\n",
    "\n",
    "import joblib\n",
    "model_prod = joblib.load('/kaggle/input/models-v8/ensemble_model (7).pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca273eb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:18.960553Z",
     "iopub.status.busy": "2023-11-14T14:56:18.959422Z",
     "iopub.status.idle": "2023-11-14T14:56:18.970458Z",
     "shell.execute_reply": "2023-11-14T14:56:18.969679Z"
    },
    "papermill": {
     "duration": 0.026944,
     "end_time": "2023-11-14T14:56:18.972591",
     "exception": false,
     "start_time": "2023-11-14T14:56:18.945647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stock_id',\n",
       " 'seconds_in_bucket',\n",
       " 'imbalance_size',\n",
       " 'imbalance_buy_sell_flag',\n",
       " 'reference_price',\n",
       " 'matched_size',\n",
       " 'far_price',\n",
       " 'near_price',\n",
       " 'bid_price',\n",
       " 'bid_size',\n",
       " 'ask_price',\n",
       " 'ask_size',\n",
       " 'wap',\n",
       " 'mid_price',\n",
       " 'liquidity_imbalance',\n",
       " 'matched_imbalance',\n",
       " 'size_imbalance',\n",
       " 'reference_price_far_price_imb',\n",
       " 'reference_price_near_price_imb',\n",
       " 'reference_price_ask_price_imb',\n",
       " 'reference_price_bid_price_imb',\n",
       " 'reference_price_wap_imb',\n",
       " 'far_price_near_price_imb',\n",
       " 'far_price_ask_price_imb',\n",
       " 'far_price_bid_price_imb',\n",
       " 'far_price_wap_imb',\n",
       " 'near_price_ask_price_imb',\n",
       " 'near_price_bid_price_imb',\n",
       " 'near_price_wap_imb',\n",
       " 'ask_price_bid_price_imb',\n",
       " 'ask_price_wap_imb',\n",
       " 'bid_price_wap_imb',\n",
       " 'ask_price_bid_price_wap_imb2',\n",
       " 'ask_price_bid_price_reference_price_imb2',\n",
       " 'ask_price_wap_reference_price_imb2',\n",
       " 'bid_price_wap_reference_price_imb2',\n",
       " 'matched_size_bid_size_ask_size_imb2',\n",
       " 'matched_size_bid_size_imbalance_size_imb2',\n",
       " 'matched_size_ask_size_imbalance_size_imb2',\n",
       " 'stock_weights',\n",
       " 'weighted_wap',\n",
       " 'wap_momentum',\n",
       " 'imbalance_momentum',\n",
       " 'price_spread',\n",
       " 'spread_intensity',\n",
       " 'price_pressure',\n",
       " 'market_urgency',\n",
       " 'spread_depth_ratio',\n",
       " 'mid_price_movement',\n",
       " 'micro_price',\n",
       " 'relative_spread',\n",
       " 'wap_rolling_avg_6',\n",
       " 'imbalance_size_rolling_avg_6',\n",
       " 'reference_price_rolling_avg_6',\n",
       " 'far_price_rolling_avg_6',\n",
       " 'near_price_rolling_avg_6',\n",
       " 'ask_price_rolling_avg_6',\n",
       " 'bid_price_rolling_avg_6',\n",
       " 'all_prices_mean',\n",
       " 'all_sizes_mean',\n",
       " 'all_prices_std',\n",
       " 'all_sizes_std',\n",
       " 'all_prices_skew',\n",
       " 'all_sizes_skew',\n",
       " 'all_prices_kurt',\n",
       " 'all_sizes_kurt',\n",
       " 'matched_size_shift_1',\n",
       " 'matched_size_ret_1',\n",
       " 'matched_size_shift_2',\n",
       " 'matched_size_ret_2',\n",
       " 'matched_size_shift_3',\n",
       " 'matched_size_ret_3',\n",
       " 'matched_size_shift_5',\n",
       " 'matched_size_ret_5',\n",
       " 'matched_size_shift_10',\n",
       " 'matched_size_ret_10',\n",
       " 'imbalance_size_shift_1',\n",
       " 'imbalance_size_ret_1',\n",
       " 'imbalance_size_shift_2',\n",
       " 'imbalance_size_ret_2',\n",
       " 'imbalance_size_shift_3',\n",
       " 'imbalance_size_ret_3',\n",
       " 'imbalance_size_shift_5',\n",
       " 'imbalance_size_ret_5',\n",
       " 'imbalance_size_shift_10',\n",
       " 'imbalance_size_ret_10',\n",
       " 'reference_price_shift_1',\n",
       " 'reference_price_ret_1',\n",
       " 'reference_price_shift_2',\n",
       " 'reference_price_ret_2',\n",
       " 'reference_price_shift_3',\n",
       " 'reference_price_ret_3',\n",
       " 'reference_price_shift_5',\n",
       " 'reference_price_ret_5',\n",
       " 'reference_price_shift_10',\n",
       " 'reference_price_ret_10',\n",
       " 'imbalance_buy_sell_flag_shift_1',\n",
       " 'imbalance_buy_sell_flag_shift_2',\n",
       " 'imbalance_buy_sell_flag_shift_3',\n",
       " 'imbalance_buy_sell_flag_shift_5',\n",
       " 'imbalance_buy_sell_flag_shift_10',\n",
       " 'ask_price_diff_1',\n",
       " 'ask_price_diff_2',\n",
       " 'ask_price_diff_3',\n",
       " 'ask_price_diff_5',\n",
       " 'bid_price_diff_1',\n",
       " 'bid_price_diff_2',\n",
       " 'bid_price_diff_3',\n",
       " 'bid_price_diff_5',\n",
       " 'ask_size_diff_1',\n",
       " 'ask_size_diff_3',\n",
       " 'bid_size_diff_1',\n",
       " 'wap_diff_1',\n",
       " 'wap_diff_2',\n",
       " 'wap_diff_3',\n",
       " 'wap_diff_5',\n",
       " 'near_price_diff_1',\n",
       " 'near_price_diff_2',\n",
       " 'near_price_diff_3',\n",
       " 'near_price_diff_5',\n",
       " 'near_price_diff_10',\n",
       " 'far_price_diff_1',\n",
       " 'far_price_diff_2',\n",
       " 'far_price_diff_3',\n",
       " 'far_price_diff_5',\n",
       " 'far_price_diff_10',\n",
       " 'market_urgency_diff_1',\n",
       " 'market_urgency_diff_2',\n",
       " 'market_urgency_diff_3',\n",
       " 'market_urgency_diff_5',\n",
       " 'market_urgency_diff_10',\n",
       " 'dow',\n",
       " 'dom',\n",
       " 'seconds',\n",
       " 'global_median_size',\n",
       " 'global_std_size',\n",
       " 'global_ptp_size',\n",
       " 'global_median_price',\n",
       " 'global_std_price',\n",
       " 'global_ptp_price',\n",
       " 'rsi_reference_price',\n",
       " 'rsi_far_price',\n",
       " 'rsi_near_price',\n",
       " 'rsi_ask_price',\n",
       " 'rsi_bid_price',\n",
       " 'rsi_wap',\n",
       " 'macd_reference_price',\n",
       " 'macd_ask_price',\n",
       " 'macd_bid_price',\n",
       " 'macd_wap',\n",
       " 'macd_sig_reference_price',\n",
       " 'macd_sig_ask_price',\n",
       " 'macd_sig_bid_price',\n",
       " 'macd_sig_wap',\n",
       " 'macd_hist_reference_price',\n",
       " 'macd_hist_ask_price',\n",
       " 'macd_hist_bid_price',\n",
       " 'macd_hist_wap']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prod.models[0].feature_name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdbfbc11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:19.001210Z",
     "iopub.status.busy": "2023-11-14T14:56:19.000282Z",
     "iopub.status.idle": "2023-11-14T14:56:19.010952Z",
     "shell.execute_reply": "2023-11-14T14:56:19.009822Z"
    },
    "papermill": {
     "duration": 0.027451,
     "end_time": "2023-11-14T14:56:19.013333",
     "exception": false,
     "start_time": "2023-11-14T14:56:18.985882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stock_id',\n",
       " 'seconds_in_bucket',\n",
       " 'imbalance_size',\n",
       " 'imbalance_buy_sell_flag',\n",
       " 'reference_price',\n",
       " 'matched_size',\n",
       " 'far_price',\n",
       " 'near_price',\n",
       " 'bid_price',\n",
       " 'bid_size',\n",
       " 'ask_price',\n",
       " 'ask_size',\n",
       " 'wap',\n",
       " 'mid_price',\n",
       " 'liquidity_imbalance',\n",
       " 'matched_imbalance',\n",
       " 'size_imbalance',\n",
       " 'reference_price_far_price_imb',\n",
       " 'reference_price_near_price_imb',\n",
       " 'reference_price_ask_price_imb',\n",
       " 'reference_price_bid_price_imb',\n",
       " 'reference_price_wap_imb',\n",
       " 'far_price_near_price_imb',\n",
       " 'far_price_ask_price_imb',\n",
       " 'far_price_bid_price_imb',\n",
       " 'far_price_wap_imb',\n",
       " 'near_price_ask_price_imb',\n",
       " 'near_price_bid_price_imb',\n",
       " 'near_price_wap_imb',\n",
       " 'ask_price_bid_price_imb',\n",
       " 'ask_price_wap_imb',\n",
       " 'bid_price_wap_imb',\n",
       " 'ask_price_bid_price_wap_imb2',\n",
       " 'ask_price_bid_price_reference_price_imb2',\n",
       " 'ask_price_wap_reference_price_imb2',\n",
       " 'bid_price_wap_reference_price_imb2',\n",
       " 'matched_size_bid_size_ask_size_imb2',\n",
       " 'matched_size_bid_size_imbalance_size_imb2',\n",
       " 'matched_size_ask_size_imbalance_size_imb2',\n",
       " 'stock_weights',\n",
       " 'weighted_wap',\n",
       " 'wap_momentum',\n",
       " 'imbalance_momentum',\n",
       " 'price_spread',\n",
       " 'spread_intensity',\n",
       " 'price_pressure',\n",
       " 'market_urgency',\n",
       " 'spread_depth_ratio',\n",
       " 'mid_price_movement',\n",
       " 'micro_price',\n",
       " 'relative_spread',\n",
       " 'wap_rolling_avg_6',\n",
       " 'imbalance_size_rolling_avg_6',\n",
       " 'reference_price_rolling_avg_6',\n",
       " 'far_price_rolling_avg_6',\n",
       " 'near_price_rolling_avg_6',\n",
       " 'ask_price_rolling_avg_6',\n",
       " 'bid_price_rolling_avg_6',\n",
       " 'all_prices_mean',\n",
       " 'all_sizes_mean',\n",
       " 'all_prices_std',\n",
       " 'all_sizes_std',\n",
       " 'all_prices_skew',\n",
       " 'all_sizes_skew',\n",
       " 'all_prices_kurt',\n",
       " 'all_sizes_kurt',\n",
       " 'matched_size_shift_1',\n",
       " 'matched_size_ret_1',\n",
       " 'matched_size_shift_2',\n",
       " 'matched_size_ret_2',\n",
       " 'matched_size_shift_3',\n",
       " 'matched_size_ret_3',\n",
       " 'matched_size_shift_5',\n",
       " 'matched_size_ret_5',\n",
       " 'matched_size_shift_10',\n",
       " 'matched_size_ret_10',\n",
       " 'imbalance_size_shift_1',\n",
       " 'imbalance_size_ret_1',\n",
       " 'imbalance_size_shift_2',\n",
       " 'imbalance_size_ret_2',\n",
       " 'imbalance_size_shift_3',\n",
       " 'imbalance_size_ret_3',\n",
       " 'imbalance_size_shift_5',\n",
       " 'imbalance_size_ret_5',\n",
       " 'imbalance_size_shift_10',\n",
       " 'imbalance_size_ret_10',\n",
       " 'reference_price_shift_1',\n",
       " 'reference_price_ret_1',\n",
       " 'reference_price_shift_2',\n",
       " 'reference_price_ret_2',\n",
       " 'reference_price_shift_3',\n",
       " 'reference_price_ret_3',\n",
       " 'reference_price_shift_5',\n",
       " 'reference_price_ret_5',\n",
       " 'reference_price_shift_10',\n",
       " 'reference_price_ret_10',\n",
       " 'imbalance_buy_sell_flag_shift_1',\n",
       " 'imbalance_buy_sell_flag_shift_2',\n",
       " 'imbalance_buy_sell_flag_shift_3',\n",
       " 'imbalance_buy_sell_flag_shift_5',\n",
       " 'imbalance_buy_sell_flag_shift_10',\n",
       " 'ask_price_diff_1',\n",
       " 'ask_price_diff_2',\n",
       " 'ask_price_diff_3',\n",
       " 'ask_price_diff_5',\n",
       " 'bid_price_diff_1',\n",
       " 'bid_price_diff_2',\n",
       " 'bid_price_diff_3',\n",
       " 'bid_price_diff_5',\n",
       " 'ask_size_diff_1',\n",
       " 'ask_size_diff_3',\n",
       " 'bid_size_diff_1',\n",
       " 'wap_diff_1',\n",
       " 'wap_diff_2',\n",
       " 'wap_diff_3',\n",
       " 'wap_diff_5',\n",
       " 'near_price_diff_1',\n",
       " 'near_price_diff_2',\n",
       " 'near_price_diff_3',\n",
       " 'near_price_diff_5',\n",
       " 'near_price_diff_10',\n",
       " 'far_price_diff_1',\n",
       " 'far_price_diff_2',\n",
       " 'far_price_diff_3',\n",
       " 'far_price_diff_5',\n",
       " 'far_price_diff_10',\n",
       " 'market_urgency_diff_1',\n",
       " 'market_urgency_diff_2',\n",
       " 'market_urgency_diff_3',\n",
       " 'market_urgency_diff_5',\n",
       " 'market_urgency_diff_10',\n",
       " 'dow',\n",
       " 'dom',\n",
       " 'seconds',\n",
       " 'global_median_size',\n",
       " 'global_std_size',\n",
       " 'global_ptp_size',\n",
       " 'global_median_price',\n",
       " 'global_std_price',\n",
       " 'global_ptp_price',\n",
       " 'rsi_reference_price',\n",
       " 'rsi_far_price',\n",
       " 'rsi_near_price',\n",
       " 'rsi_ask_price',\n",
       " 'rsi_bid_price',\n",
       " 'rsi_wap',\n",
       " 'macd_reference_price',\n",
       " 'macd_ask_price',\n",
       " 'macd_bid_price',\n",
       " 'macd_wap',\n",
       " 'macd_sig_reference_price',\n",
       " 'macd_sig_ask_price',\n",
       " 'macd_sig_bid_price',\n",
       " 'macd_sig_wap',\n",
       " 'macd_hist_reference_price',\n",
       " 'macd_hist_ask_price',\n",
       " 'macd_hist_bid_price',\n",
       " 'macd_hist_wap']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prod.models[0].feature_name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "480b09dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:19.042210Z",
     "iopub.status.busy": "2023-11-14T14:56:19.041835Z",
     "iopub.status.idle": "2023-11-14T14:56:21.132287Z",
     "shell.execute_reply": "2023-11-14T14:56:21.131346Z"
    },
    "papermill": {
     "duration": 2.108409,
     "end_time": "2023-11-14T14:56:21.135276",
     "exception": false,
     "start_time": "2023-11-14T14:56:19.026867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# External general-purpose modules\n",
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import itertools as itt\n",
    "from itertools import combinations, product\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from numba import njit, prange\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Setting pandas options and warning filters\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "path_root_project = Path.cwd()\n",
    "if path_root_project.name not in [\"working\", \"content\"]:\n",
    "    path_root_project = Path(os.getenv(\"ROOT_PATH\") or path_root_project)\n",
    "\n",
    "    directories_to_add = [\"utils\", \"feat_engineering\", \"validation\"]\n",
    "    for directory in directories_to_add:\n",
    "        sys.path.append(str(path_root_project / \"src\" / directory))\n",
    "\n",
    "        \n",
    "from utils_training import create_model, experiments_data\n",
    "from utils_data import load_config, load_dataset, reduce_mem_usage, PathManager\n",
    "from utils_kaggle import (\n",
    "    setup_kaggle,\n",
    "    download_data,\n",
    "    get_data,\n",
    "    clean_directory_except_one,\n",
    ")\n",
    "\n",
    "from fe_optiver_trading_at_the_close import calculate_triplet_imbalance_numba, compute_triplet_imbalance, convert_weights_to_dict, global_stock_id_feats\n",
    "\n",
    "pm = PathManager(path_root_project)\n",
    "\n",
    "if TRAIN:\n",
    "    if pm.path_root_project.name == \"working\":\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "        user_secrets = UserSecretsClient()\n",
    "        aws_access_key_id = user_secrets.get_secret(\"AWS_ACCESS_KEY_ID\")\n",
    "        aws_region = user_secrets.get_secret(\"AWS_DEFAULT_REGION\")\n",
    "        aws_secret_access_key = user_secrets.get_secret(\"AWS_SECRET_ACCESS_KEY\")\n",
    "        s3_bucket_name = user_secrets.get_secret(\"S3_BUCKET\")\n",
    "\n",
    "        # Set AWS credentials in the environment variables\n",
    "        os.environ['AWS_ACCESS_KEY_ID'] = aws_access_key_id\n",
    "        os.environ['AWS_SECRET_ACCESS_KEY'] = aws_secret_access_key\n",
    "        os.environ['AWS_DEFAULT_REGION'] = aws_region\n",
    "    else:\n",
    "        aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "        aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9d254",
   "metadata": {
    "papermill": {
     "duration": 0.013446,
     "end_time": "2023-11-14T14:56:21.162265",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.148819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd1cb45",
   "metadata": {
    "papermill": {
     "duration": 0.013454,
     "end_time": "2023-11-14T14:56:21.189112",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.175658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeae03a",
   "metadata": {
    "papermill": {
     "duration": 0.012898,
     "end_time": "2023-11-14T14:56:21.215359",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.202461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4033be52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.244071Z",
     "iopub.status.busy": "2023-11-14T14:56:21.243329Z",
     "iopub.status.idle": "2023-11-14T14:56:21.248459Z",
     "shell.execute_reply": "2023-11-14T14:56:21.247399Z"
    },
    "papermill": {
     "duration": 0.022293,
     "end_time": "2023-11-14T14:56:21.250975",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.228682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#clean_directory_except_one('/kaggle/working/','submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc1ddfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.279866Z",
     "iopub.status.busy": "2023-11-14T14:56:21.279451Z",
     "iopub.status.idle": "2023-11-14T14:56:21.298016Z",
     "shell.execute_reply": "2023-11-14T14:56:21.296730Z"
    },
    "papermill": {
     "duration": 0.035618,
     "end_time": "2023-11-14T14:56:21.300299",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.264681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Conditional imports and settings based on TRAIN constant\n",
    "if TRAIN:\n",
    "    if pm.path_root_project.name == \"working\":\n",
    "        !pip install loguru mlflow optuna > /dev/null\n",
    "\n",
    "    \n",
    "\n",
    "    from utils_mlflow import (\n",
    "        get_experiments_df,\n",
    "        delete_runs_and_artifacts,\n",
    "        download_and_load_model,\n",
    "        load_models_and_create_ensemble,\n",
    "        save_and_register_model,\n",
    "        log_model_parameters,\n",
    "        get_or_create_experiment,\n",
    "        experiments_data,\n",
    "    )\n",
    "    from utils_feat_importance import log_feature_importance, aggregate_feature_importance\n",
    "    from model_validation import time_series_split\n",
    "\n",
    "    # External Libraries\n",
    "    import boto3\n",
    "    from botocore.exceptions import NoCredentialsError\n",
    "    from mlflow.exceptions import MlflowException\n",
    "    import lightgbm as lgbm\n",
    "    import mlflow\n",
    "    import optuna\n",
    "    from mlflow.tracking import MlflowClient\n",
    "    from optuna.integration.mlflow import MLflowCallback\n",
    "    from sklearn.model_selection import KFold\n",
    "    from xgboost import XGBRegressor as XGBR\n",
    "    from lightgbm import log_evaluation, early_stopping, LGBMRegressor as LGBMR\n",
    "\n",
    "\n",
    "\n",
    "    # Auto-reload modules - Specific to Jupyter Notebooks\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "    mlflow.set_tracking_uri(pm.path_experiments_dir)\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    # Create an S3 client\n",
    "    s3 = boto3.client(\n",
    "        \"s3\",\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "949cfed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.329341Z",
     "iopub.status.busy": "2023-11-14T14:56:21.328656Z",
     "iopub.status.idle": "2023-11-14T14:56:21.333586Z",
     "shell.execute_reply": "2023-11-14T14:56:21.332840Z"
    },
    "papermill": {
     "duration": 0.021792,
     "end_time": "2023-11-14T14:56:21.335759",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.313967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    s3 = boto3.client(\n",
    "        \"s3\",\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "    )\n",
    "    # Load the models and create an ensemble\n",
    "    ensemble_model = load_models_and_create_ensemble(s3, model_paths)\n",
    "\n",
    "    # Save and register the ensemble model in MLflow\n",
    "    save_and_register_model(ensemble_model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8557b6d",
   "metadata": {
    "papermill": {
     "duration": 0.013331,
     "end_time": "2023-11-14T14:56:21.362906",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.349575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cfa3eb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.392753Z",
     "iopub.status.busy": "2023-11-14T14:56:21.392062Z",
     "iopub.status.idle": "2023-11-14T14:56:21.399254Z",
     "shell.execute_reply": "2023-11-14T14:56:21.398436Z"
    },
    "papermill": {
     "duration": 0.02474,
     "end_time": "2023-11-14T14:56:21.401516",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.376776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    if not os.path.exists(pm.path_dataset_processed) or OVERWRITE_PROCESSED_DATA:\n",
    "        df_train_raw = pd.read_csv(pm.path_data_train_raw)\n",
    "\n",
    "        if DEBUG:\n",
    "            df_train_raw = df_train_raw[df_train_raw[\"stock_id\"].isin([0, 1, 2])]\n",
    "\n",
    "        drop_idx = df_train_raw.loc[\n",
    "            df_train_raw[\"target\"].isna(), \"target\"\n",
    "        ].index.to_list()\n",
    "        df_train = df_train_raw.drop(drop_idx, axis=0)\n",
    "        df_train.reset_index(drop=True, inplace=True)\n",
    "    else:\n",
    "        df_train = pd.read_csv(pm.path_dataset_processed)\n",
    "        if DEBUG:\n",
    "            df_train = df_train[df_train[\"stock_id\"].isin([0, 1, 2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe94d607",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.430335Z",
     "iopub.status.busy": "2023-11-14T14:56:21.429684Z",
     "iopub.status.idle": "2023-11-14T14:56:21.433828Z",
     "shell.execute_reply": "2023-11-14T14:56:21.432965Z"
    },
    "papermill": {
     "duration": 0.02096,
     "end_time": "2023-11-14T14:56:21.435912",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.414952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    global_stock_id_feats = global_stock_id_feats(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b95266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.464873Z",
     "iopub.status.busy": "2023-11-14T14:56:21.464188Z",
     "iopub.status.idle": "2023-11-14T14:56:21.473101Z",
     "shell.execute_reply": "2023-11-14T14:56:21.472229Z"
    },
    "papermill": {
     "duration": 0.026019,
     "end_time": "2023-11-14T14:56:21.475366",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.449347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def aggregate_feature_importance(list_files_feat_importance):\n",
    "    list_of_dfs = []\n",
    "    for file_path in list_files_feat_importance:\n",
    "        feature_importance_df = pd.read_csv(file_path)\n",
    "\n",
    "        folds = [col for col in feature_importance_df.columns if \"imp_fold\" in col]\n",
    "\n",
    "        # Normalize by dividing each score by the sum of scores within its respective fold\n",
    "        for fold in folds:\n",
    "            fold_sum = feature_importance_df[fold].sum()\n",
    "            feature_importance_df[fold] = feature_importance_df[fold] / fold_sum\n",
    "\n",
    "        list_of_dfs.append(feature_importance_df)\n",
    "\n",
    "    aggregated_df = pd.concat(list_of_dfs, ignore_index=True)\n",
    "\n",
    "    df_median_importance = aggregated_df.groupby(\"feat\").median().reset_index()\n",
    "\n",
    "    df_median_importance[\"feat_imp_overall_mean\"] = df_median_importance.loc[\n",
    "        :, df_median_importance.columns != \"feat\"\n",
    "    ].median(axis=1, skipna=True)\n",
    "    cols = [\"feat\", \"feat_imp_overall_mean\"] + [\n",
    "        col\n",
    "        for col in df_median_importance.columns\n",
    "        if col not in [\"feat_imp_overall_mean\", \"feat\"]\n",
    "    ]\n",
    "    df_median_importance = df_median_importance[cols]\n",
    "\n",
    "    df_median_importance.sort_values(\n",
    "        \"feat_imp_overall_mean\", ascending=False, inplace=True\n",
    "    )\n",
    "    return df_median_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7e432ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.504209Z",
     "iopub.status.busy": "2023-11-14T14:56:21.503548Z",
     "iopub.status.idle": "2023-11-14T14:56:21.507962Z",
     "shell.execute_reply": "2023-11-14T14:56:21.507023Z"
    },
    "papermill": {
     "duration": 0.021687,
     "end_time": "2023-11-14T14:56:21.510535",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.488848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#aggregate_feature_importance(['/kaggle/working/feat_impor_optiver_trading_at_the_close_23_11_13_2032.csv']).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71ba8b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.539215Z",
     "iopub.status.busy": "2023-11-14T14:56:21.538779Z",
     "iopub.status.idle": "2023-11-14T14:56:21.545150Z",
     "shell.execute_reply": "2023-11-14T14:56:21.543892Z"
    },
    "papermill": {
     "duration": 0.023648,
     "end_time": "2023-11-14T14:56:21.547602",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.523954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_experiments = get_experiments_df(client)\n",
    "\n",
    "# experiment_ids_to_remove = [\n",
    "#     \"999333986568643837\",\n",
    "#     \"867182202959923683\",\n",
    "#     \"773486292991054569\",\n",
    "#     \"195291970476306379\",\n",
    "# ]\n",
    "# delete_runs_and_artifacts(client, experiment_ids_to_remove, s3_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ebf3e6",
   "metadata": {
    "papermill": {
     "duration": 0.013,
     "end_time": "2023-11-14T14:56:21.573997",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.560997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4aa2e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.602414Z",
     "iopub.status.busy": "2023-11-14T14:56:21.602025Z",
     "iopub.status.idle": "2023-11-14T14:56:21.613315Z",
     "shell.execute_reply": "2023-11-14T14:56:21.612392Z"
    },
    "papermill": {
     "duration": 0.028374,
     "end_time": "2023-11-14T14:56:21.615667",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.587293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "@njit(fastmath=True)\n",
    "def rolling_average(arr, window):\n",
    "    \"\"\"\n",
    "    Calculate the rolling average for a 1D numpy array.\n",
    "    \n",
    "    Parameters:\n",
    "    arr (numpy.ndarray): Input array to calculate the rolling average.\n",
    "    window (int): The number of elements to consider for the moving average.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Array containing the rolling average values.\n",
    "    \"\"\"\n",
    "    n = len(arr)\n",
    "    result = np.empty(n)\n",
    "    result[:window] = np.nan  # Padding with NaN for elements where the window is not full\n",
    "    cumsum = np.cumsum(arr)\n",
    "\n",
    "    for i in range(window, n):\n",
    "        result[i] = (cumsum[i] - cumsum[i - window]) / window\n",
    "\n",
    "    return result\n",
    "\n",
    "@njit(parallel=True)\n",
    "def compute_rolling_averages(df_values, window_sizes):\n",
    "    \"\"\"\n",
    "    Calculate the rolling averages for multiple window sizes in parallel.\n",
    "    \n",
    "    Parameters:\n",
    "    df_values (numpy.ndarray): 2D array of values to calculate the rolling averages.\n",
    "    window_sizes (List[int]): List of window sizes for the rolling averages.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: A 3D array containing the rolling averages for each window size.\n",
    "    \"\"\"\n",
    "    num_rows, num_features = df_values.shape\n",
    "    num_windows = len(window_sizes)\n",
    "    rolling_features = np.empty((num_rows, num_features, num_windows))\n",
    "\n",
    "    for feature_idx in prange(num_features):\n",
    "        for window_idx, window in enumerate(window_sizes):\n",
    "            rolling_features[:, feature_idx, window_idx] = rolling_average(df_values[:, feature_idx], window)\n",
    "\n",
    "    return rolling_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ac30ec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.702761Z",
     "iopub.status.busy": "2023-11-14T14:56:21.702345Z",
     "iopub.status.idle": "2023-11-14T14:56:21.713750Z",
     "shell.execute_reply": "2023-11-14T14:56:21.712755Z"
    },
    "papermill": {
     "duration": 0.03045,
     "end_time": "2023-11-14T14:56:21.717713",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.687263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 515 µs, sys: 43 µs, total: 558 µs\n",
      "Wall time: 541 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "@njit(parallel = True)\n",
    "def calculate_rsi(prices, period=14):\n",
    "    rsi_values = np.zeros_like(prices)\n",
    "\n",
    "    for col in prange(prices.shape[1]):\n",
    "        price_data = prices[:, col]\n",
    "        delta = np.zeros_like(price_data)\n",
    "        delta[1:] = price_data[1:] - price_data[:-1]\n",
    "        gain = np.where(delta > 0, delta, 0)\n",
    "        loss = np.where(delta < 0, -delta, 0)\n",
    "\n",
    "        avg_gain = np.mean(gain[:period])\n",
    "        avg_loss = np.mean(loss[:period])\n",
    "        \n",
    "        if avg_loss != 0:\n",
    "            rs = avg_gain / avg_loss\n",
    "        else:\n",
    "            rs = 1e-9  # or any other appropriate default value\n",
    "            \n",
    "        rsi_values[:period, col] = 100 - (100 / (1 + rs))\n",
    "\n",
    "        for i in prange(period-1, len(price_data)-1):\n",
    "            avg_gain = (avg_gain * (period - 1) + gain[i]) / period\n",
    "            avg_loss = (avg_loss * (period - 1) + loss[i]) / period\n",
    "            if avg_loss != 0:\n",
    "                rs = avg_gain / avg_loss\n",
    "            else:\n",
    "                rs = 1e-9  # or any other appropriate default value\n",
    "            rsi_values[i+1, col] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    return rsi_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f545aafe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.746468Z",
     "iopub.status.busy": "2023-11-14T14:56:21.746060Z",
     "iopub.status.idle": "2023-11-14T14:56:21.752848Z",
     "shell.execute_reply": "2023-11-14T14:56:21.751784Z"
    },
    "papermill": {
     "duration": 0.023933,
     "end_time": "2023-11-14T14:56:21.755079",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.731146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_rsi(df):\n",
    "    # Define lists of price and size-related column names\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "    \n",
    "    for stock_id, values in df.groupby(['stock_id'])[prices]:\n",
    "        columns = [f'rsi_{col}' for col in values.columns]\n",
    "        data = calculate_rsi(values.values)\n",
    "        df.loc[values.index, columns] = data\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2700cb1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.784052Z",
     "iopub.status.busy": "2023-11-14T14:56:21.783669Z",
     "iopub.status.idle": "2023-11-14T14:56:21.791831Z",
     "shell.execute_reply": "2023-11-14T14:56:21.790754Z"
    },
    "papermill": {
     "duration": 0.025421,
     "end_time": "2023-11-14T14:56:21.794248",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.768827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_macd(df):\n",
    "    # Define lists of price and size-related column names\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "    \n",
    "    for stock_id, values in df.groupby(['stock_id'])[prices]:\n",
    "        macd_values, signal_line_values, histogram_values = calculate_macd(values.values)\n",
    "        col_macd = [f'macd_{col}' for col in values.columns]\n",
    "        col_signal = [f'macd_sig_{col}' for col in values.columns]\n",
    "        col_hist = [f'macd_hist_{col}' for col in values.columns]\n",
    "        \n",
    "        df.loc[values.index, col_macd] = macd_values\n",
    "        df.loc[values.index, col_signal] = signal_line_values\n",
    "        df.loc[values.index, col_hist] = histogram_values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c9c09ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.823489Z",
     "iopub.status.busy": "2023-11-14T14:56:21.823111Z",
     "iopub.status.idle": "2023-11-14T14:56:21.833978Z",
     "shell.execute_reply": "2023-11-14T14:56:21.832810Z"
    },
    "papermill": {
     "duration": 0.028121,
     "end_time": "2023-11-14T14:56:21.836220",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.808099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def calculate_macd(data, short_window=12, long_window=26, signal_window=9):\n",
    "    rows, cols = data.shape\n",
    "    macd_values = np.empty((rows, cols))\n",
    "    signal_line_values = np.empty((rows, cols))\n",
    "    histogram_values = np.empty((rows, cols))\n",
    "\n",
    "    for i in prange(cols):\n",
    "        short_ema = np.zeros(rows)\n",
    "        long_ema = np.zeros(rows)\n",
    "\n",
    "        for j in range(1, rows):\n",
    "            short_ema[j] = (data[j, i] - short_ema[j - 1]) * (2 / (short_window + 1)) + short_ema[j - 1]\n",
    "            long_ema[j] = (data[j, i] - long_ema[j - 1]) * (2 / (long_window + 1)) + long_ema[j - 1]\n",
    "\n",
    "        macd_values[:, i] = short_ema - long_ema\n",
    "\n",
    "        signal_line = np.zeros(rows)\n",
    "        for j in range(1, rows):\n",
    "            signal_line[j] = (macd_values[j, i] - signal_line[j - 1]) * (2 / (signal_window + 1)) + signal_line[j - 1]\n",
    "\n",
    "        signal_line_values[:, i] = signal_line\n",
    "        histogram_values[:, i] = macd_values[:, i] - signal_line\n",
    "\n",
    "    return macd_values, signal_line_values, histogram_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2153bb8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.865014Z",
     "iopub.status.busy": "2023-11-14T14:56:21.864644Z",
     "iopub.status.idle": "2023-11-14T14:56:21.896367Z",
     "shell.execute_reply": "2023-11-14T14:56:21.895039Z"
    },
    "papermill": {
     "duration": 0.049258,
     "end_time": "2023-11-14T14:56:21.898846",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.849588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate imbalance features\n",
    "def imbalance_features(df):\n",
    "    prices = [\n",
    "        \"reference_price\",\n",
    "        \"far_price\",\n",
    "        \"near_price\",\n",
    "        \"ask_price\",\n",
    "        \"bid_price\",\n",
    "        \"wap\",\n",
    "        \"imbalance_size\"\n",
    "    ]\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "\n",
    "    # V1\n",
    "    df[\"volume\"] = df.eval(\"ask_size + bid_size\")\n",
    "    df[\"mid_price\"] = df.eval(\"(ask_price + bid_price) / 2\")\n",
    "    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
    "    df[\"matched_imbalance\"] = df.eval(\n",
    "        \"(imbalance_size-matched_size)/(matched_size+imbalance_size)\"\n",
    "    )\n",
    "    df[\"size_imbalance\"] = df.eval(\"bid_size / ask_size\")\n",
    "\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\")\n",
    "\n",
    "    for c in [[\"ask_price\", \"bid_price\", \"wap\", \"reference_price\"], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n",
    "        df[triplet_feature.columns] = triplet_feature.values\n",
    "\n",
    "    # V2\n",
    "    weights = convert_weights_to_dict()\n",
    "    df[\"stock_weights\"] = df[\"stock_id\"].map(weights)\n",
    "    df[\"weighted_wap\"] = df[\"stock_weights\"] * df[\"wap\"]\n",
    "    df[\"wap_momentum\"] = df.groupby(\"stock_id\")[\"weighted_wap\"].pct_change(periods=6)\n",
    "    df[\"imbalance_momentum\"] = (\n",
    "        df.groupby([\"stock_id\"])[\"imbalance_size\"].diff(periods=1) / df[\"matched_size\"]\n",
    "    )\n",
    "    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df[\"spread_intensity\"] = df.groupby([\"stock_id\"])[\"price_spread\"].diff()\n",
    "    df[\"price_pressure\"] = df[\"imbalance_size\"] * (df[\"ask_price\"] - df[\"bid_price\"])\n",
    "    df[\"market_urgency\"] = df[\"price_spread\"] * df[\"liquidity_imbalance\"]\n",
    "    df[\"depth_pressure\"] = (df[\"ask_size\"] - df[\"bid_size\"]) * (\n",
    "        df[\"far_price\"] - df[\"near_price\"]\n",
    "    )\n",
    "    df[\"spread_depth_ratio\"] = (df[\"ask_price\"] - df[\"bid_price\"]) / (\n",
    "        df[\"bid_size\"] + df[\"ask_size\"]\n",
    "    )\n",
    "    df[\"mid_price_movement\"] = (\n",
    "        df[\"mid_price\"]\n",
    "        .diff(periods=5)\n",
    "        .apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "    )\n",
    "    df[\"micro_price\"] = (\n",
    "        (df[\"bid_price\"] * df[\"ask_size\"]) + (df[\"ask_price\"] * df[\"bid_size\"])\n",
    "    ) / (df[\"bid_size\"] + df[\"ask_size\"])\n",
    "    df[\"relative_spread\"] = (df[\"ask_price\"] - df[\"bid_price\"]) / df[\"wap\"]\n",
    "\n",
    "    \n",
    "    # V4 features - Rolling averages\n",
    "    window_sizes = [6]  # Define your desired window sizes\n",
    "    list_cols = [\"wap\",\"imbalance_size\"]\n",
    "    for price in prices:\n",
    "        rolling_avg_features = compute_rolling_averages(df[price].values.reshape(-1, 1), window_sizes)\n",
    "\n",
    "        # Assigning the rolling average results to the DataFrame\n",
    "        for i, window in enumerate(window_sizes):\n",
    "            column_name = f\"{price}_rolling_avg_{window}\"\n",
    "            df[column_name] = rolling_avg_features[:, 0, i]\n",
    "\n",
    "    # Patching the start-of-day values after all rolling averages are calculated\n",
    "    for window in window_sizes:\n",
    "        for idx, seconds in enumerate(df['seconds_in_bucket'].values):\n",
    "            if seconds / 10 <= window:\n",
    "                for price in prices:\n",
    "                    column_name = f\"{price}_rolling_avg_{window}\"\n",
    "                    df.at[idx, column_name] = df.at[idx, price]\n",
    "                    \n",
    "                    \n",
    "    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n",
    "        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n",
    "        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n",
    "\n",
    "    # V3\n",
    "    for col in [\n",
    "        \"matched_size\",\n",
    "        \"imbalance_size\",\n",
    "        \"reference_price\",\n",
    "        \"imbalance_buy_sell_flag\"\n",
    "    ]:\n",
    "        for window in [1, 2, 3, 5, 10]:\n",
    "\n",
    "            df[f\"{col}_shift_{window}\"] = df.groupby([\"stock_id\"])[col].shift(window)\n",
    "            df[f\"{col}_ret_{window}\"] = df.groupby([\"stock_id\"])[col].pct_change(window)\n",
    "\n",
    "    for col in [\n",
    "        \"ask_price\",\n",
    "        \"bid_price\",\n",
    "        \"ask_size\",\n",
    "        \"bid_size\",\n",
    "        \"wap\",\n",
    "        \"near_price\",\n",
    "        \"far_price\",\n",
    "        \"market_urgency\"\n",
    "    ]:\n",
    "        for window in [1, 2, 3, 5, 10]:\n",
    "            df[f\"{col}_diff_{window}\"] = df.groupby([\"stock_id\"])[col].diff(window)\n",
    "\n",
    "    return df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "\n",
    "# generate time & stock features\n",
    "def other_features(df):\n",
    "    df[\"dow\"] = df[\"date_id\"] % 5\n",
    "    df[\"dom\"] = df[\"date_id\"] % 20\n",
    "    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60\n",
    "    df[\"minute\"] = df[\"seconds_in_bucket\"] // 60\n",
    "\n",
    "    for key, value in global_stock_id_feats.items():\n",
    "        df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# generate all features\n",
    "def feat_engineering(df):\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    cols = [c for c in df.columns if c not in [\"row_id\"]]\n",
    "    df = df[cols]\n",
    "    df = imbalance_features(df)\n",
    "    df = other_features(df)\n",
    "    \n",
    "        \n",
    "    df = generate_rsi(df)\n",
    "    df = generate_macd(df)\n",
    "    gc.collect()\n",
    "\n",
    "    list_cols = [i for i in df.columns if i not in [\"row_id\"] + ['depth_pressure',\n",
    "         'bid_size_diff_5',\n",
    "         'ask_size_diff_5',\n",
    "         'ask_size_diff_10',\n",
    "         'imbalance_buy_sell_flag_ret_5',\n",
    "         'imbalance_buy_sell_flag_ret_10',\n",
    "         'imbalance_buy_sell_flag_ret_3',\n",
    "         'imbalance_buy_sell_flag_ret_2',\n",
    "         'minute','bid_size_diff_3',\n",
    "         'bid_size_diff_10',\n",
    "         'ask_price_diff_10',\n",
    "         'bid_price_diff_10',\n",
    "         'macd_hist_far_price',\n",
    "         'macd_far_price',\n",
    "         'macd_sig_near_price',\n",
    "         'macd_sig_far_price',\n",
    "         'macd_near_price',\n",
    "         'macd_hist_near_price','bid_size_diff_2','volume','wap_diff_10','imbalance_buy_sell_flag_ret_1','bid_size_ask_size_imbalance_size_imb2','ask_size_diff_2']]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    return df[list_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85c4ec33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.928285Z",
     "iopub.status.busy": "2023-11-14T14:56:21.927530Z",
     "iopub.status.idle": "2023-11-14T14:56:21.932693Z",
     "shell.execute_reply": "2023-11-14T14:56:21.931916Z"
    },
    "papermill": {
     "duration": 0.022316,
     "end_time": "2023-11-14T14:56:21.934972",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.912656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    df_train_feats = feat_engineering(df_train)\n",
    "    print(\"Build Online Train Feats Finished.\")\n",
    "\n",
    "    df_train_feats = reduce_mem_usage(df_train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db932eda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:21.963988Z",
     "iopub.status.busy": "2023-11-14T14:56:21.963198Z",
     "iopub.status.idle": "2023-11-14T14:56:21.969390Z",
     "shell.execute_reply": "2023-11-14T14:56:21.968663Z"
    },
    "papermill": {
     "duration": 0.023188,
     "end_time": "2023-11-14T14:56:21.971602",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.948414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    col_split = \"time_id\"\n",
    "    df_train_feats.sort_values([col_split], inplace=True)\n",
    "    df_train_feats.reset_index(drop=True, inplace=True)\n",
    "    df_train_feats[\"factorized\"] = pd.factorize(df_train_feats[col_split])[0]\n",
    "\n",
    "    list_cols_drop = [\"date_id\", \"time_id\"]\n",
    "    df_train_feats.drop(list_cols_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a87449",
   "metadata": {
    "papermill": {
     "duration": 0.012952,
     "end_time": "2023-11-14T14:56:21.998313",
     "exception": false,
     "start_time": "2023-11-14T14:56:21.985361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8128da",
   "metadata": {
    "papermill": {
     "duration": 0.013221,
     "end_time": "2023-11-14T14:56:22.025104",
     "exception": false,
     "start_time": "2023-11-14T14:56:22.011883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b736c1c1",
   "metadata": {
    "papermill": {
     "duration": 0.013082,
     "end_time": "2023-11-14T14:56:22.051720",
     "exception": false,
     "start_time": "2023-11-14T14:56:22.038638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "019696f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:22.081267Z",
     "iopub.status.busy": "2023-11-14T14:56:22.080457Z",
     "iopub.status.idle": "2023-11-14T14:56:22.094680Z",
     "shell.execute_reply": "2023-11-14T14:56:22.093460Z"
    },
    "papermill": {
     "duration": 0.032117,
     "end_time": "2023-11-14T14:56:22.097275",
     "exception": false,
     "start_time": "2023-11-14T14:56:22.065158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    experiment_name = f\"{EXPERIMENT_PURPOSE}_v{VERSION_NB}\"\n",
    "    name_folder_models = f\"models_v{VERSION_NB}\"\n",
    "\n",
    "    experiment_date_str = datetime.now().strftime(\"%y_%m_%d_%H%M\")\n",
    "    experiment_id = get_or_create_experiment(\n",
    "        client, experiment_name, artifact_location=pm.path_artifact_location\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    nbrnd_erly_stp = 130\n",
    "    cv_mthd = \"KF\"\n",
    "\n",
    "    # Cross-Validation Setup\n",
    "    if TRAIN:\n",
    "        # Initialize MLflow callback\n",
    "        mlflow_callback = MLflowCallback(\n",
    "            tracking_uri=mlflow.get_tracking_uri(), metric_name=\"mae\"\n",
    "        )\n",
    "\n",
    "        all_cv = {\"KF\": KFold(n_splits=5, shuffle=True, random_state=STATE)}\n",
    "        cv = all_cv[cv_mthd]\n",
    "\n",
    "        model_params_dict = {\n",
    "            \"LGBMR\": {\n",
    "                \"static_params\": {\n",
    "                    \"device\": \"gpu\" if gpu_switch == \"ON\" else \"cpu\",\n",
    "                    \"objective\": \"mae\",\n",
    "                    \"boosting_type\": \"gbdt\",\n",
    "                    \"random_state\": STATE,\n",
    "                    \"n_jobs\": 4,\n",
    "                    \"verbose\": -1,\n",
    "                    \"importance_type\": \"gain\",\n",
    "                },\n",
    "                \"dynamic_params\": {\n",
    "                    \"n_estimators\": {\n",
    "                        \"type\": \"int\",\n",
    "                        \"low\": 4052,\n",
    "                        \"high\": 4052,\n",
    "                    },\n",
    "                    \"learning_rate\": {\n",
    "                        \"type\": \"float\",\n",
    "                        \"low\": 0.012,\n",
    "                        \"high\": 0.012,\n",
    "                    },\n",
    "                    \"max_depth\": {\"type\": \"int\", \"low\": 49, \"high\": 49},\n",
    "                    \"num_leaves\": {\n",
    "                        \"type\": \"int\",\n",
    "                        \"low\": 63,\n",
    "                        \"high\": 63,\n",
    "                    },\n",
    "                    \"min_child_samples\": {\n",
    "                        \"type\": \"int\",\n",
    "                        \"low\": 23,\n",
    "                        \"high\": 23,\n",
    "                    },\n",
    "                    \"subsample\": {\n",
    "                        \"type\": \"float\",\n",
    "                        \"low\": 1,\n",
    "                        \"high\": 1,\n",
    "                    },\n",
    "                    \"colsample_bytree\": {\n",
    "                        \"type\": \"float\",\n",
    "                        \"low\": 1,\n",
    "                        \"high\": 1,\n",
    "                    },\n",
    "                  \n",
    "                   \n",
    "                },\n",
    "            },\n",
    "        }\n",
    "\n",
    "        dict_models = {\"LGBMR\": LGBMR}\n",
    "\n",
    "        log_model = True\n",
    "\n",
    "\n",
    "    if TRAIN:\n",
    "        args = {\n",
    "            \"cv_mthd\": cv_mthd,\n",
    "            \"experiment_purpose\": EXPERIMENT_PURPOSE,\n",
    "            \"experiment_name\": experiment_name,\n",
    "            \"dict_models\": dict_models,\n",
    "            \"model_params_dict\": model_params_dict,\n",
    "            \"n_splits\": N_SPLITS,\n",
    "            \"n_test_splits\": N_TEST_SPLITS,\n",
    "            \"n_purge\": N_PURGE,\n",
    "            \"n_embargo\": N_EMBARGO,\n",
    "            \"experiment_date_str\": experiment_date_str,\n",
    "            \"path_artifact_location\": pm.path_artifact_location,\n",
    "            \"target_col\": \"target\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35ae90",
   "metadata": {
    "papermill": {
     "duration": 0.013498,
     "end_time": "2023-11-14T14:56:22.125143",
     "exception": false,
     "start_time": "2023-11-14T14:56:22.111645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfb4e452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:22.154960Z",
     "iopub.status.busy": "2023-11-14T14:56:22.154576Z",
     "iopub.status.idle": "2023-11-14T14:56:22.182467Z",
     "shell.execute_reply": "2023-11-14T14:56:22.181597Z"
    },
    "papermill": {
     "duration": 0.045154,
     "end_time": "2023-11-14T14:56:22.184731",
     "exception": false,
     "start_time": "2023-11-14T14:56:22.139577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_mlflow_experiment(df_train, args, trial=None):\n",
    "    cv_mthd = args[\"cv_mthd\"]\n",
    "    experiment_purpose = args[\"experiment_purpose\"]\n",
    "    experiment_name = args[\"experiment_name\"]\n",
    "    dict_models = args[\"dict_models\"]\n",
    "    model_params_dict = args[\"model_params_dict\"]\n",
    "\n",
    "    n_splits = args[\"n_splits\"]\n",
    "    n_test_splits = args[\"n_test_splits\"]\n",
    "    n_purge = args[\"n_purge\"]\n",
    "    n_embargo = args[\"n_embargo\"]\n",
    "\n",
    "    experiment_date_str = args[\"experiment_date_str\"]\n",
    "    path_artifact_location = args[\"path_artifact_location\"]\n",
    "    target_col = args[\"target_col\"]\n",
    "\n",
    "    if trial == None:\n",
    "        trial = optuna.trial.FixedTrial(\n",
    "            {\n",
    "                \"n_estimators\": 500,\n",
    "                \"learning_rate\": 0.005,\n",
    "                \"max_depth\": 10,\n",
    "                \"num_leaves\": 20,\n",
    "                \"min_child_samples\": 10,\n",
    "                \"subsample\": 0.7,\n",
    "                \"colsample_bytree\": 1.0,\n",
    "                \"min_split_gain\": 0.0,\n",
    "                \"reg_alpha\": 0.0,\n",
    "                \"reg_lambda\": 0.0,\n",
    "                \"device\": \"gpu\" if gpu_switch == \"ON\" else \"cpu\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    run_time_start_trial = datetime.now().strftime(\"%y_%m_%d_%H%M%S\")\n",
    "\n",
    "    with mlflow.start_run(\n",
    "        run_name=run_time_start_trial, experiment_id=experiment_id\n",
    "    ) as run:\n",
    "        score_list = []\n",
    "\n",
    "        # mlflow.set_tag(\"cv_mthd\", cv_mthd)\n",
    "        mlflow.set_tag(\"n_splits\", n_splits)\n",
    "        mlflow.set_tag(\"n_test_splits\", n_test_splits)\n",
    "        mlflow.set_tag(\"n_purge\", n_purge)\n",
    "        mlflow.set_tag(\"n_embargo\", n_embargo)\n",
    "\n",
    "        for model_name, model_class in dict_models.items():\n",
    "            if TUNING:\n",
    "                model = create_model(\n",
    "                    trial,\n",
    "                    model_class,\n",
    "                    model_params_dict[model_name][\"static_params\"],\n",
    "                    model_params_dict[model_name][\"dynamic_params\"],\n",
    "                )\n",
    "            else:\n",
    "                params = model_prod.get_params()\n",
    "                params['device'] = \"gpu\"\n",
    "                \n",
    "                model = model_class(**params)\n",
    "\n",
    "            priority_params = [\"learning_rate\", \"max_depth\"]\n",
    "            excluded_params = [\n",
    "                \"device\",\n",
    "                \"class_weight\",\n",
    "                \"random_state\",\n",
    "                \"silent\",\n",
    "                \"verbose\",\n",
    "                \"n_jobs\",\n",
    "            ]\n",
    "\n",
    "            ordered_params = log_model_parameters(\n",
    "                model, priority_params, excluded_params, verbose=True\n",
    "            )\n",
    "\n",
    "            mlflow.log_params(ordered_params)\n",
    "\n",
    "            for fold_n, (train_indices, test_indices) in enumerate(\n",
    "                time_series_split(\n",
    "                    df_train,\n",
    "                    n_splits=n_splits,\n",
    "                    n_test_splits=n_test_splits,\n",
    "                    n_purge=n_purge,\n",
    "                    n_embargo=n_embargo,\n",
    "                )\n",
    "            ):\n",
    "               # if fold_n == 0:\n",
    "                with mlflow.start_run(\n",
    "                    run_name=f\"fold_{fold_n+1}\",\n",
    "                    nested=True,\n",
    "                    experiment_id=experiment_id,\n",
    "                ) as nested_run:\n",
    "                    mlflow.set_tag(\"n_trial\", str(trial.number))\n",
    "\n",
    "                    mask_train = df_train[\"factorized\"].isin(train_indices)\n",
    "                    mask_test = df_train[\"factorized\"].isin(test_indices)\n",
    "\n",
    "                    y_train = df_train.loc[mask_train, target_col]\n",
    "                    y_val = df_train.loc[mask_test, target_col]\n",
    "                    X_train = df_train.loc[mask_train].drop(\n",
    "                        [target_col, \"factorized\"], axis=1\n",
    "                    )\n",
    "                    X_val = df_train.loc[mask_test].drop(\n",
    "                        [target_col, \"factorized\"], axis=1\n",
    "                    )\n",
    "\n",
    "                    mlflow.log_param(\"train_rows\", X_train.shape[0])\n",
    "                    mlflow.log_param(\"train_cols\", X_train.shape[1])\n",
    "\n",
    "                    model.fit(\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        eval_set=[(X_val, y_val)],\n",
    "                        eval_metric=\"mae\",\n",
    "                        callbacks=[\n",
    "                            lgbm.callback.early_stopping(stopping_rounds=100),\n",
    "                            lgbm.callback.log_evaluation(period=100000),\n",
    "                        ],\n",
    "                    )\n",
    "\n",
    "                    log_feature_importance(\n",
    "                        trial.number,\n",
    "                        model,\n",
    "                        X_train,\n",
    "                        fold_n,\n",
    "                        experiment_purpose,\n",
    "                        experiment_date_str,\n",
    "                    )\n",
    "\n",
    "                    fold_score = model.best_score_[\"valid_0\"][\"l1\"]\n",
    "\n",
    "                    score_list.append(fold_score)\n",
    "\n",
    "                    mlflow.log_metric(\"fold_score\", round(fold_score, 6))\n",
    "                    mlflow.log_param(\"fold_number\", fold_n + 1)\n",
    "                    mlflow.log_param(\"model_name\", model_name)\n",
    "\n",
    "                    mlflow.log_params(ordered_params)\n",
    "\n",
    "                    current_time_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    model_log_name = f\"{model_name}_{trial.number}_{current_time_str}\"\n",
    "\n",
    "                    mlflow.sklearn.log_model(model, model_log_name)\n",
    "\n",
    "                    mlflow.log_param(\"run_time\", current_time_str)\n",
    "\n",
    "                    nested_run_id = nested_run.info.run_id\n",
    "                    model_path = f\"{path_artifact_location}/{run.info.experiment_id}/{nested_run_id}/artifacts/{model_log_name}/model.pkl\"\n",
    "                    mlflow.log_param(\"model_path\", model_path)\n",
    "\n",
    "                avg_score = sum(score_list) / len(score_list)\n",
    "                median_score = np.median(score_list)\n",
    "                mlflow.log_metric(\"avg score\", round(avg_score, 6))\n",
    "                mlflow.log_metric(\"median score\", round(median_score, 6))\n",
    "\n",
    "        return avg_score\n",
    "\n",
    "\n",
    "def objective(trial, df_train):\n",
    "    avg_score = run_mlflow_experiment(df_train, args, trial)\n",
    "    return avg_score\n",
    "\n",
    "\n",
    "# Run the Optuna study\n",
    "if TRAIN:\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        study_name=\"Your Study Name\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    study.optimize(lambda trial: objective(trial, df_train_feats), n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6088b94",
   "metadata": {
    "_cell_guid": "51030a77-aba3-469f-9c08-7963bc8a09d2",
    "_uuid": "6ff7d358-62f0-4ac9-b028-d1c920bb4eaf",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:22.214485Z",
     "iopub.status.busy": "2023-11-14T14:56:22.213408Z",
     "iopub.status.idle": "2023-11-14T14:56:22.222688Z",
     "shell.execute_reply": "2023-11-14T14:56:22.221764Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.026377,
     "end_time": "2023-11-14T14:56:22.224975",
     "exception": false,
     "start_time": "2023-11-14T14:56:22.198598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    df_exp = experiments_data(\n",
    "        client, list_experiment_id=None, save_df=None, list_columns=None\n",
    "    )\n",
    "    list_base_cols = [\n",
    "        \"run_time\",\n",
    "        \"experiment_id\",\n",
    "        \"n_trial\",\n",
    "        \"run_id\",\n",
    "        \"model_name\",\n",
    "        \"fold_number\",\n",
    "        \"fold_score\",\n",
    "    ]\n",
    "    list_dynamic_params = list(model_params_dict[\"LGBMR\"][\"dynamic_params\"].keys())\n",
    "\n",
    "    df_exp[\"run_time\"] = pd.to_datetime(\n",
    "        df_exp[\"run_time\"], format=\"%Y%m%d_%H%M%S\", errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    for col in df_exp.columns:\n",
    "        df_exp[col] = pd.to_numeric(df_exp[col], errors=\"ignore\")\n",
    "\n",
    "    for col in df_exp.select_dtypes(include=[\"float\", \"int\"]):\n",
    "        df_exp[col] = df_exp[col].round(5)\n",
    "\n",
    "    list_cols_exp = [\"run_time\"] + list_base_cols + list_dynamic_params + [\"model_path\"]\n",
    "\n",
    "    experiment_id\n",
    "    df_exp = df_exp[df_exp[\"experiment_id\"] != 0]\n",
    "\n",
    "    df_exp = df_exp[list_cols_exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650227f9",
   "metadata": {
    "papermill": {
     "duration": 0.013015,
     "end_time": "2023-11-14T14:56:22.251650",
     "exception": false,
     "start_time": "2023-11-14T14:56:22.238635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38daf82",
   "metadata": {
    "papermill": {
     "duration": 0.012914,
     "end_time": "2023-11-14T14:56:22.278091",
     "exception": false,
     "start_time": "2023-11-14T14:56:22.265177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73877ef5",
   "metadata": {
    "papermill": {
     "duration": 0.013003,
     "end_time": "2023-11-14T14:56:22.304410",
     "exception": false,
     "start_time": "2023-11-14T14:56:22.291407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5606dd12",
   "metadata": {
    "_cell_guid": "d4bfb979-2758-4fe9-8947-399b1c3a574c",
    "_uuid": "bef1a199-0988-4743-813e-99d4308fc9bb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:22.335141Z",
     "iopub.status.busy": "2023-11-14T14:56:22.333876Z",
     "iopub.status.idle": "2023-11-14T14:56:22.358965Z",
     "shell.execute_reply": "2023-11-14T14:56:22.357967Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.042912,
     "end_time": "2023-11-14T14:56:22.361956",
     "exception": false,
     "start_time": "2023-11-14T14:56:22.319044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6df7da97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:22.392008Z",
     "iopub.status.busy": "2023-11-14T14:56:22.391633Z",
     "iopub.status.idle": "2023-11-14T14:56:41.824995Z",
     "shell.execute_reply": "2023-11-14T14:56:41.823989Z"
    },
    "papermill": {
     "duration": 19.451534,
     "end_time": "2023-11-14T14:56:41.827800",
     "exception": false,
     "start_time": "2023-11-14T14:56:22.376266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/kaggle/input/optiver-trading-at-the-close/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5a271b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:41.857224Z",
     "iopub.status.busy": "2023-11-14T14:56:41.856845Z",
     "iopub.status.idle": "2023-11-14T14:56:43.623746Z",
     "shell.execute_reply": "2023-11-14T14:56:43.622743Z"
    },
    "papermill": {
     "duration": 1.784748,
     "end_time": "2023-11-14T14:56:43.626460",
     "exception": false,
     "start_time": "2023-11-14T14:56:41.841712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_stock_id_feats = global_stock_id_feats(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02332bd9",
   "metadata": {
    "_cell_guid": "d30f3862-dca2-4242-9db0-ab9750118622",
    "_uuid": "efd9073c-aaef-4135-bf7c-1e892e9aa831",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-14T14:56:43.655573Z",
     "iopub.status.busy": "2023-11-14T14:56:43.655161Z",
     "iopub.status.idle": "2023-11-14T15:04:39.777125Z",
     "shell.execute_reply": "2023-11-14T15:04:39.776168Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 476.139875,
     "end_time": "2023-11-14T15:04:39.780027",
     "exception": false,
     "start_time": "2023-11-14T14:56:43.640152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "df_tot_test = []\n",
    "for test, revealed_targets, sample_prediction in iter_test:\n",
    "    test[\"time_id\"] = counter\n",
    "    test[\"target\"] = \"none\"\n",
    "\n",
    "    if counter < 12:\n",
    "        df_tot_test.append(test)\n",
    "    else:\n",
    "        df_tot_test = df_tot_test[1:]\n",
    "        df_tot_test.append(test)\n",
    "\n",
    "    df_test = pd.concat(df_tot_test, axis=0, ignore_index=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    feat = feat_engineering(df_test)\n",
    "    feat = feat.sort_values([\"date_id\", \"seconds_in_bucket\", \"stock_id\"])[-len(test) :]\n",
    "\n",
    "    list_cols_drop = [\"date_id\"]\n",
    "    feat.drop(list_cols_drop, axis=1, inplace=True)\n",
    "\n",
    "    list_features = model_prod.models[0].feature_name_\n",
    "    feat = feat[list_features]\n",
    "    sample_prediction[\"target\"] = model_prod.predict(feat, 'median')\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e1d7f3",
   "metadata": {
    "papermill": {
     "duration": 0.013508,
     "end_time": "2023-11-14T15:04:39.808301",
     "exception": false,
     "start_time": "2023-11-14T15:04:39.794793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e6c85",
   "metadata": {
    "papermill": {
     "duration": 0.013731,
     "end_time": "2023-11-14T15:04:39.835856",
     "exception": false,
     "start_time": "2023-11-14T15:04:39.822125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 512.699896,
   "end_time": "2023-11-14T15:04:41.475793",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-14T14:56:08.775897",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
