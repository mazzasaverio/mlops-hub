/home/sam/github/my-ml-training-platform
├── config
│   └── train_config.yaml
├── custom_tree_and_files_corrected.txt
├── data
│   ├── processed
│   │   └── synthetic_ticker_data.csv
│   └── raw
├── .env
├── .gitignore
├── LICENSE
├── mlops
│   ├── deployment
│   ├── environment.yml
│   ├── experiments
│   │   ├── mlflow_optuna_init.py
│   │   └── optuna_objective.py
│   ├── main.py
│   ├── requirements.txt
│   ├── .trash
│   ├── utils.py
│   └── validation
│       ├── cv_setup.py
│       └── model_validation.py
└── README.md

10 directories, 15 files


=== Content of /home/sam/github/my-ml-training-platform/config/train_config.yaml ===

xgboost:
  learning_rate: 0.1
  max_depth: 6
  n_estimators: 100

random_forest:
  n_estimators: 100
  max_depth: None
  min_samples_split: 2

validation_method: 'comb_purged_kfold'  # Can be 'kfold', 'stratified_kfold', or 'comb_purged_kfold'




=== Content of /home/sam/github/my-ml-training-platform/mlops/main.py ===

# main.py
from utils import load_config, load_dataset
from experiments.mlflow_optuna_init import initialize_mlflow, initialize_optuna
from validation.cv_setup import initialize_cv_method
from experiments.optuna_objective import objective
from utils import prepare_features_and_target
import os
from dotenv import load_dotenv
import warnings
# Suppress warnings
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

# Load environment variables
load_dotenv()
# Load configurations and datasets
config_path = os.path.join(os.getenv('ROOT_PATH'), 'config/train_config.yaml')
config = load_config(config_path)

dataset_path = os.path.join(os.getenv('ROOT_PATH'), 'data/processed/synthetic_ticker_data.csv')
df_train = load_dataset(dataset_path)

print(config_path)
print(dataset_path)
# Prepare features and target
X, y = prepare_features_and_target(df_train)  # Assuming you have this function


# Initialize MLFlow and Optuna
path_experiments_storage = os.path.join(os.getenv('ROOT_PATH', 'default/path/to/config'), 'data/experiments_storage')
print(path_experiments_storage)
initialize_mlflow(path_experiments_storage, config)
study = initialize_optuna(path_experiments_storage, config)
print("SONO QUI")
# Initialize Cross-Validation
splits = initialize_cv_method(config['validation_method'], X, y)

# Optuna Study
study.optimize(lambda trial: objective(trial, splits, X, y), n_trials=config.get('n_trials', 3))


=== Content of /home/sam/github/my-ml-training-platform/mlops/utils.py ===

# utils.py
import os
import sys
import yaml
import pandas as pd

def load_config(path: str) -> dict:
    try:
        with open(path, 'r') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        print(f"Configuration file {path} not found. Exiting.")
        sys.exit()

def load_dataset(path: str) -> pd.DataFrame:
    try:
        return pd.read_csv(path)
    except FileNotFoundError:
        print(f"Data file {path} not found. Exiting.")
        sys.exit()




def prepare_features_and_target(df_train: pd.DataFrame) -> (pd.DataFrame, pd.Series):
    cols_feat = [c for c in df_train.columns if c not in ['datetime', 'target', 'ticker']]
    X = df_train[cols_feat]
    y = df_train['target']
    y = y.map({-1: 0, 0: 1, 1: 2})
    return X, y

=== Content of /home/sam/github/my-ml-training-platform/mlops/validation/model_validation.py ===

Code present but not reported for space reasons

=== Content of /home/sam/github/my-ml-training-platform/mlops/validation/cv_setup.py ===

# cv_setup.py
import sys
from sklearn.model_selection import KFold, StratifiedKFold
from validation.model_validation import CombPurgedKFoldCV
import pandas as pd

def initialize_cv_method(cv_method: str, X: pd.DataFrame, y: pd.Series, n_splits=5, n_test_splits=1, embargo_td=2):
    splits = []
    if cv_method == 'comb_purged_kfold':
        cv = CombPurgedKFoldCV(n_splits=n_splits, n_test_splits=n_test_splits, embargo_td=embargo_td)
        t1_ = X.index  # Assuming X is your feature DataFrame
        t1 = pd.Series(t1_).shift(100).fillna(0).astype(int)
        t2 = pd.Series(t1_).shift(-100).fillna(1e12).astype(int)
        splits = list(cv.split(X, pred_times=t1, eval_times=t2))
    elif cv_method == 'kfold':
        cv = KFold(n_splits=n_splits)
        splits = list(cv.split(X))
    elif cv_method == 'stratified_kfold':
        cv = StratifiedKFold(n_splits=n_splits)
        splits = list(cv.split(X, y))  # Assuming y is your target variable
    else:
        raise ValueError(f"Invalid cross-validation method: {cv_method}.")
    
    return splits





=== Content of /home/sam/github/my-ml-training-platform/mlops/experiments/optuna_objective.py ===

import mlflow
from xgboost import XGBClassifier

# Objective function for Optuna optimization
def objective(trial, splits, X, y):
    with mlflow.start_run() as run:
        n_estimators = trial.suggest_int("n_estimators", 50, 200)
        max_depth = trial.suggest_int("max_depth", 2, 32, log=True)
        
        model = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth)
        
        cv_scores = []
        for train_index, test_index in splits:
            X_train, X_test = X.iloc[train_index], X.iloc[test_index]
            y_train, y_test = y.iloc[train_index], y.iloc[test_index]
            
            model.fit(X_train, y_train)
            score = model.score(X_test, y_test)
            cv_scores.append(score)
        
        avg_score = sum(cv_scores) / len(cv_scores)
        
        mlflow.log_params({'n_estimators': n_estimators, 'max_depth': max_depth})
        mlflow.log_metric('cv_score', avg_score)
        
        return avg_score

=== Content of /home/sam/github/my-ml-training-platform/mlops/experiments/mlflow_optuna_init.py ===

# mlflow_optuna_init.py
import mlflow
import optuna

def initialize_mlflow(path:str, config: dict):

    mlflow.set_tracking_uri(path)
    mlflow.set_experiment(config.get('experiment_name', 'Default_Experiment'))

def initialize_optuna(path:str, config: dict):

    try:
        study = optuna.create_study(
            study_name=config.get('study_name', 'Default_Study_Name'),
            storage=f"sqlite:///{path}/optuna.db",
            direction="maximize",
            load_if_exists=True
        )
        return study
    except Exception as e:
        print(f"Could not initialize Optuna study. Error: {e}")


=== Content of /home/sam/github/my-ml-training-platform/mlops/remove/train_model.py ===

import os
import sys
import yaml
import warnings
import pandas as pd
import mlflow
import optuna
from sklearn.model_selection import KFold, StratifiedKFold
from xgboost import XGBClassifier
from dotenv import load_dotenv
from mlops.validation.model_validation import CombPurgedKFoldCV

# Suppress warnings
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

# Load environment variables
load_dotenv()

def load_config(path: str) -> dict:
    try:
        with open(path, 'r') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        print(f"Configuration file {path} not found. Exiting.")
        sys.exit()

def load_dataset(path: str) -> pd.DataFrame:
    try:
        return pd.read_csv(path)
    except FileNotFoundError:
        print(f"Data file {path} not found. Exiting.")
        sys.exit()

def ensure_directory_exists(directory: str):
    if not os.path.exists(directory):
        os.makedirs(directory)
        print(f"Directory {directory} created.")
    else:
        print(f"Directory {directory} already exists.")

config_path = os.path.join(os.getenv('CONFIG_PATH', 'default/path/to/config'), 'config/train_config.yaml')
config = load_config(config_path)

# Ensure directory exists
path_experiments_storage = config['path_experiments_storage']
ensure_directory_exists(path_experiments_storage)

# Initialize MLflow and Optuna
mlflow_artifact_location = os.path.join(path_experiments_storage, "mlruns")
mlflow.set_tracking_uri(mlflow_artifact_location)
mlflow.set_experiment(config.get('experiment_name', 'Default_Experiment'))

try:
    db_path = os.path.join(path_experiments_storage, "optuna.db")
    study = optuna.create_study(
        study_name=config.get('study_name', 'Default_Study_Name'),
        storage=f"sqlite:///{db_path}",
        direction="maximize",
        load_if_exists=True
    )
    print("Optuna study created.")
except Exception as e:
    print(f"Could not initialize Optuna study. Error: {e}")

# Load and prepare dataset
dataset_path = config.get('dataset_path', '/default/path/to/dataset.csv')
df_train = load_dataset(dataset_path)
cols_feat = [c for c in df_train.columns if c not in ['datetime', 'target', 'ticker']]
X = df_train[cols_feat]
y = df_train['target']

# Re-map target values
y = y.map({-1: 0, 0: 1, 1: 2})

# Initialize Cross-Validation
cv_method = config.get('validation_method', 'kfold')
splits = []

if cv_method == 'comb_purged_kfold':
    cv = CombPurgedKFoldCV(n_splits=3, n_test_splits=1, embargo_td=2)
    t1_ = df_train.index
    t1 = pd.Series(t1_).shift(100).fillna(0).astype(int)
    t2 = pd.Series(t1_).shift(-100).fillna(1e12).astype(int)
    splits = list(cv.split(df_train, pred_times=t1, eval_times=t2))
elif cv_method == 'kfold':
    cv = KFold(n_splits=5)
elif cv_method == 'stratified_kfold':
    cv = StratifiedKFold(n_splits=5)
else:
    print(f"Invalid cross-validation method: {cv_method}. Exiting.")
    sys.exit()

# Objective function for Optuna optimization
def objective(trial):
    with mlflow.start_run() as run:
        n_estimators = trial.suggest_int("n_estimators", 50, 200)
        max_depth = trial.suggest_int("max_depth", 2, 32, log=True)
        
        model = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth)
        
        cv_scores = []
        for train_index, test_index in splits:
            X_train, X_test = X.iloc[train_index], X.iloc[test_index]
            y_train, y_test = y.iloc[train_index], y.iloc[test_index]
            
            model.fit(X_train, y_train)
            score = model.score(X_test, y_test)
            cv_scores.append(score)
        
        avg_score = sum(cv_scores) / len(cv_scores)
        
        mlflow.log_params({'n_estimators': n_estimators, 'max_depth': max_depth})
        mlflow.log_metric('cv_score', avg_score)
        
        return avg_score

# Optimize
study.optimize(objective, n_trials=config.get('n_trials', 10))

# Save the best parameters
best_params = study.best_params
with open("../config/best_params.yaml", 'w') as f:
    yaml.dump(best_params, f)
