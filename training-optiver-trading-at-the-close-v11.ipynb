{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":512.699896,"end_time":"2023-11-14T15:04:41.475793","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-11-14T14:56:08.775897","version":"2.4.0"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57891,"databundleVersionId":7056235,"sourceType":"competition"},{"sourceId":6993423,"sourceType":"datasetVersion","datasetId":4019630},{"sourceId":150406473,"sourceType":"kernelVersion"},{"sourceId":150406565,"sourceType":"kernelVersion"},{"sourceId":150406696,"sourceType":"kernelVersion"},{"sourceId":150407056,"sourceType":"kernelVersion"},{"sourceId":150412552,"sourceType":"kernelVersion"},{"sourceId":150429530,"sourceType":"kernelVersion"},{"sourceId":151165317,"sourceType":"kernelVersion"},{"sourceId":151165495,"sourceType":"kernelVersion"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Constants and Configuration Variables\nDEBUG = False\nTRAIN = True\nTUNING = True\nOVERWRITE_PROCESSED_DATA = True\nN_TRIALS = 10\nSTATE = 42\nN_FOLD_BREAK = 0\n\nGPU_SWITCH = \"ON\"\nN_SPLITS = 5\nN_TEST_SPLITS = 1\nN_PURGE = 11\nN_EMBARGO = 11\n\nSAVE_MODELS = False\n\nVERSION_NB = 19\nEXPERIMENT_PURPOSE = \"optiver_trading_at_the_close\"\n\nmodel_params_dict = {\n    \"LGBMR\": {\n        \"static_params\": {\n            \"device\": \"gpu\" if GPU_SWITCH == \"ON\" else \"cpu\",\n            \"objective\": \"mae\",\n            \"boosting_type\": \"gbdt\",\n            \"random_state\": STATE,\n            \"n_jobs\": 4,\n            \"verbose\": -1,\n            \"importance_type\": \"gain\"\n        },\n        \"dynamic_params\": {\n            \"n_estimators\": {\n                \"type\": \"int\",\n                \"low\": 450,\n                \"high\": 550,\n            },\n            \"learning_rate\": {\n                \"type\": \"float\",\n                \"low\": 0.009,\n                \"high\": 0.0154,\n            },\n            \"max_depth\": {\"type\": \"int\", \"low\": 11, \"high\": 17},\n            \"num_leaves\": {\n                \"type\": \"int\",\n                \"low\": 180,\n                \"high\": 290,\n            },\n            \"min_child_samples\": {\n                \"type\": \"int\",\n                \"low\": 18,\n                \"high\": 29,\n            },\n            \"subsample\": {\n                \"type\": \"float\",\n                \"low\": 1,\n                \"high\": 1,\n            },\n            \"colsample_bytree\": {\n                \"type\": \"float\",\n                \"low\": 1,\n                \"high\": 1,\n            },\n        },\n    },\n}\n\n# RECORD ENSAMBLE MODEL\nmodel_paths = [\n    \"s3://mlflow-v1/kaggle_optiver_trading_at_the_close/15d253a7751b414fbc8ec5a78c81e24c/artifacts/LGBMR_0_20231118_044309/model.pkl\",\n    \"s3://mlflow-v1/kaggle_optiver_trading_at_the_close/8a881129db7c45e9bd92094cd1097297/artifacts/LGBMR_0_20231118_044743/model.pkl\",\n    \"s3://mlflow-v1/kaggle_optiver_trading_at_the_close/9e402e7a59be460897bf7cee58fc85c5/artifacts/LGBMR_0_20231118_045214/model.pkl\",\n    \"s3://mlflow-v1/kaggle_optiver_trading_at_the_close/1ffb209c2fe2420db01bb4df17d86f1d/artifacts/LGBMR_0_20231118_045642/model.pkl\",\n    \"s3://mlflow-v1/kaggle_optiver_trading_at_the_close/562d3c3b41c74c9a90e080b88eb5af3a/artifacts/LGBMR_0_20231118_050108/model.pkl\",\n]\n\n# Define the model name for registration in MLflow\n\nversion = 9\nmodel_name = f\"ensemble_model ({version})\"\nfolder_model = f\"models-v{version}\"","metadata":{"papermill":{"duration":6.524524,"end_time":"2023-11-14T14:56:18.932693","exception":false,"start_time":"2023-11-14T14:56:12.408169","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# External general-purpose modules\nimport gc\nimport sys\nimport os\nimport itertools as itt\nfrom itertools import combinations, product\nfrom datetime import datetime\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport joblib\nimport time\n\nfrom pathlib import Path\nimport warnings\nfrom numba import njit, prange\nimport boto3\nfrom botocore.exceptions import NoCredentialsError\nfrom dotenv import load_dotenv\n\n\n# Setting pandas options and warning filters\npd.set_option(\"display.max_columns\", None)\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n\n# Load environment variables\nload_dotenv()\npath_root_project = Path.cwd()\nif path_root_project.name not in [\"working\", \"content\"]:\n    path_root_project = Path(os.getenv(\"ROOT_PATH\") or path_root_project)\n\n    directories_to_add = [\"utils\", \"feat_engineering\", \"validation\"]\n    for directory in directories_to_add:\n        sys.path.append(str(path_root_project / \"src\" / directory))\n\n\nfrom utils_training import create_model, experiments_data\nfrom utils_data import load_config, load_dataset, reduce_mem_usage, PathManager\nfrom utils_kaggle import (\n    setup_kaggle,\n    download_data,\n    get_data,\n    clean_directory_except_one,\n)\n\nfrom fe_optiver_trading_at_the_close import (\n    calculate_triplet_imbalance_numba,\n    convert_weights_to_dict,\n    global_stock_id_feats,\n    compute_rolling_averages,\n    generate_rsi,\n)\n\npm = PathManager(path_root_project)\n\nif TRAIN:\n    if pm.path_root_project.name == \"working\":\n        from kaggle_secrets import UserSecretsClient\n\n        user_secrets = UserSecretsClient()\n        aws_access_key_id = user_secrets.get_secret(\"AWS_ACCESS_KEY_ID\")\n        aws_region = user_secrets.get_secret(\"AWS_DEFAULT_REGION\")\n        aws_secret_access_key = user_secrets.get_secret(\"AWS_SECRET_ACCESS_KEY\")\n        s3_bucket_name = user_secrets.get_secret(\"S3_BUCKET\")\n\n        # Set AWS credentials in the environment variables\n        os.environ[\"AWS_ACCESS_KEY_ID\"] = aws_access_key_id\n        os.environ[\"AWS_SECRET_ACCESS_KEY\"] = aws_secret_access_key\n        os.environ[\"AWS_DEFAULT_REGION\"] = aws_region\n    else:\n        aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n        aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")","metadata":{"papermill":{"duration":2.108409,"end_time":"2023-11-14T14:56:21.135276","exception":false,"start_time":"2023-11-14T14:56:19.026867","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_prod = joblib.load(f'/kaggle/input/{folder_model}/{model_name}.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_feat = pd.read_csv(\"/kaggle/working/feat_impor_optiver_trading_at_the_close_23_11_18_0438.csv\").sort_values(\"t0_imp_fold_1\")","metadata":{"papermill":{"duration":0.022293,"end_time":"2023-11-14T14:56:21.250975","exception":false,"start_time":"2023-11-14T14:56:21.228682","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def aggregate_feature_importance(df_feat_importance):\n    df_feat_importance[\"feat_imp_mean\"] = df_feat_importance.loc[\n        :, df_feat_importance.columns != \"feat\"\n    ].mean(axis=1, skipna=True)\n\n\n\n    df_feat_importance.sort_values('feat_imp_mean', inplace = True, ascending = False)\n    df_feat_importance.reset_index(drop =  True, inplace = True)\n\n\n\n    cols  = [col for col in  df_feat_importance.columns if col not in  [\"feat\",\"feat_imp_mean\"]]\n\n\n    df_feat_importance[\"feat_imp_std\"] = df_feat_importance.loc[\n            :,cols\n        ].std(axis=1, skipna=True)\n\n    df_feat_importance['feat_imp_variability'] =  df_feat_importance['feat_imp_std'] /df_feat_importance['feat_imp_mean'] \n\n    return df_feat_importance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Conditional imports and settings based on TRAIN constant\nif TRAIN:\n    if pm.path_root_project.name == \"working\":\n        !pip install loguru mlflow optuna > /dev/null\n\n    \n\n    from utils_mlflow import (\n        get_experiments_df,\n        delete_runs_and_artifacts,\n        download_and_load_model,\n        load_models_and_create_ensemble,\n        save_and_register_model,\n        log_model_parameters,\n        get_or_create_experiment,\n        experiments_data,\n    )\n    from utils_feat_importance import log_feature_importance, aggregate_feature_importance\n    from model_validation import time_series_split\n\n    # External Libraries\n    import boto3\n    from botocore.exceptions import NoCredentialsError\n    from mlflow.exceptions import MlflowException\n    import lightgbm as lgbm\n    import mlflow\n    import optuna\n    from mlflow.tracking import MlflowClient\n    from optuna.integration.mlflow import MLflowCallback\n    from sklearn.model_selection import KFold\n    from xgboost import XGBRegressor as XGBR\n    from lightgbm import log_evaluation, early_stopping, LGBMRegressor as LGBMR\n\n\n\n    # Auto-reload modules - Specific to Jupyter Notebooks\n    %load_ext autoreload\n    %autoreload 2\n    if not DEBUG:\n        mlflow.set_tracking_uri(pm.path_experiments_dir)\n        \n    client = MlflowClient()\n    \n    # Create an S3 client\n    s3 = boto3.client(\n        \"s3\",\n        aws_access_key_id=aws_access_key_id,\n        aws_secret_access_key=aws_secret_access_key,\n    )","metadata":{"papermill":{"duration":0.035618,"end_time":"2023-11-14T14:56:21.300299","exception":false,"start_time":"2023-11-14T14:56:21.264681","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if SAVE_MODELS:\n     s3 = boto3.client(\n         \"s3\",\n         aws_access_key_id=aws_access_key_id,\n         aws_secret_access_key=aws_secret_access_key,\n     )\n     # Load the models and create an ensemble\n     ensemble_model = load_models_and_create_ensemble(s3, model_paths)\n\n     # Save and register the ensemble model in MLflow\n     save_and_register_model(ensemble_model, model_name)","metadata":{"papermill":{"duration":0.021792,"end_time":"2023-11-14T14:56:21.335759","exception":false,"start_time":"2023-11-14T14:56:21.313967","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.013331,"end_time":"2023-11-14T14:56:21.362906","exception":false,"start_time":"2023-11-14T14:56:21.349575","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    if not os.path.exists(pm.path_dataset_processed) or OVERWRITE_PROCESSED_DATA:\n        df_train_raw = pd.read_csv(pm.path_data_train_raw)\n\n        if DEBUG:\n            df_train_raw = df_train_raw[df_train_raw[\"stock_id\"].isin([0, 1, 2, 3, 4])]\n\n        drop_idx = df_train_raw.loc[\n            df_train_raw[\"target\"].isna(), \"target\"\n        ].index.to_list()\n        df_train = df_train_raw.drop(drop_idx, axis=0)\n        df_train.reset_index(drop=True, inplace=True)\n    else:\n        df_train = pd.read_csv(pm.path_dataset_processed)\n        if DEBUG:\n            df_train = df_train[df_train[\"stock_id\"].isin([0, 1, 2, 3, 4])]\n\n    df_train.sort_values([\"time_id\", \"stock_id\"], inplace=True)","metadata":{"papermill":{"duration":0.02474,"end_time":"2023-11-14T14:56:21.401516","exception":false,"start_time":"2023-11-14T14:56:21.376776","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    dict_global_stock_id_feats = global_stock_id_feats(df_train)","metadata":{"papermill":{"duration":0.02096,"end_time":"2023-11-14T14:56:21.435912","exception":false,"start_time":"2023-11-14T14:56:21.414952","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@njit(parallel=True)\ndef calculate_macd(data, short_window=12, long_window=26, signal_window=9):\n    rows, cols = data.shape\n    macd_values = np.empty((rows, cols))\n    signal_line_values = np.empty((rows, cols))\n    histogram_values = np.empty((rows, cols))\n\n    for i in prange(cols):\n        short_ema = np.zeros(rows)\n        long_ema = np.zeros(rows)\n\n        for j in range(1, rows):\n            short_ema[j] = (data[j, i] - short_ema[j - 1]) * (2 / (short_window + 1)) + short_ema[j - 1]\n            long_ema[j] = (data[j, i] - long_ema[j - 1]) * (2 / (long_window + 1)) + long_ema[j - 1]\n\n        macd_values[:, i] = short_ema - long_ema\n\n        signal_line = np.zeros(rows)\n        for j in range(1, rows):\n            signal_line[j] = (macd_values[j, i] - signal_line[j - 1]) * (2 / (signal_window + 1)) + signal_line[j - 1]\n\n        signal_line_values[:, i] = signal_line\n        histogram_values[:, i] = macd_values[:, i] - signal_line\n\n    return macd_values, signal_line_values, histogram_values\n\n\ndef generate_macd(df):\n    # Define lists of price and size-related column names\n    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n    \n    for stock_id, values in df.groupby(['stock_id'])[prices]:\n        macd_values, signal_line_values, histogram_values = calculate_macd(values.values)\n        col_macd = [f'macd_{col}' for col in values.columns]\n        col_signal = [f'macd_sig_{col}' for col in values.columns]\n        col_hist = [f'macd_hist_{col}' for col in values.columns]\n        \n        df.loc[values.index, col_macd] = macd_values\n        df.loc[values.index, col_signal] = signal_line_values\n        df.loc[values.index, col_hist] = histogram_values\n    \n    return df\n\ndef generate_rsi(df):\n    # Define lists of price and size-related column names\n    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n    \n    for stock_id, values in df.groupby(['stock_id'])[prices]:\n        columns = [f'rsi_{col}' for col in values.columns]\n        data = calculate_rsi(values.values)\n        df.loc[values.index, columns] = data\n    \n    return df\n\n\n\n@njit(parallel = True)\ndef calculate_rsi(prices, period=14):\n    rsi_values = np.zeros_like(prices)\n\n    for col in prange(prices.shape[1]):\n        price_data = prices[:, col]\n        delta = np.zeros_like(price_data)\n        delta[1:] = price_data[1:] - price_data[:-1]\n        gain = np.where(delta > 0, delta, 0)\n        loss = np.where(delta < 0, -delta, 0)\n\n        avg_gain = np.mean(gain[:period])\n        avg_loss = np.mean(loss[:period])\n        \n        if avg_loss != 0:\n            rs = avg_gain / avg_loss\n        else:\n            rs = 1e-9  # or any other appropriate default value\n            \n        rsi_values[:period, col] = 100 - (100 / (1 + rs))\n\n        for i in prange(period-1, len(price_data)-1):\n            avg_gain = (avg_gain * (period - 1) + gain[i]) / period\n            avg_loss = (avg_loss * (period - 1) + loss[i]) / period\n            if avg_loss != 0:\n                rs = avg_gain / avg_loss\n            else:\n                rs = 1e-9  # or any other appropriate default value\n            rsi_values[i+1, col] = 100 - (100 / (1 + rs))\n\n    return rsi_values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imbalance_features(df):\n    # Define lists of price and size-related column names\n    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n    df[\"volume\"] = df.eval(\"ask_size + bid_size\")\n    df[\"mid_price\"] = df.eval(\"(ask_price + bid_price) / 2\")\n    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n    df[\"matched_imbalance\"] = df.eval(\"(imbalance_size-matched_size)/(matched_size+imbalance_size)\")\n    df[\"size_imbalance\"] = df.eval(\"bid_size / ask_size\")\n\n    for c in combinations(prices, 2):\n        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\")\n\n    for c in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n        df[triplet_feature.columns] = triplet_feature.values\n   \n    df[\"imbalance_momentum\"] = df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / df['matched_size']\n    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n    df[\"spread_intensity\"] = df.groupby(['stock_id'])['price_spread'].diff()\n    df['price_pressure'] = df['imbalance_size'] * (df['ask_price'] - df['bid_price'])\n    df['market_urgency'] = df['price_spread'] * df['liquidity_imbalance']\n    df['depth_pressure'] = (df['ask_size'] - df['bid_size']) * (df['far_price'] - df['near_price'])\n    \n    # Calculate various statistical aggregation features\n    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n        \n\n    for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n        for window in [1, 2, 3, 10]:\n            df[f\"{col}_shift_{window}\"] = df.groupby('stock_id')[col].shift(window)\n            df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window)\n    \n    # Calculate diff features for specific columns\n    for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size', 'market_urgency', 'imbalance_momentum', 'size_imbalance']:\n        for window in [1, 2, 3, 10]:\n            df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window)\n\n    return df.replace([np.inf, -np.inf], 0)\n\ndef other_features(df):\n    df[\"dow\"] = df[\"date_id\"] % 5  # Day of the week\n    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  \n    for key, value in dict_global_stock_id_feats.items():\n        df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n\n    return df\n\ndef feat_engineering(df):\n    # Select relevant columns for feature generation\n    cols = [c for c in df.columns if c not in [\"row_id\"]]\n    df = df[cols]\n    \n    # Generate imbalance features\n    df = imbalance_features(df)\n    df = other_features(df)\n    \n    \n    gc.collect()  \n    df = generate_rsi(df)\n    df = generate_macd(df)\n    \n    list_cols = [i for i in df.columns if i not in [\"row_id\"]]\n    \n    return df[list_cols]\n\n","metadata":{"papermill":{"duration":0.049258,"end_time":"2023-11-14T14:56:21.898846","exception":false,"start_time":"2023-11-14T14:56:21.849588","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    df_train_feats = feat_engineering(df_train)\n    print(\"Build Online Train Feats Finished.\")\n\n    df_train_feats = reduce_mem_usage(df_train_feats)","metadata":{"papermill":{"duration":0.022316,"end_time":"2023-11-14T14:56:21.934972","exception":false,"start_time":"2023-11-14T14:56:21.912656","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    col_split = \"time_id\"\n    df_train_feats.sort_values([col_split], inplace=True)\n\n    df_train_feats[\"factorized\"] = pd.factorize(df_train_feats[col_split])[0]\n\n    df_train_feats.sort_values([\"time_id\", \"stock_id\"], inplace=True)\n    list_cols_drop = [\"date_id\", \"time_id\"]\n\n    df_train_feats.reset_index(drop=True, inplace=True)\n    df_train_feats.drop(list_cols_drop, axis=1, inplace=True)","metadata":{"papermill":{"duration":0.023188,"end_time":"2023-11-14T14:56:21.971602","exception":false,"start_time":"2023-11-14T14:56:21.948414","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.013082,"end_time":"2023-11-14T14:56:22.051720","exception":false,"start_time":"2023-11-14T14:56:22.038638","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    experiment_name = f\"{EXPERIMENT_PURPOSE}_v{VERSION_NB}\"\n    name_folder_models = f\"models_v{VERSION_NB}\"\n\n    experiment_date_str = datetime.now().strftime(\"%y_%m_%d_%H%M\")\n\n    if DEBUG:\n        experiment_name = f\"{experiment_name}_debug\"\n        name_folder_models = f\"{name_folder_models}_debug\"\n        path_artifact_location = \".\"\n    else:\n        path_artifact_location = pm.path_artifact_location\n\n    experiment_id = get_or_create_experiment(\n        client, experiment_name, artifact_location=path_artifact_location\n    )\n\n    nbrnd_erly_stp = 130\n    cv_mthd = \"KF\"\n\n    mlflow_callback = MLflowCallback(\n        tracking_uri=mlflow.get_tracking_uri(), metric_name=\"mae\"\n    )\n\n    all_cv = {\"KF\": KFold(n_splits=5, shuffle=True, random_state=STATE)}\n    cv = all_cv[cv_mthd]\n\n    dict_models = {\"LGBMR\": LGBMR}\n\n    log_model = True\n\n    args = {\n        \"cv_mthd\": cv_mthd,\n        \"experiment_purpose\": EXPERIMENT_PURPOSE,\n        \"experiment_name\": experiment_name,\n        \"dict_models\": dict_models,\n        \"model_params_dict\": model_params_dict,\n        \"n_splits\": N_SPLITS,\n        \"n_test_splits\": N_TEST_SPLITS,\n        \"n_purge\": N_PURGE,\n        \"n_embargo\": N_EMBARGO,\n        \"experiment_date_str\": experiment_date_str,\n        \"path_artifact_location\": pm.path_artifact_location,\n        \"target_col\": \"target\",\n    }","metadata":{"papermill":{"duration":0.032117,"end_time":"2023-11-14T14:56:22.097275","exception":false,"start_time":"2023-11-14T14:56:22.065158","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.013498,"end_time":"2023-11-14T14:56:22.125143","exception":false,"start_time":"2023-11-14T14:56:22.111645","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_mlflow_experiment(df_train, args, trial=None):\n    cv_mthd = args[\"cv_mthd\"]\n    experiment_purpose = args[\"experiment_purpose\"]\n    experiment_name = args[\"experiment_name\"]\n    dict_models = args[\"dict_models\"]\n    model_params_dict = args[\"model_params_dict\"]\n\n    n_splits = args[\"n_splits\"]\n    n_test_splits = args[\"n_test_splits\"]\n    n_purge = args[\"n_purge\"]\n    n_embargo = args[\"n_embargo\"]\n\n    experiment_date_str = args[\"experiment_date_str\"]\n    path_artifact_location = args[\"path_artifact_location\"]\n    target_col = args[\"target_col\"]\n\n    if trial == None:\n        trial = optuna.trial.FixedTrial(\n            {\n                \"n_estimators\": 500,\n                \"learning_rate\": 0.005,\n                \"max_depth\": 10,\n                \"num_leaves\": 20,\n                \"min_child_samples\": 10,\n                \"subsample\": 0.7,\n                \"colsample_bytree\": 1.0,\n                \"min_split_gain\": 0.0,\n                \"reg_alpha\": 0.0,\n                \"reg_lambda\": 0.0,\n                \"device\": \"gpu\" if GPU_SWITCH == \"ON\" else \"cpu\",\n            }\n        )\n\n    run_time_start_trial = datetime.now().strftime(\"%y_%m_%d_%H%M%S\")\n\n    with mlflow.start_run(\n        run_name=run_time_start_trial, experiment_id=experiment_id\n    ) as run:\n        score_list = []\n\n        # mlflow.set_tag(\"cv_mthd\", cv_mthd)\n        mlflow.set_tag(\"n_splits\", n_splits)\n        mlflow.set_tag(\"n_test_splits\", n_test_splits)\n        mlflow.set_tag(\"n_purge\", n_purge)\n        mlflow.set_tag(\"n_embargo\", n_embargo)\n\n        for model_name, model_class in dict_models.items():\n            if TUNING:\n                \n                model = create_model(\n                    trial,\n                    model_class,\n                    model_params_dict[model_name][\"static_params\"],\n                    model_params_dict[model_name][\"dynamic_params\"],\n                )\n            \n            else:\n                params = model_prod.get_params()\n                params[\"device\"] = \"gpu\" if GPU_SWITCH == \"ON\" else \"cpu\"\n\n                model = model_class(**params)\n\n            priority_params = [\"learning_rate\", \"max_depth\"]\n            excluded_params = [\n                \"device\",\n                \"class_weight\",\n                \"random_state\",\n                \"silent\",\n                \"verbose\",\n                \"n_jobs\",\n            ]\n\n            ordered_params = log_model_parameters(\n                model, priority_params, excluded_params, verbose=True\n            )\n\n            mlflow.log_params(ordered_params)\n\n            for fold_n, (train_indices, test_indices) in enumerate(\n                time_series_split(\n                    df_train,\n                    n_splits=n_splits,\n                    n_test_splits=n_test_splits,\n                    n_purge=n_purge,\n                    n_embargo=n_embargo,\n                )\n            ):\n                print(f\"X_train shape: {X_train.shape}\")\n                with mlflow.start_run(\n                    run_name=f\"fold_{fold_n+1}\",\n                    nested=True,\n                    experiment_id=experiment_id,\n                ) as nested_run:\n                    mlflow.set_tag(\"n_trial\", str(trial.number))\n\n                    mask_train = df_train[\"factorized\"].isin(train_indices)\n                    mask_test = df_train[\"factorized\"].isin(test_indices)\n\n                    y_train = df_train.loc[mask_train, target_col]\n                    y_val = df_train.loc[mask_test, target_col]\n                    X_train = df_train.loc[mask_train].drop(\n                        [target_col, \"factorized\"], axis=1\n                    )\n                    X_val = df_train.loc[mask_test].drop(\n                        [target_col, \"factorized\"], axis=1\n                    )\n\n                    mlflow.log_param(\"train_rows\", X_train.shape[0])\n                    mlflow.log_param(\"train_cols\", X_train.shape[1])\n\n                    model.fit(\n                        X_train,\n                        y_train,\n                        eval_set=[(X_val, y_val)],\n                        eval_metric=\"mae\",\n                        callbacks=[\n                            lgbm.callback.early_stopping(stopping_rounds=100),\n                            lgbm.callback.log_evaluation(period=100000),\n                        ],\n                    )\n\n                    log_feature_importance(\n                        trial.number,\n                        model,\n                        X_train,\n                        fold_n,\n                        experiment_purpose,\n                        experiment_date_str,\n                    )\n\n                    fold_score = model.best_score_[\"valid_0\"][\"l1\"]\n\n                    score_list.append(fold_score)\n\n                    mlflow.log_metric(\"fold_score\", round(fold_score, 6))\n                    mlflow.log_param(\"fold_number\", fold_n + 1)\n                    mlflow.log_param(\"model_name\", model_name)\n\n                    mlflow.log_params(ordered_params)\n\n                    current_time_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n                    model_log_name = f\"{model_name}_{trial.number}_{current_time_str}\"\n\n                    mlflow.sklearn.log_model(model, model_log_name)\n\n                    mlflow.log_param(\"run_time\", current_time_str)\n\n                    nested_run_id = nested_run.info.run_id\n                    model_path = f\"{path_artifact_location}/{run.info.experiment_id}/{nested_run_id}/artifacts/{model_log_name}/model.pkl\"\n                    mlflow.log_param(\"model_path\", model_path)\n\n                avg_score = sum(score_list) / len(score_list)\n                median_score = np.median(score_list)\n                mlflow.log_metric(\"avg score\", round(avg_score, 6))\n                mlflow.log_metric(\"median score\", round(median_score, 6))\n\n                if fold_n >= N_FOLD_BREAK:\n                    break\n\n        return avg_score\n\n\ndef objective(trial, df_train):\n    avg_score = run_mlflow_experiment(df_train, args, trial)\n    return avg_score\n\n\n# Run the Optuna study\nif TRAIN:\n    study = optuna.create_study(\n        direction=\"minimize\",\n        study_name=\"Your Study Name\",\n        load_if_exists=True,\n    )\n    study.optimize(lambda trial: objective(trial, df_train_feats), n_trials=N_TRIALS)","metadata":{"papermill":{"duration":0.045154,"end_time":"2023-11-14T14:56:22.184731","exception":false,"start_time":"2023-11-14T14:56:22.139577","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    df_exp = experiments_data(\n        client, list_experiment_id=None, save_df=None, list_columns=None\n    )\n    list_base_cols = [\n        \"run_time\",\n        \"experiment_id\",\n        \"n_trial\",\n        \"run_id\",\n        \"model_name\",\n        \"fold_number\",\n        \"fold_score\",\n    ]\n    list_dynamic_params = list(model_params_dict[\"LGBMR\"][\"dynamic_params\"].keys())\n\n    df_exp[\"run_time\"] = pd.to_datetime(\n        df_exp[\"run_time\"], format=\"%Y%m%d_%H%M%S\", errors=\"coerce\"\n    )\n\n    for col in df_exp.columns:\n        df_exp[col] = pd.to_numeric(df_exp[col], errors=\"ignore\")\n\n    for col in df_exp.select_dtypes(include=[\"float\", \"int\"]):\n        df_exp[col] = df_exp[col].round(5)\n\n    list_cols_exp = [\"run_time\"] + list_base_cols + list_dynamic_params + [\"model_path\"]\n\n    experiment_id\n    df_exp = df_exp[df_exp[\"experiment_id\"] != 0]\n\n    df_exp = df_exp[list_cols_exp]","metadata":{"_cell_guid":"51030a77-aba3-469f-9c08-7963bc8a09d2","_uuid":"6ff7d358-62f0-4ac9-b028-d1c920bb4eaf","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.026377,"end_time":"2023-11-14T14:56:22.224975","exception":false,"start_time":"2023-11-14T14:56:22.198598","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.012914,"end_time":"2023-11-14T14:56:22.278091","exception":false,"start_time":"2023-11-14T14:56:22.265177","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.013003,"end_time":"2023-11-14T14:56:22.304410","exception":false,"start_time":"2023-11-14T14:56:22.291407","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"d4bfb979-2758-4fe9-8947-399b1c3a574c","_uuid":"bef1a199-0988-4743-813e-99d4308fc9bb","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.042912,"end_time":"2023-11-14T14:56:22.361956","exception":false,"start_time":"2023-11-14T14:56:22.319044","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/optiver-trading-at-the-close/train.csv\")","metadata":{"papermill":{"duration":19.451534,"end_time":"2023-11-14T14:56:41.827800","exception":false,"start_time":"2023-11-14T14:56:22.376266","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_global_stock_id_feats = global_stock_id_feats(df_train)","metadata":{"papermill":{"duration":1.784748,"end_time":"2023-11-14T14:56:43.626460","exception":false,"start_time":"2023-11-14T14:56:41.841712","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"d30f3862-dca2-4242-9db0-ab9750118622","_uuid":"efd9073c-aaef-4135-bf7c-1e892e9aa831","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":476.139875,"end_time":"2023-11-14T15:04:39.780027","exception":false,"start_time":"2023-11-14T14:56:43.640152","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def zero_sum(prices, volumes):\n    std_error = np.sqrt(volumes)\n    step = np.sum(prices) / np.sum(std_error)\n    out = prices - std_error * step\n    return out\n\nimport optiver2023\nenv = optiver2023.make_env()\niter_test = env.iter_test()\ncounter = 0\ny_min, y_max = -64, 64\nqps, predictions = [], []\ncache = pd.DataFrame()\n\nfor (test, revealed_targets, sample_prediction) in iter_test:\n    now_time = time.time()\n    cache = pd.concat([cache, test], ignore_index=True, axis=0)\n    if counter > 0:\n        cache = cache.groupby(['stock_id']).tail(21).sort_values(by=['date_id', 'seconds_in_bucket', 'stock_id']).reset_index(drop=True)\n\n    feat = feat_engineering(cache)[-len(test):]\n\n    # added after new API, reference: https://www.kaggle.com/competitions/optiver-trading-at-the-close/discussion/455690#2526672\n    if test.currently_scored.iloc[0]== False:\n        sample_prediction['target'] = 0\n        env.predict(sample_prediction)\n        counter += 1\n        qps.append(time.time() - now_time)\n        if counter % 10 == 0:\n            print(counter, 'qps:', np.mean(qps))\n        continue\n\n    #feat = feat.drop(columns = [\"currently_scored\"])    \n    # end of new codes for new API\n\n    # Generate predictions for each model and calculate the weighted average\n\n    list_cols_drop = [\"date_id\"]\n    feat.drop(list_cols_drop, axis=1, inplace=True)\n\n    list_features = model_prod.models[0].feature_name_\n    feat = feat[list_features]\n    lgb_predictions = model_prod.predict(feat, \"mean\")\n\n\n    lgb_predictions = zero_sum(lgb_predictions, test['bid_size'] + test['ask_size'])\n    clipped_predictions = np.clip(lgb_predictions, y_min, y_max)\n    sample_prediction['target'] = clipped_predictions\n    env.predict(sample_prediction)\n    counter += 1\n    qps.append(time.time() - now_time)\n    if counter % 10 == 0:\n        print(counter, 'qps:', np.mean(qps))\n\ntime_cost = 1.146 * np.mean(qps)\nprint(f\"The code will take approximately {np.round(time_cost, 4)} hours to reason about\")","metadata":{"papermill":{"duration":0.013508,"end_time":"2023-11-14T15:04:39.808301","exception":false,"start_time":"2023-11-14T15:04:39.794793","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean_directory_except_one('/kaggle/working/','submission.csv')","metadata":{"papermill":{"duration":0.013731,"end_time":"2023-11-14T15:04:39.835856","exception":false,"start_time":"2023-11-14T15:04:39.822125","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}