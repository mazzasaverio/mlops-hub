{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":112.139146,"end_time":"2023-10-29T17:18:32.866665","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-10-29T17:16:40.727519","version":"2.4.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# Constants\nTRAIN = True\nOVERWRITE = False\nDEBUG = False\n\nN_TRIALS = 3\n\nVERSION_NB = 4\n\nstate = 42\n\ndownload_kaggle_data = False\n\n# External general-purpose modules\nimport os\nimport shutil\nimport warnings\nfrom datetime import datetime\nimport glob\nfrom itertools import combinations\nfrom warnings import simplefilter\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nfrom dotenv import load_dotenv\nfrom joblib import dump\nimport joblib\nimport os\n\n# Setting pandas options and warning filters\npd.set_option(\"display.max_columns\", None)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\")\nsimplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n\n# Load environment variables\nload_dotenv()","metadata":{"papermill":{"duration":0.660513,"end_time":"2023-10-29T17:16:44.604311","exception":false,"start_time":"2023-10-29T17:16:43.943798","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:09:51.781871Z","iopub.execute_input":"2023-11-01T21:09:51.782247Z","iopub.status.idle":"2023-11-01T21:09:54.254575Z","shell.execute_reply.started":"2023-11-01T21:09:51.782214Z","shell.execute_reply":"2023-11-01T21:09:54.253593Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"# Setting up the project directory path\npath_project_dir = os.getcwd()\nif path_project_dir not in [\"/kaggle/working\", \"/content\"]:\n    path_project_dir = os.getenv(\"ROOT_PATH\")\n\n# Imports and setup for training\nif TRAIN:\n    # Install packages and import logging libraries\n    if path_project_dir == '/kaggle/working':\n        !pip install loguru mlflow optuna > /dev/null\n        \n\n    from utils import log_feature_importance, create_model, log_training_details, aggregate_feature_importance,  get_data, clean_directory_except_one\n    \n    from loguru import logger\n    import mlflow\n    import optuna\n    from optuna.integration.mlflow import MLflowCallback\n    from mlflow.tracking import MlflowClient\n    import zipfile\n    \n    from tqdm import tqdm\n\n    # Import machine learning libraries\n    from lightgbm import log_evaluation, early_stopping, LGBMRegressor as LGBMR\n    from sklearn.model_selection import KFold\n    from xgboost import XGBRegressor as XGBR\n\n    # Set logging\n    logger.add(\"logs.log\", format=\"{time:YYYY-MM-DD HH:mm} | {level} | {message}\")\n    optuna.logging.set_verbosity(optuna.logging.WARNING)\n    warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning)\n    \n    # Auto-reload modules\n    %load_ext autoreload\n    %autoreload 2\n\n    # Initialize MLflow callback\n    mlflow_callback = MLflowCallback(\n        tracking_uri=mlflow.get_tracking_uri(), metric_name=\"mae\"\n    )","metadata":{"_cell_guid":"3bdaa15b-0b9e-4b3b-9c47-58e6b9b18b5e","_uuid":"206043b9-f1d5-4691-b03a-935f2177086d","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.032481,"end_time":"2023-10-29T17:16:44.649372","exception":false,"start_time":"2023-10-29T17:16:44.616891","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:09:54.256296Z","iopub.execute_input":"2023-11-01T21:09:54.256734Z","iopub.status.idle":"2023-11-01T21:10:17.659249Z","shell.execute_reply.started":"2023-11-01T21:09:54.256708Z","shell.execute_reply":"2023-11-01T21:10:17.658402Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"if path_project_dir == \"/kaggle/working\":\n    path_data_project_dir = \"/kaggle/input/optiver-trading-at-the-close\"\n    path_experiments_storage = os.path.join(path_project_dir, \"experiments_storage\")\n\n    path_dataset_train_raw = \"/kaggle/input/optiver-trading-at-the-close/train.csv\"\n    path_dataset_test_raw = (\n        \"/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv\"\n    )\n\n    path_dataset_processed = \"/kaggle/working/processed_data\"\n    path_dataset_train = os.path.join(path_dataset_processed, \"train.csv\")\n    path_dataset_test = os.path.join(path_dataset_processed, \"test.csv\")\n\nelse:\n    name_folder_data_project = \"kaggle_optiver_trading_at_the_close\"\n\n    path_data_dir = os.path.join(path_project_dir, \"data\")\n    path_dataset_train_raw = os.path.join(\n        path_data_dir, \"kaggle_optiver_trading_at_the_close/raw\", \"train.csv\"\n    )\n    path_dataset_processed = os.path.join(\n        path_data_dir, \"kaggle_optiver_trading_at_the_close/processed\"\n    )\n\n    path_data_project_dir = os.path.join(path_data_dir, name_folder_data_project)\n\n    path_config_dir = os.path.join(path_project_dir, \"config\")\n    path_config_train = os.path.join(path_config_dir, \"train_config.yaml\")\n\n    path_experiments_storage = os.path.join(\n        path_data_project_dir, \"experiments_storage\"\n    )\n\n    if download_kaggle_data:\n        dataset_name = \"ravi20076/optiver-memoryreduceddatasets\"\n        kaggle_json_path = os.path.join(path_project_dir, \"kaggle.json\")\n        get_data(\n            kaggle_json_path,\n            path_data_project_dir,\n            dataset_name=dataset_name,\n            specific_file=None,\n        )\n\n    file_name_df_train = \"train.csv\"\n    file_name_df_test = \"test.csv\"\n\n    path_dataset_train = os.path.join(path_data_project_dir, file_name_df_train)\n    path_dataset_test = os.path.join(path_data_project_dir, file_name_df_test)\n\nif TRAIN:\n    mlflow.set_tracking_uri(path_experiments_storage)\n    client = MlflowClient()","metadata":{"_cell_guid":"9765420b-f8ab-46ba-8b4c-e4487eb04b76","_uuid":"c4174134-1441-41f8-adbf-f03ad3f7d7dc","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.024352,"end_time":"2023-10-29T17:16:44.685842","exception":false,"start_time":"2023-10-29T17:16:44.661490","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:10:17.660476Z","iopub.execute_input":"2023-11-01T21:10:17.660777Z","iopub.status.idle":"2023-11-01T21:10:17.709540Z","shell.execute_reply.started":"2023-11-01T21:10:17.660751Z","shell.execute_reply":"2023-11-01T21:10:17.708629Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=0):\n    \"\"\"\n    Iterate through all numeric columns of a dataframe and modify the data type\n    to reduce memory usage.\n    \"\"\"\n\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if (col_type != object) and (col != \"target\"):\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float32)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float32)\n\n    if verbose:\n        logger.info(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n        end_mem = df.memory_usage().sum() / 1024**2\n        logger.info(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n        decrease = 100 * (start_mem - end_mem) / start_mem\n        logger.info(f\"Decreased by {decrease:.2f}%\")\n\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2023-11-01T21:10:17.711967Z","iopub.execute_input":"2023-11-01T21:10:17.712276Z","iopub.status.idle":"2023-11-01T21:10:17.763342Z","shell.execute_reply.started":"2023-11-01T21:10:17.712252Z","shell.execute_reply":"2023-11-01T21:10:17.762433Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    if not os.path.exists(path_dataset_processed):\n        os.makedirs(path_dataset_processed)\n\n    if not os.path.exists(path_dataset_train) or OVERWRITE:\n        df_train_raw = pd.read_csv(path_dataset_train_raw)\n        \n    else:\n        df_train_raw = pd.read_csv(path_dataset_train)\n\n    if DEBUG:\n        df_train_raw = df_train_raw[df_train_raw[\"stock_id\"].isin([0, 1, 2])]\n        \n","metadata":{"papermill":{"duration":0.021683,"end_time":"2023-10-29T17:16:44.743683","exception":false,"start_time":"2023-10-29T17:16:44.722000","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:10:17.764355Z","iopub.execute_input":"2023-11-01T21:10:17.764696Z","iopub.status.idle":"2023-11-01T21:10:36.948733Z","shell.execute_reply.started":"2023-11-01T21:10:17.764663Z","shell.execute_reply":"2023-11-01T21:10:36.947851Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    # Dropping rows with null targets:-\n    drop_idx = df_train_raw.loc[df_train_raw[\"target\"].isna(), \"target\"].index.to_list()\n    df_train_raw = df_train_raw.drop(drop_idx, axis=0)\n    df_train_raw.reset_index(drop=True, inplace=True)\n    df_train_raw = df_train_raw.drop([\"time_id\",\"row_id\"], axis = 1)","metadata":{"papermill":{"duration":0.020681,"end_time":"2023-10-29T17:16:44.777236","exception":false,"start_time":"2023-10-29T17:16:44.756555","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:10:36.949984Z","iopub.execute_input":"2023-11-01T21:10:36.950287Z","iopub.status.idle":"2023-11-01T21:10:37.957015Z","shell.execute_reply.started":"2023-11-01T21:10:36.950262Z","shell.execute_reply":"2023-11-01T21:10:37.956132Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def feat_engineering(df_train):\n    df = pl.DataFrame(df_train)\n    # 7. Handle Missing Values\n    df = df.with_columns(\n        [\n            pl.col(\"far_price\").fill_null(strategy=\"forward\").alias(\"far_price\"),\n            pl.col(\"near_price\").fill_null(strategy=\"forward\").alias(\"near_price\"),\n        ]\n    )\n    # Level 1 Features\n    level_one_features = [\n        (pl.col(\"imbalance_size\") / pl.col(\"matched_size\")).alias(\n            \"imbalance_to_matched_size\"\n        ),\n        (pl.col(\"imbalance_size\") * pl.col(\"imbalance_buy_sell_flag\")).alias(\n            \"imbalance_flag_to_size\"\n        ),\n        (pl.col(\"ask_price\") - pl.col(\"bid_price\")).alias(\"spread\"),\n        (pl.col(\"bid_size\") - pl.col(\"ask_size\")).alias(\"bid_ask_imbalance\"),\n        (pl.col(\"bid_size\") / pl.col(\"ask_size\")).alias(\"liquidity\"),\n      #  (pl.col(\"ask_size\") - pl.col(\"wap\")).alias(\"size_diff_ask_to_wap\"),\n        (pl.col(\"wap\") - pl.col(\"wap\").shift(1).over([\"stock_id\", \"date_id\"])).alias(\n            \"wap_velocity\"\n        ),\n        (\n            pl.col(\"wap\") / pl.col(\"wap\").shift(5).over([\"stock_id\", \"date_id\"]) - 1\n        ).alias(\"wap_momentum_5\"),\n        (\n            pl.col(\"wap\")\n            .std()\n            .over([\"stock_id\", \"date_id\"])\n            .alias(\"short_term_volatility\")\n        ),\n        (\n            (\n                pl.col(\"imbalance_size\")\n                / (pl.col(\"matched_size\") + pl.col(\"imbalance_size\"))\n            ).alias(\"price_impact\")\n        ),\n        (\n            (pl.col(\"bid_size\") - pl.col(\"ask_size\"))\n            / (pl.col(\"bid_size\") + pl.col(\"ask_size\"))\n        ).alias(\"order_imbalance_ratio\"),\n        (\n            (pl.col(\"ask_price\") - pl.col(\"bid_price\"))\n            / (pl.col(\"ask_price\") + pl.col(\"bid_price\"))\n        ).alias(\"price_skewness\"),\n        (pl.col(\"seconds_in_bucket\") / 600).alias(\"time_decay\"),\n    ]\n\n    # Level 2 Features\n    level_two_features = [\n        (\n            pl.col(\"wap_velocity\")\n            - pl.col(\"wap_velocity\").shift(1).over([\"stock_id\", \"date_id\"])\n        ).alias(\"wap_acceleration\"),\n        (\n            pl.col(\"short_term_volatility\").shift(1).over([\"stock_id\", \"date_id\"])\n            - pl.col(\"short_term_volatility\")\n        ).alias(\"volatility_rate_of_change\"),\n        (\n            (\n                pl.col(\"liquidity\")\n                - pl.col(\"liquidity\").shift(1).over([\"stock_id\", \"date_id\"])\n            )\n            / pl.col(\"liquidity\").shift(1).over([\"stock_id\", \"date_id\"])\n        ).alias(\"liquidity_ratio_change\"),\n        (\n            (\n                pl.col(\"order_imbalance_ratio\")\n                - pl.col(\"order_imbalance_ratio\").shift(1).over([\"stock_id\", \"date_id\"])\n            )\n            / pl.col(\"order_imbalance_ratio\").shift(1).over([\"stock_id\", \"date_id\"])\n        ).alias(\"order_imbalance_over_time\"),\n        (\n            (\n                pl.col(\"price_skewness\")\n                - pl.col(\"price_skewness\").shift(1).over([\"stock_id\", \"date_id\"])\n            )\n            / pl.col(\"price_skewness\").shift(1).over([\"stock_id\", \"date_id\"])\n        ).alias(\"price_skewness_rate_of_change\"),\n    ]\n\n    # Level 3 Features\n    level_three_aggregations = [\n        pl.col(\"wap\").mean().alias(\"avg_wap_by_market\"),\n        pl.col(\"near_price\").mean().alias(\"avg_near_price_by_market\"),\n        pl.col(\"matched_size\").mean().alias(\"avg_matched_size_by_market\"),\n        pl.col(\"imbalance_to_matched_size\")\n        .mean()\n        .alias(\"avg_imbalance_to_matched_size_by_market\"),\n        pl.col(\"spread\").mean().alias(\"avg_spread_by_market\"),\n        pl.col(\"liquidity\").mean().alias(\"avg_liquidity_by_market\"),\n        pl.col(\"short_term_volatility\").mean().alias(\"avg_market_volatility\"),\n        pl.col(\"order_imbalance_ratio\").mean().alias(\"avg_market_imbalance\"),\n        pl.col(\"liquidity\").mean().alias(\"avg_market_liquidity\"),\n        pl.col(\"price_impact\").mean().alias(\"avg_market_price_impact\"),\n        pl.col(\"price_skewness\").mean().alias(\"avg_market_price_skewness\"),\n    ]\n\n    # Adding all features and performing join operation\n    df = df.with_columns(level_one_features)\n    df = df.with_columns(level_two_features)\n    group_by_market = df.groupby([\"date_id\", \"seconds_in_bucket\"]).agg(\n        *level_three_aggregations\n    )\n    df = df.join(group_by_market, on=[\"date_id\", \"seconds_in_bucket\"], how=\"left\")\n\n    polynomial_and_interaction_features = [\n        (pl.col(\"seconds_in_bucket\") * pl.col(\"near_price\")).alias(\n            \"seconds_in_bucket_X_near_price\"\n        ),\n        (pl.col(\"matched_size\") * pl.col(\"near_price\")).alias(\n            \"matched_size_X_near_price\"\n        ),\n        (pl.col(\"near_price\") ** 2).alias(\"near_price_squared\"),\n        (pl.col(\"matched_size\") ** 2).alias(\"matched_size_squared\"),\n        (pl.col(\"seconds_in_bucket\") * pl.col(\"imbalance_flag_to_size\")).alias(\n            \"seconds_in_bucket_X_imbalance_flag_to_size\"\n        ),\n        (pl.col(\"seconds_in_bucket\") ** 2).alias(\"seconds_in_bucket_squared\"),\n        (pl.col(\"imbalance_flag_to_size\") ** 2).alias(\"imbalance_flag_to_size_squared\"),\n    ]\n\n    # Relative to Market Features\n    relative_to_market_features = [\n        (pl.col(\"wap\") / pl.col(\"avg_wap_by_market\")).alias(\"relative_wap_to_market\"),\n        (pl.col(\"near_price\") / pl.col(\"avg_near_price_by_market\")).alias(\n            \"relative_near_price_to_market\"\n        ),\n        (pl.col(\"matched_size\") / pl.col(\"avg_matched_size_by_market\")).alias(\n            \"relative_matched_size_to_market\"\n        ),\n        (\n            pl.col(\"imbalance_to_matched_size\")\n            / pl.col(\"avg_imbalance_to_matched_size_by_market\")\n        ).alias(\"relative_imbalance_to_matched_size_to_market\"),\n        (pl.col(\"spread\") / pl.col(\"avg_spread_by_market\")).alias(\n            \"relative_spread_to_market\"\n        ),\n        (pl.col(\"liquidity\") / pl.col(\"avg_liquidity_by_market\")).alias(\n            \"relative_liquidity_to_market\"\n        ),\n    ]\n\n    # Combine all Level 4 features and add them to the DataFrame\n    all_level_four_features = (\n        polynomial_and_interaction_features + relative_to_market_features\n    )\n    df = df.with_columns(all_level_four_features)\n\n    for window in [5, 10]:\n        rolling_group = df.group_by_rolling(\n            index_column=\"seconds_in_bucket\",\n            period=f\"{window}i\",  # 'i' denotes index count (integer)\n            by=[\"stock_id\", \"date_id\"],\n            closed=\"left\",  # Adjust as needed\n        )\n\n        # Apply to basic and new features\n        for col in [\n            \"wap\",\n            \"imbalance_size\",\n            \"bid_price\",\n            \"ask_price\",\n            \"relative_wap_to_market\",\n            \"wap_momentum_5\",\n        ]:\n            df = df.join(\n                rolling_group.agg(pl.col(col).mean().alias(f\"{col}_mean_{window}\")),\n                on=[\"stock_id\", \"date_id\", \"seconds_in_bucket\"],\n                how=\"left\",\n            )\n\n    low_importance_cols = [\n        \"wap_mean_5\",\n        #\"imbalance_buy_sell_flag\",\n        \"imbalance_flag_to_size_squared\",\n        \"imbalance_size_mean_5\",\n        \"bid_price_mean_5\",\n        \"ask_price_mean_5\",\n        \"wap_momentum_5_mean_5\",\n        \"relative_wap_to_market_mean_5\",\n        \"volatility_rate_of_change\",\n        \"avg_market_liquidity\",\n        \"seconds_in_bucket_squared\",\n        \"order_imbalance_over_time\"\n        # Add more columns as needed\n    ]\n\n    existing_cols = df.columns\n\n    # Drop columns only if they exist in DataFrame\n    cols_to_drop = [col for col in low_importance_cols if col in existing_cols]\n\n    \n    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n\n   \n    df = df.with_columns(\n        (pl.col(\"ask_size\") + pl.col(\"bid_size\")).alias(\"volume\")\n    )\n    df = df.with_columns(\n        ((pl.col(\"ask_price\") + pl.col(\"bid_price\")) / 2).alias(\"mid_price\")\n    )\n    df = df.with_columns(\n        ((pl.col(\"bid_size\") - pl.col(\"ask_size\")) / (pl.col(\"bid_size\") + pl.col(\"ask_size\"))).alias(\"liquidity_imbalance\")\n    )\n\n    for c in combinations(prices, 2):\n        df = df.with_columns(\n            ((pl.col(c[0]) - pl.col(c[1])) / (pl.col(c[0]) + pl.col(c[1]))).alias(f\"{c[0]}_{c[1]}_imb\")\n        )\n    \n    \n    if cols_to_drop:\n        engineered_df = df.drop(cols_to_drop)\n    else:\n        engineered_df = df.to_pandas()\n\n    engineered_df = engineered_df.to_pandas()\n    \n  \n\n    print(\"# V2\")\n    engineered_df[\"imbalance_momentum\"] = engineered_df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / engineered_df['matched_size']\n \n\n    engineered_df['price_pressure'] = engineered_df['imbalance_size'] * (engineered_df['ask_price'] - engineered_df['bid_price'])\n    engineered_df['market_urgency'] = engineered_df['spread'] * engineered_df['liquidity_imbalance']\n    engineered_df['depth_pressure'] = (engineered_df['ask_size'] - engineered_df['bid_size']) * (engineered_df['far_price'] - engineered_df['near_price'])\n    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n        engineered_df[f\"all_prices_{func}\"] = engineered_df[prices].agg(func, axis=1)\n        engineered_df[f\"all_sizes_{func}\"] = engineered_df[sizes].agg(func, axis=1)\n        \n    for c in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n        triplet_feature = calculate_triplet_imbalance_numba(c, engineered_df)\n        engineered_df[triplet_feature.columns] = triplet_feature.values\n\n    print(\"V3\")\n    for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n        for window in [ 3]:\n            engineered_df[f\"{col}_shift_{window}\"] = engineered_df.groupby(['stock_id','date_id'])[col].shift(window)\n            engineered_df[f\"{col}_ret_{window}\"] = engineered_df.groupby(['stock_id','date_id'])[col].pct_change(window)\n            \n    for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size']:\n        for window in [ 3]:\n            engineered_df[f\"{col}_diff_{window}\"] = engineered_df.groupby([\"stock_id\",'date_id'])[col].diff(window)\n    \n    engineered_df[\"dow\"] = engineered_df[\"date_id\"] % 5\n    engineered_df[\"seconds\"] = engineered_df[\"seconds_in_bucket\"] % 60\n    engineered_df[\"minute\"] = engineered_df[\"seconds_in_bucket\"] // 60\n    \n    \n    \n    cols_to_drop = ['near_price_squared', 'matched_size_bid_size_imbalance_size_imb2',\n       'minute', 'all_prices_kurt', 'imbalance_size_mean_10',\n       'avg_liquidity_by_market', 'imbalance_size',\n       'far_price_ask_price_imb', 'far_price_bid_price_imb',\n       'wap_mean_10', 'matched_size_ask_size_imbalance_size_imb2',\n       'all_prices_skew', 'all_sizes_skew', 'price_pressure',\n       'all_sizes_kurt', 'reference_price_far_price_imb',\n       'far_price_wap_imb', 'relative_liquidity_to_market',\n       'bid_size_diff_3', 'imbalance_buy_sell_flag',\n       'matched_size_squared', 'liquidity_ratio_change', 'price_impact',\n       'ask_price_bid_price_imb', 'seconds',\n       'bid_size_ask_size_imbalance_size_imb2', 'wap_acceleration',\n       'ask_size_diff_3', 'depth_pressure',\n       'imbalance_buy_sell_flag_ret_3','reference_price_far_price_imb', 'all_sizes_skew',\n       'matched_imbalance', 'relative_near_price_to_market',\n       'avg_market_imbalance', 'all_sizes_kurt',\n       'avg_market_price_skewness',\n       'relative_imbalance_to_matched_size_to_market', 'liquidity',\n       'far_price_wap_imb', 'relative_wap_to_market_mean_10',\n       'time_decay', 'matched_size', 'wap_velocity', 'bid_size_diff_3',\n       'imbalance_to_matched_size',\n       'bid_size_ask_size_imbalance_size_imb2', 'ask_size_diff_3',\n       'matched_size_X_near_price', 'bid_size', 'depth_pressure',\n       'relative_spread_to_market', 'seconds', 'spread',\n       'bid_price_mean_10', 'ask_price_mean_10', 'ask_size',\n       'order_imbalance_ratio', 'price_skewness', 'bid_ask_imbalance',\n       'price_skewness_rate_of_change', 'imbalance_size_mean_10',\n       'avg_liquidity_by_market', 'imbalance_buy_sell_flag',\n       'imbalance_size', 'size_diff_ask_to_wap', 'price_diff_ask_to_wap',\n       'price_diff_bid_to_wap', 'size_diff_bid_to_wap',\n       'imbalance_buy_sell_flag_ret_3', 'wap_mean_10', 'price_spread',\n       'wap_acceleration', 'liquidity_ratio_change',\n       'ask_price_bid_price_imb', 'near_price_squared',\n       'relative_liquidity_to_market', 'minute', 'liquidity_imbalance',\n       'price_impact', 'matched_size_squared', 'size_imbalance',\n       'ask_price_mean_1', 'wap_mean_1', 'wap_momentum_5_mean_3',\n       'wap_momentum_5_mean_2', 'wap_momentum_5_mean_1', 'wap_mean_3',\n       'wap_mean_2', 'bid_price_mean_2', 'bid_price_mean_3',\n       'imbalance_size_mean_2', 'ask_price_mean_3', 'ask_price_mean_2',\n       'imbalance_size_mean_1', 'relative_wap_to_market_mean_1',\n       'bid_price_mean_1', 'relative_wap_to_market_mean_2',\n       'relative_wap_to_market_mean_3', 'imbalance_size_mean_3']\n    cols_drop_in = [col for col in cols_to_drop if col in engineered_df.columns]\n    \n    engineered_df = engineered_df.drop(cols_drop_in, axis=1)\n\n            \n    return engineered_df.replace([np.inf, -np.inf], 0)","metadata":{"papermill":{"duration":0.042863,"end_time":"2023-10-29T17:16:44.832191","exception":false,"start_time":"2023-10-29T17:16:44.789328","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:10:37.958691Z","iopub.execute_input":"2023-11-01T21:10:37.959112Z","iopub.status.idle":"2023-11-01T21:10:38.049796Z","shell.execute_reply.started":"2023-11-01T21:10:37.959073Z","shell.execute_reply":"2023-11-01T21:10:38.048682Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feat_engineering(df_train):\n    df = pl.DataFrame(df_train)\n    df = df.sort([\"stock_id\", \"date_id\", \"seconds_in_bucket\"])\n\n    df = df.with_columns(\n        (pl.col(\"seconds_in_bucket\") / 10).cast(pl.Int32).alias(\"seconds_in_bucket\")\n    )\n    for window in range(1, 30, 3):\n        print(f\"Processing window size: {window}\")\n        rolling_group = df.group_by_rolling(\n            index_column=\"seconds_in_bucket\",\n            period=f\"{window}i\",  # 'i' denotes index count (integer)\n            by=[\"stock_id\", \"date_id\"],\n            closed=\"left\",  # Adjust as needed\n        )\n\n        # Apply to basic and new features\n        for col in [\"wap\", \"bid_price\", \"ask_price\", \"imbalance_size\"]:\n            df = df.join(\n                rolling_group.agg(pl.col(col).mean().alias(f\"{col}_mean_{window}\")),\n                on=[\"stock_id\", \"date_id\", \"seconds_in_bucket\"],\n                how=\"left\",\n            )\n\n            df = df.join(\n                rolling_group.agg(pl.col(col).std().alias(f\"{col}_std_{window}\")),\n                on=[\"stock_id\", \"date_id\", \"seconds_in_bucket\"],\n                how=\"left\",\n            )\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-11-01T21:10:38.051109Z","iopub.execute_input":"2023-11-01T21:10:38.051507Z","iopub.status.idle":"2023-11-01T21:10:38.101725Z","shell.execute_reply.started":"2023-11-01T21:10:38.051452Z","shell.execute_reply":"2023-11-01T21:10:38.100913Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    df_train = feat_engineering(df_train_raw)\n    \n    #df_train = reduce_mem_usage(df_train, verbose=1)\n    \n    \n","metadata":{"papermill":{"duration":0.020101,"end_time":"2023-10-29T17:16:44.864351","exception":false,"start_time":"2023-10-29T17:16:44.844250","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:10:38.102634Z","iopub.execute_input":"2023-11-01T21:10:38.102877Z","iopub.status.idle":"2023-11-01T21:13:45.006644Z","shell.execute_reply.started":"2023-11-01T21:10:38.102855Z","shell.execute_reply":"2023-11-01T21:13:45.005706Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Processing window size: 1\nProcessing window size: 4\nProcessing window size: 7\nProcessing window size: 10\nProcessing window size: 13\nProcessing window size: 16\nProcessing window size: 19\nProcessing window size: 22\nProcessing window size: 25\nProcessing window size: 28\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = df_train.to_pandas()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T21:13:45.010287Z","iopub.execute_input":"2023-11-01T21:13:45.010648Z","iopub.status.idle":"2023-11-01T21:13:46.649227Z","shell.execute_reply.started":"2023-11-01T21:13:45.010613Z","shell.execute_reply":"2023-11-01T21:13:46.648158Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#engineered_df = df_train.copy()\n#numerical_cols = list(engineered_df.select_dtypes(include=['number']).columns)\n#list_cols = [col for col in numerical_cols if col not in ['stock_id', 'date_id', 'seconds_in_bucket']]\n#correlation_matrix = engineered_df[list_cols].corr()\n#high_correlation = correlation_matrix[correlation_matrix > 0.8]\n\n# Or, for the highest N correlations\n#N = 30\n#highest_correlations = correlation_matrix.unstack().sort_values(ascending=False).drop_duplicates()\n#highest_N_correlations = highest_correlations.head(N)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T21:13:46.650414Z","iopub.execute_input":"2023-11-01T21:13:46.650740Z","iopub.status.idle":"2023-11-01T21:13:46.696643Z","shell.execute_reply.started":"2023-11-01T21:13:46.650713Z","shell.execute_reply":"2023-11-01T21:13:46.695541Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from loguru import logger\nimport pandas as pd\nimport numpy as np\nimport itertools as itt\n\n\ndef time_series_split(X, n_splits, n_test_splits, embargo_td=2):\n    factorized_indices = np.unique(X[\"factorized\"])\n\n    # Compute the fold boundaries\n    fold_bounds = [\n        (fold[0], fold[-1] + 1) for fold in np.array_split(factorized_indices, n_splits)\n    ]\n\n    # Create the list of all tests test_fold_bounds that will become the test sets\n    selected_fold_bounds = list(itt.combinations(fold_bounds, n_test_splits))\n\n    # Reverse to start the testing from the most recent part of the dataset\n    selected_fold_bounds.reverse()\n\n    for fold_bound_list in selected_fold_bounds:\n        test_factorized_indices = np.empty(0)\n        test_fold_bounds = []\n\n        for fold_start, fold_end in fold_bound_list:\n            # Records the boundaries of the current test split\n            if not test_fold_bounds or fold_start != test_fold_bounds[-1][-1]:\n                test_fold_bounds.append((fold_start, fold_end))\n            elif fold_start == test_fold_bounds[-1][-1]:\n                test_fold_bounds[-1] = (test_fold_bounds[-1][0], fold_end)\n\n            test_factorized_indices = np.union1d(\n                test_factorized_indices, factorized_indices[fold_start:fold_end]\n            ).astype(int)\n\n        # Compute the train set indices\n        train_indices = np.setdiff1d(factorized_indices, test_factorized_indices)\n\n        # Purge and embargo can be added here if needed\n        # ...\n\n        yield train_indices, test_factorized_indices\n\n\n# # Example usage:\n","metadata":{"execution":{"iopub.status.busy":"2023-11-01T21:13:46.697980Z","iopub.execute_input":"2023-11-01T21:13:46.698363Z","iopub.status.idle":"2023-11-01T21:13:46.748121Z","shell.execute_reply.started":"2023-11-01T21:13:46.698320Z","shell.execute_reply":"2023-11-01T21:13:46.747124Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    col_split = \"date_id\"\n    df_train.sort_values([col_split], inplace=True)\n    df_train.reset_index(drop=True, inplace=True)\n    df_train[\"factorized\"] = pd.factorize(df_train[col_split])[0]\n    \n    list_cols_drop = [ \"date_id\"]\n    df_train.drop(list_cols_drop, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T21:13:46.749306Z","iopub.execute_input":"2023-11-01T21:13:46.749710Z","iopub.status.idle":"2023-11-01T21:13:50.661917Z","shell.execute_reply.started":"2023-11-01T21:13:46.749675Z","shell.execute_reply":"2023-11-01T21:13:50.660863Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEBUG:\n    n_estimators_min =n_estimators_max= 50\nelse:\n    n_estimators_min = 500\n    n_estimators_max = 500\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-01T21:13:50.663407Z","iopub.execute_input":"2023-11-01T21:13:50.663839Z","iopub.status.idle":"2023-11-01T21:13:50.712271Z","shell.execute_reply.started":"2023-11-01T21:13:50.663799Z","shell.execute_reply":"2023-11-01T21:13:50.711508Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgbm\n","metadata":{"execution":{"iopub.status.busy":"2023-11-01T21:41:34.874210Z","iopub.execute_input":"2023-11-01T21:41:34.874689Z","iopub.status.idle":"2023-11-01T21:41:34.925836Z","shell.execute_reply.started":"2023-11-01T21:41:34.874653Z","shell.execute_reply":"2023-11-01T21:41:34.924909Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"gpu_switch = \"ON\"\nn_splits = 5\nn_test_split = 1\nembargo_td = 100\n\nn_repeats = 1\nnbrnd_erly_stp = 130\n\ncv_mthd = \"KF\"\n\n# Cross-Validation Setup\nif TRAIN:\n    all_cv = {\"KF\": KFold(n_splits=n_splits, shuffle=True, random_state=state)}\n    cv = all_cv[cv_mthd]\n\n    model_params_dict = {\n        \"LGBMR\": {\n            \"static_params\": {\n                \"device\": \"gpu\" if gpu_switch == \"ON\" else \"cpu\",\n                \"objective\": \"mae\",\n                \"boosting_type\": \"gbdt\",\n                \"random_state\": state,\n                \"n_jobs\" : 4,\n                \"verbose\": -1,\n                \"importance_type\" : \"gain\",\n            },\n            \"dynamic_params\": {\n                \"n_estimators\": {\n                    \"type\": \"int\",\n                    \"low\": n_estimators_min,\n                    \"high\": n_estimators_max,\n                },\n                \"learning_rate\": {\n                    \"type\": \"float\",\n                    \"low\": 0.01,\n                    \"high\": 0.05,\n                },\n                \"max_depth\": {\"type\": \"int\", \"low\": 20, \"high\": 70},\n                \"num_leaves\": {\n                    \"type\": \"int\",\n                    \"low\": 60,\n                    \"high\": 300,\n                },\n                \"min_child_samples\": {\n                    \"type\": \"int\",\n                    \"low\": 20,\n                    \"high\": 40,\n                },\n                \"subsample\": {\n                    \"type\": \"float\",\n                    \"low\": 0.7,\n                    \"high\": 1,\n                },\n                \"colsample_bytree\": {\n                    \"type\": \"float\",\n                    \"low\": 1,\n                    \"high\": 1,\n                },\n                \"min_split_gain\": {\n                    \"type\": \"float\",\n                    \"low\": 0,\n                    \"high\": 1,\n                },\n                \"reg_alpha\": {\n                    \"type\": \"float\",\n                    \"low\": 0,\n                    \"high\": 1,\n                },\n                \"reg_lambda\": {\n                    \"type\": \"float\",\n                    \"low\": 0,\n                    \"high\": 1,\n                },\n            },\n        },\n    }\n\n    dict_models = {\"LGBMR\": LGBMR}\n\n    log_model = True\n\n    experiment_date_str = datetime.now().strftime(\"%Y%m%d_%H_%M_%S\")\n    experiment_purpose = \"optiver_trading_at_the_close\"\n    experiment_name = f\"{experiment_purpose}_{experiment_date_str}\"\n\n    mlflow.set_experiment(experiment_name)\n\n\ndef objective(trial, df_train):\n    try:\n        print(f\"trial: {trial.number}\")\n        with mlflow.start_run() as run:\n            mlflow.log_param(\"cv_mthd\", cv_mthd)\n            mlflow.set_tag(\"experiment_purpose\", experiment_purpose)\n            mlflow.set_tag(\"experiment_name\", experiment_name)\n            mlflow.set_tag(\"version_nb\", VERSION_NB)\n            for model_name, model_class in dict_models.items():\n                model = create_model(\n                    trial,\n                    dict_models[model_name],\n                    model_params_dict[model_name][\"static_params\"],\n                    model_params_dict[model_name][\"dynamic_params\"],\n                )\n                mae_list = []\n\n                log_training_details(logger, model, trial, model_name)\n\n                for fold_n, (train_indices, test_indices) in enumerate(time_series_split(df_train, n_splits = n_splits, n_test_splits = n_test_split)\n                ):\n                  \n                    with mlflow.start_run(\n                        run_name=f\"fold_{fold_n+1}\", nested=True\n                    ) as nested_run:\n                        mask_train = df_train[\"factorized\"].isin(list(train_indices))\n                        mask_test = df_train[\"factorized\"].isin(list(test_indices))\n\n                        # Filter based on the 'factorized' field\n                        y_train = df_train.loc[mask_train, \"target\"].squeeze()\n                        y_val = df_train.loc[mask_test, \"target\"].squeeze()\n                        X_train = df_train[mask_train].drop(\"target\", axis=1)\n                        X_val = df_train[mask_test].drop(\"target\", axis=1)\n\n                        mlflow.log_param(\"training_data_rows\", X_train.shape[0])\n                        mlflow.log_param(\"training_data_columns\", X_train.shape[1])\n\n                        model.fit(\n                            X_train,\n                            y_train,\n                            eval_set=[(X_val, y_val)],\n                            eval_metric=\"mae\",\n                            callbacks=[\n                                lgbm.callback.early_stopping(stopping_rounds=100),\n                                lgbm.callback.log_evaluation(period=100),\n                            ],\n                            \n                        )\n\n                        log_feature_importance(\n                            trial.number,\n                            model,\n                            X_train,\n                            fold_n,\n                            experiment_purpose,\n                            experiment_date_str,\n                        )\n\n                        fold_mae = model.best_score_[\"valid_0\"][\"l1\"]\n                        print(model.best_score_)\n                        mae_list.append(fold_mae)\n                        logger.info(f\"{fold_n + 1:<5} {'|':<2} {fold_mae:<20}\")\n\n                      \n                        mlflow.log_param(\"fold_number\", fold_n + 1)\n                        mlflow.log_param(\"model_name\", model_name)\n                        mlflow.log_param(\"log_model\", log_model)\n\n                        params_to_log = model.get_params()\n                        mlflow.log_params(params_to_log)\n\n                        if log_model:\n                            current_time_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n                            model_log_name = (\n                                f\"{model_name}_{trial.number}_{current_time_str}\"\n                            )\n\n                            mlflow.log_param(\"model_log_name\", model_log_name)\n\n                            mlflow.sklearn.log_model(model, model_log_name)\n\n                            mlflow.log_param(\"run_time\", current_time_str)\n\n                        nested_run_id = nested_run.info.run_id\n                        model_path = f\"{path_experiments_storage}/{run.info.experiment_id}/{nested_run_id}/artifacts/{model_log_name}/model.pkl\"\n                        mlflow.log_param(\"model_path\", model_path)\n                avg_mae = sum(mae_list) / len(mae_list)\n\n                mlflow.log_param(\"model_name\", model_name)\n\n                return avg_mae\n\n    except Exception as e:\n        logger.error(f\"An exception occurred: {e}\")\n        return float(\"inf\")","metadata":{"_cell_guid":"334e81a6-b09b-4a3d-96a1-fe0278deff13","_uuid":"4288a49c-b472-4af2-b2bb-95cf0cd2bd6d","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.038424,"end_time":"2023-10-29T17:16:44.947628","exception":false,"start_time":"2023-10-29T17:16:44.909204","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:41:35.759141Z","iopub.execute_input":"2023-11-01T21:41:35.759533Z","iopub.status.idle":"2023-11-01T21:41:35.867747Z","shell.execute_reply.started":"2023-11-01T21:41:35.759501Z","shell.execute_reply":"2023-11-01T21:41:35.866831Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"2023/11/01 21:41:35 INFO mlflow.tracking.fluent: Experiment with name 'optiver_trading_at_the_close_20231101_21_41_35' does not exist. Creating a new experiment.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Run the Optuna study\nif TRAIN:\n    study = optuna.create_study(\n        direction=\"minimize\",\n        study_name=\"Your Study Name\",\n        load_if_exists=True,\n    )\n    study.optimize(lambda trial: objective(trial, df_train), n_trials=N_TRIALS)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T21:41:37.517993Z","iopub.execute_input":"2023-11-01T21:41:37.518417Z","iopub.status.idle":"2023-11-01T21:45:27.246865Z","shell.execute_reply.started":"2023-11-01T21:41:37.518384Z","shell.execute_reply":"2023-11-01T21:45:27.245508Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"\u001b[32m2023-11-01 21:41:37.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m296\u001b[0m - \u001b[1m\u001b[34mTraining model: LGBMR\u001b[0m\u001b[0m\n\u001b[32m2023-11-01 21:41:37.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1m\u001b[32mTrial 0    | n_estimators: 500 | learning_rate: 0.04311922854011265 | max_depth: 55 | num_leaves: 141 | min_child_samples: 40 | subsample: 0.8632932374044058 | colsample_bytree: 1.0 | min_split_gain: 0.4373487510621791 | reg_alpha: 0.34440869890212666 | reg_lambda: 0.9605991094356225\u001b[0m\u001b[0m\n\u001b[32m2023-11-01 21:41:37.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1mFold  |  MAE                 \u001b[0m\n\u001b[32m2023-11-01 21:41:37.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1m----- |  --------------------\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"trial: 0\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l1: 5.98754\n[200]\tvalid_0's l1: 5.98582\n[300]\tvalid_0's l1: 5.98539\n[400]\tvalid_0's l1: 5.98526\nEarly stopping, best iteration is:\n[341]\tvalid_0's l1: 5.98423\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m2023-11-01 21:44:14.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1m1     |  5.984226157303706   \u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('l1', 5.984226157303706)])})\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"[W 2023-11-01 21:45:26,375] Trial 0 failed with parameters: {'n_estimators': 500, 'learning_rate': 0.04311922854011265, 'max_depth': 55, 'num_leaves': 141, 'min_child_samples': 40, 'subsample': 0.8632932374044058, 'colsample_bytree': 1.0, 'min_split_gain': 0.4373487510621791, 'reg_alpha': 0.34440869890212666, 'reg_lambda': 0.9605991094356225} because of the following error: KeyboardInterrupt().\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n    value_or_values = func(trial)\n  File \"/tmp/ipykernel_605/3066020017.py\", line 8, in <lambda>\n    study.optimize(lambda trial: objective(trial, df_train), n_trials=N_TRIALS)\n  File \"/tmp/ipykernel_605/4053967825.py\", line 126, in objective\n    model.fit(\n  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 895, in fit\n    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 748, in fit\n    self._Booster = train(\n  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py\", line 292, in train\n    booster.update(fobj=fobj)\n  File \"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py\", line 3021, in update\n    _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\nKeyboardInterrupt\n[W 2023-11-01 21:45:26,379] Trial 0 failed with value None.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAIN:\n\u001b[1;32m      3\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m      4\u001b[0m         direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m         study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour Study Name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m         load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m     )\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[34], line 8\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAIN:\n\u001b[1;32m      3\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m      4\u001b[0m         direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m         study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour Study Name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m         load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m     )\n\u001b[0;32m----> 8\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39mN_TRIALS)\n","Cell \u001b[0;32mIn[33], line 126\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, df_train)\u001b[0m\n\u001b[1;32m    123\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_data_rows\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    124\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_data_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 126\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmae\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlgbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlgbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m log_feature_importance(\n\u001b[1;32m    139\u001b[0m     trial\u001b[38;5;241m.\u001b[39mnumber,\n\u001b[1;32m    140\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m     experiment_date_str,\n\u001b[1;32m    145\u001b[0m )\n\u001b[1;32m    147\u001b[0m fold_mae \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbest_score_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_0\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:895\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y,\n\u001b[1;32m    889\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    890\u001b[0m         eval_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    891\u001b[0m         eval_init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    892\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m'\u001b[39m, feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    893\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    894\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 895\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m                \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    745\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    746\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    285\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m    286\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    287\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    288\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[1;32m    289\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[1;32m    290\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 292\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m evaluation_result_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3021\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the Optuna study\nif TRAIN:\n    study = optuna.create_study(\n        direction=\"minimize\",\n        study_name=\"Your Study Name\",\n        load_if_exists=True,\n    )\n    study.optimize(lambda trial: objective(trial, df_train), n_trials=N_TRIALS)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T21:14:10.993920Z","iopub.execute_input":"2023-11-01T21:14:10.994233Z","iopub.status.idle":"2023-11-01T21:14:20.887145Z","shell.execute_reply.started":"2023-11-01T21:14:10.994205Z","shell.execute_reply":"2023-11-01T21:14:20.886384Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"\u001b[32m2023-11-01 21:14:11.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m296\u001b[0m - \u001b[1m\u001b[34mTraining model: LGBMR\u001b[0m\u001b[0m\n\u001b[32m2023-11-01 21:14:11.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1m\u001b[32mTrial 0    | n_estimators: 500 | learning_rate: 0.021602197769132456 | max_depth: 62 | num_leaves: 300 | min_child_samples: 27 | subsample: 0.7898461609148738 | colsample_bytree: 1.0 | min_split_gain: 0.3241565745023913 | reg_alpha: 0.3551796946275849 | reg_lambda: 0.925473392114989\u001b[0m\u001b[0m\n\u001b[32m2023-11-01 21:14:11.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1mFold  |  MAE                 \u001b[0m\n\u001b[32m2023-11-01 21:14:11.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1m----- |  --------------------\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"trial: 0\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m2023-11-01 21:14:14.292\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m182\u001b[0m - \u001b[31m\u001b[1mAn exception occurred: type object 'LGBMRegressor' has no attribute 'callback'\u001b[0m\n\u001b[32m2023-11-01 21:14:14.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m296\u001b[0m - \u001b[1m\u001b[34mTraining model: LGBMR\u001b[0m\u001b[0m\n\u001b[32m2023-11-01 21:14:14.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1m\u001b[32mTrial 1    | n_estimators: 500 | learning_rate: 0.022333391077249888 | max_depth: 47 | num_leaves: 194 | min_child_samples: 40 | subsample: 0.9035237009593953 | colsample_bytree: 1.0 | min_split_gain: 0.02241462075385159 | reg_alpha: 0.9824888108987258 | reg_lambda: 0.18795577547812092\u001b[0m\u001b[0m\n\u001b[32m2023-11-01 21:14:14.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1mFold  |  MAE                 \u001b[0m\n\u001b[32m2023-11-01 21:14:14.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1m----- |  --------------------\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"trial: 1\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m2023-11-01 21:14:17.599\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m182\u001b[0m - \u001b[31m\u001b[1mAn exception occurred: type object 'LGBMRegressor' has no attribute 'callback'\u001b[0m\n\u001b[32m2023-11-01 21:14:17.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m296\u001b[0m - \u001b[1m\u001b[34mTraining model: LGBMR\u001b[0m\u001b[0m\n\u001b[32m2023-11-01 21:14:17.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1m\u001b[32mTrial 2    | n_estimators: 500 | learning_rate: 0.015037829179250103 | max_depth: 51 | num_leaves: 300 | min_child_samples: 35 | subsample: 0.7762425823755148 | colsample_bytree: 1.0 | min_split_gain: 0.2790922512861522 | reg_alpha: 0.17745588048509398 | reg_lambda: 0.874467954621376\u001b[0m\u001b[0m\n\u001b[32m2023-11-01 21:14:17.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1mFold  |  MAE                 \u001b[0m\n\u001b[32m2023-11-01 21:14:17.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1m----- |  --------------------\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"trial: 2\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m2023-11-01 21:14:20.872\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m182\u001b[0m - \u001b[31m\u001b[1mAn exception occurred: type object 'LGBMRegressor' has no attribute 'callback'\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the Optuna study\nif TRAIN:\n    study = optuna.create_study(\n        direction=\"minimize\",\n        study_name=\"Your Study Name\",\n        load_if_exists=True,\n    )\n    study.optimize(lambda trial: objective(trial, df_train), n_trials=N_TRIALS)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T21:14:20.888308Z","iopub.execute_input":"2023-11-01T21:14:20.888615Z","iopub.status.idle":"2023-11-01T21:14:30.769565Z","shell.execute_reply.started":"2023-11-01T21:14:20.888590Z","shell.execute_reply":"2023-11-01T21:14:30.768710Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"\u001b[32m2023-11-01 21:14:20.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m296\u001b[0m - \u001b[1m\u001b[34mTraining model: LGBMR\u001b[0m\u001b[0m\n\u001b[32m2023-11-01 21:14:20.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1m\u001b[32mTrial 0    | n_estimators: 500 | learning_rate: 0.03663118825529107 | max_depth: 20 | num_leaves: 147 | min_child_samples: 35 | subsample: 0.7596240793815405 | colsample_bytree: 1.0 | min_split_gain: 0.6949689704935348 | reg_alpha: 0.5510969853108687 | reg_lambda: 0.3684042832580505\u001b[0m\u001b[0m\n\u001b[32m2023-11-01 21:14:20.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1mFold  |  MAE                 \u001b[0m\n\u001b[32m2023-11-01 21:14:20.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1m----- |  --------------------\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"trial: 0\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m2023-11-01 21:14:24.204\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m182\u001b[0m - \u001b[31m\u001b[1mAn exception occurred: type object 'LGBMRegressor' has no attribute 'callback'\u001b[0m\n\u001b[32m2023-11-01 21:14:24.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m296\u001b[0m - \u001b[1m\u001b[34mTraining model: LGBMR\u001b[0m\u001b[0m\n\u001b[32m2023-11-01 21:14:24.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1m\u001b[32mTrial 1    | n_estimators: 500 | learning_rate: 0.02174072412868265 | max_depth: 33 | num_leaves: 268 | min_child_samples: 26 | subsample: 0.7265647360440667 | colsample_bytree: 1.0 | min_split_gain: 0.08940882907192127 | reg_alpha: 0.5802550526832412 | reg_lambda: 0.916778816240275\u001b[0m\u001b[0m\n\u001b[32m2023-11-01 21:14:24.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1mFold  |  MAE                 \u001b[0m\n\u001b[32m2023-11-01 21:14:24.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1m----- |  --------------------\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"trial: 1\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m2023-11-01 21:14:27.500\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m182\u001b[0m - \u001b[31m\u001b[1mAn exception occurred: type object 'LGBMRegressor' has no attribute 'callback'\u001b[0m\n\u001b[32m2023-11-01 21:14:27.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m296\u001b[0m - \u001b[1m\u001b[34mTraining model: LGBMR\u001b[0m\u001b[0m\n\u001b[32m2023-11-01 21:14:27.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1m\u001b[32mTrial 2    | n_estimators: 500 | learning_rate: 0.040527467645875316 | max_depth: 36 | num_leaves: 162 | min_child_samples: 25 | subsample: 0.8519515578896526 | colsample_bytree: 1.0 | min_split_gain: 0.2189514431597066 | reg_alpha: 0.39717724521461706 | reg_lambda: 0.18573859358989386\u001b[0m\u001b[0m\n\u001b[32m2023-11-01 21:14:27.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1mFold  |  MAE                 \u001b[0m\n\u001b[32m2023-11-01 21:14:27.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mlog_training_details\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1m----- |  --------------------\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"trial: 2\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m2023-11-01 21:14:30.755\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mobjective\u001b[0m:\u001b[36m182\u001b[0m - \u001b[31m\u001b[1mAn exception occurred: type object 'LGBMRegressor' has no attribute 'callback'\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def experiments_data(list_experiment_id = None, save_df = None, list_columns = None):\n    \"\"\"\n    Ogni volta che viene chiamata questa funzione legge tutti gli esperimenti e ritorna una nuova versione del file con tutti gli esperimenti storicizzati\n    \"\"\"\n    experiments = client.search_experiments()\n    all_runs_data = []\n    for exp in experiments:\n        experiment_id = exp.experiment_id\n        if (list_experiment_id == None) or (experiment_id in list_experiment_id):\n        \n            run_infos = client.search_runs(experiment_ids=[experiment_id])\n\n            for run_info in run_infos:\n                run_data = {\n                    \"experiment_id\": experiment_id,\n                    \"experiment_name\": exp.name,\n                    \"run_id\": run_info.info.run_id,\n                }\n\n                # Add metrics to run_data\n                for key, value in run_info.data.metrics.items():\n                    run_data[f\"{key}\"] = value\n\n                # Add params to run_data\n                for key, value in run_info.data.params.items():\n                    run_data[f\"{key}\"] = value\n\n                all_runs_data.append(run_data)\n        \n    df_runs_new = pd.DataFrame(all_runs_data)\n    \n\n    \n    df_runs_new = df_runs_new[~df_runs_new[\"fold_number\"].isna()]\n    \n    if list_columns:\n        df_runs_new = df_runs_new[list_columns]\n        \n    if save_df:\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n        csv_filename = f\"df_runs_{timestamp}.csv\"\n        df_runs_new.to_csv(csv_filename, index=False)\n\n        print(f\"DataFrame saved to {csv_filename}, Shape: {df_unique.shape}\")\n\n    return df_runs_new","metadata":{"_cell_guid":"51030a77-aba3-469f-9c08-7963bc8a09d2","_uuid":"6ff7d358-62f0-4ac9-b028-d1c920bb4eaf","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.022231,"end_time":"2023-10-29T17:16:45.128848","exception":false,"start_time":"2023-10-29T17:16:45.106617","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:14:30.770778Z","iopub.execute_input":"2023-11-01T21:14:30.771047Z","iopub.status.idle":"2023-11-01T21:14:30.820438Z","shell.execute_reply.started":"2023-11-01T21:14:30.771024Z","shell.execute_reply":"2023-11-01T21:14:30.819611Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    df_exp  = experiments_data(list_experiment_id = None, save_df = None, list_columns = None)\n    list_base_cols = ['run_time','experiment_id','model_name','fold_number','mae','training_data_rows','training_data_columns'] \n    list_dynamic_params = list(model_params_dict[\"LGBMR\"]['dynamic_params'].keys())\n    \n    \n    \n    list_cols_exp = list_base_cols + list_dynamic_params +['model_path']\n    \n    \n    df_exp = df_exp[list_cols_exp]\n    \n    df_exp['run_time'] = pd.to_datetime(df_exp['run_time'], format='%Y%m%d_%H%M%S', errors='coerce')","metadata":{"execution":{"iopub.status.busy":"2023-11-01T21:14:30.821681Z","iopub.execute_input":"2023-11-01T21:14:30.821994Z","iopub.status.idle":"2023-11-01T21:14:32.449310Z","shell.execute_reply.started":"2023-11-01T21:14:30.821961Z","shell.execute_reply":"2023-11-01T21:14:32.448218Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.011661,"end_time":"2023-10-29T17:16:45.369942","exception":false,"start_time":"2023-10-29T17:16:45.358281","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_files_feat_importance = ['/kaggle/working/feat_impor_optiver_trading_at_the_close_20231101_072036.csv','/kaggle/working/feat_impor_optiver_trading_at_the_close_20231031_095537.csv','/kaggle/working/feat_impor_optiver_trading_at_the_close_20231031_132330.csv']","metadata":{"papermill":{"duration":0.011597,"end_time":"2023-10-29T17:16:45.393480","exception":false,"start_time":"2023-10-29T17:16:45.381883","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:14:32.450942Z","iopub.execute_input":"2023-11-01T21:14:32.451323Z","iopub.status.idle":"2023-11-01T21:14:32.496956Z","shell.execute_reply.started":"2023-11-01T21:14:32.451286Z","shell.execute_reply":"2023-11-01T21:14:32.495962Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggregate_feature_importance( list_files_feat_importance)['feat'][-70:].values\n","metadata":{"execution":{"iopub.status.busy":"2023-11-01T21:14:32.498263Z","iopub.execute_input":"2023-11-01T21:14:32.498602Z","iopub.status.idle":"2023-11-01T21:14:32.563795Z","shell.execute_reply.started":"2023-11-01T21:14:32.498575Z","shell.execute_reply":"2023-11-01T21:14:32.562937Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"array(['reference_price_far_price_imb', 'all_sizes_skew',\n       'matched_imbalance', 'relative_near_price_to_market',\n       'avg_market_imbalance', 'all_sizes_kurt',\n       'avg_market_price_skewness',\n       'relative_imbalance_to_matched_size_to_market', 'liquidity',\n       'far_price_wap_imb', 'relative_wap_to_market_mean_10',\n       'time_decay', 'matched_size', 'wap_velocity', 'bid_size_diff_3',\n       'imbalance_to_matched_size',\n       'bid_size_ask_size_imbalance_size_imb2', 'ask_size_diff_3',\n       'matched_size_X_near_price', 'bid_size', 'depth_pressure',\n       'relative_spread_to_market', 'seconds', 'spread',\n       'bid_price_mean_10', 'ask_price_mean_10', 'ask_size',\n       'order_imbalance_ratio', 'price_skewness', 'bid_ask_imbalance',\n       'price_skewness_rate_of_change', 'imbalance_size_mean_10',\n       'avg_liquidity_by_market', 'imbalance_buy_sell_flag',\n       'imbalance_size', 'size_diff_ask_to_wap', 'price_diff_ask_to_wap',\n       'price_diff_bid_to_wap', 'size_diff_bid_to_wap',\n       'imbalance_buy_sell_flag_ret_3', 'wap_mean_10', 'price_spread',\n       'wap_acceleration', 'liquidity_ratio_change',\n       'ask_price_bid_price_imb', 'near_price_squared',\n       'relative_liquidity_to_market', 'minute', 'liquidity_imbalance',\n       'price_impact', 'matched_size_squared', 'size_imbalance',\n       'ask_price_mean_1', 'wap_mean_1', 'wap_momentum_5_mean_3',\n       'wap_momentum_5_mean_2', 'wap_momentum_5_mean_1', 'wap_mean_3',\n       'wap_mean_2', 'bid_price_mean_2', 'bid_price_mean_3',\n       'imbalance_size_mean_2', 'ask_price_mean_3', 'ask_price_mean_2',\n       'imbalance_size_mean_1', 'relative_wap_to_market_mean_1',\n       'bid_price_mean_1', 'relative_wap_to_market_mean_2',\n       'relative_wap_to_market_mean_3', 'imbalance_size_mean_3'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"def ensemble_predict(model_paths, X_test):\n    models = []\n    predictions = []\n\n    # Load models based on full artifact paths\n    for model_path in model_paths:\n        try:\n            # If using direct path to pkl\n            if model_path.endswith(\".pkl\"):\n                model = joblib.load(model_path)\n            else:\n                print(f\"Unsupported model format for {model_path}. Skipping.\")\n                continue  # Skip this iteration\n\n            models.append(model)\n        except Exception as e:\n            print(f\"Failed to load model at {model_path}. Error: {e}\")\n\n    # Make predictions\n    for model in models:\n        try:\n            pred = model.predict(X_test)\n            predictions.append(pred)\n        except Exception as e:\n            print(f\"Failed to make prediction with model. Error: {e}\")\n\n    # Average predictions\n    if len(predictions) > 0:\n        ensemble_pred = np.mean(predictions, axis=0)\n    else:\n        print(\"No valid models loaded. Cannot make ensemble predictions.\")\n        ensemble_pred = None\n\n    return ensemble_pred","metadata":{"_cell_guid":"95e6c8a8-62ed-4412-944a-5b08508702fc","_uuid":"60c6783c-1e42-43ca-ba32-bda313deb585","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.02353,"end_time":"2023-10-29T17:16:45.534872","exception":false,"start_time":"2023-10-29T17:16:45.511342","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:14:32.564909Z","iopub.execute_input":"2023-11-01T21:14:32.565183Z","iopub.status.idle":"2023-11-01T21:14:32.610963Z","shell.execute_reply.started":"2023-11-01T21:14:32.565158Z","shell.execute_reply":"2023-11-01T21:14:32.610172Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.012259,"end_time":"2023-10-29T17:16:45.559669","exception":false,"start_time":"2023-10-29T17:16:45.547410","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_dir = \"model_1\"\n\nif TRAIN:\n    model_paths = list(df_runs[df_runs[\"experiment_time\"] == \"152953\"][\"model_path\"])\n\n    if not os.path.exists(models_dir):\n        os.makedirs(models_dir)\n\n    for model_path in model_paths:\n        print(f\"Checking if model path exists: {model_path}\")\n\n        if not os.path.exists(model_path):\n            print(f\"File does not exist: {model_path}\")\n            continue  # Skip to the next iteration\n\n        specific_part = model_path.split(\"/\")[-2]\n        dest_path = os.path.join(models_dir, f\"{specific_part}.pkl\")\n        if not os.path.exists(dest_path):\n            print(f\"Copying from {model_path} to {dest_path}\")\n            shutil.copy(model_path, dest_path)\n        else:\n            print(f\"File {dest_path} already exists. Skipping copy.\")\n\n    zipf = zipfile.ZipFile(\n        f\"/kaggle/working/{models_dir}.zip\", \"w\", zipfile.ZIP_DEFLATED\n    )\n\n    # Navigate through the folder and add each file to the ZIP\n    for root, dirs, files in os.walk(f\"/kaggle/working/{models_dir}\"):\n        for file in files:\n            zipf.write(\n                os.path.join(root, file),\n                os.path.relpath(\n                    os.path.join(root, file), f\"/kaggle/working/{models_dir}\"\n                ),\n            )\n\n    zipf.close()","metadata":{"papermill":{"duration":0.025212,"end_time":"2023-10-29T17:16:45.655277","exception":false,"start_time":"2023-10-29T17:16:45.630065","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:14:32.612179Z","iopub.execute_input":"2023-11-01T21:14:32.612563Z","iopub.status.idle":"2023-11-01T21:14:33.355521Z","shell.execute_reply.started":"2023-11-01T21:14:32.612529Z","shell.execute_reply":"2023-11-01T21:14:33.353537Z"},"trusted":true},"execution_count":25,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m models_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAIN:\n\u001b[0;32m----> 4\u001b[0m     model_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mdf_runs\u001b[49m[df_runs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m152953\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(models_dir):\n\u001b[1;32m      7\u001b[0m         os\u001b[38;5;241m.\u001b[39mmakedirs(models_dir)\n","\u001b[0;31mNameError\u001b[0m: name 'df_runs' is not defined"],"ename":"NameError","evalue":"name 'df_runs' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.012391,"end_time":"2023-10-29T17:16:45.680337","exception":false,"start_time":"2023-10-29T17:16:45.667946","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_paths = []\nmodels_dir_input = models_dir.replace(\"_\", \"-\")\ndirectory = f\"/kaggle/input/{models_dir_input}\"\n\n# Check if the directory exists\nif os.path.exists(directory):\n    # Traverse the directory and collect file paths\n    for filename in os.listdir(directory):\n        full_path = os.path.join(directory, filename)\n\n        # Check if the item is a file (and not a sub-directory)\n        if os.path.isfile(full_path):\n            model_paths.append(full_path)\nelse:\n    print(f\"The directory {directory} does not exist.\")\n\n# Print or return the list of file paths\nprint(\"List of file paths:\", model_paths)","metadata":{"papermill":{"duration":0.026356,"end_time":"2023-10-29T17:16:45.718974","exception":false,"start_time":"2023-10-29T17:16:45.692618","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:14:33.356249Z","iopub.status.idle":"2023-11-01T21:14:33.356703Z","shell.execute_reply.started":"2023-11-01T21:14:33.356473Z","shell.execute_reply":"2023-11-01T21:14:33.356514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.01212,"end_time":"2023-10-29T17:16:45.743760","exception":false,"start_time":"2023-10-29T17:16:45.731640","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming X_test for predict\n# ensemble_predictions = ensemble_predict(model_paths, df_test, mlflow_client)","metadata":{"_cell_guid":"79aa495a-7580-497c-b913-8941cf7d0c61","_uuid":"b3efe16f-ca61-4000-94d7-568364d0e11b","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.019319,"end_time":"2023-10-29T17:16:45.775373","exception":false,"start_time":"2023-10-29T17:16:45.756054","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:14:33.358172Z","iopub.status.idle":"2023-11-01T21:14:33.358532Z","shell.execute_reply.started":"2023-11-01T21:14:33.358353Z","shell.execute_reply":"2023-11-01T21:14:33.358369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optiver2023\n\nenv = optiver2023.make_env()\niter_test = env.iter_test()","metadata":{"_cell_guid":"d4bfb979-2758-4fe9-8947-399b1c3a574c","_uuid":"bef1a199-0988-4743-813e-99d4308fc9bb","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.04228,"end_time":"2023-10-29T17:16:45.830037","exception":false,"start_time":"2023-10-29T17:16:45.787757","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:14:33.359907Z","iopub.status.idle":"2023-11-01T21:14:33.360281Z","shell.execute_reply.started":"2023-11-01T21:14:33.360094Z","shell.execute_reply":"2023-11-01T21:14:33.360112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.016727,"end_time":"2023-10-29T17:16:45.862613","exception":false,"start_time":"2023-10-29T17:16:45.845886","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counter = 0\nfor test, revealed_targets, sample_prediction in iter_test:\n    # df_test_raw = pl.DataFrame(test)\n\n    feat = feat_engineering(test)\n\n    # feat = df_test.to_pandas()\n\n    list_cols_drop = [\"stock_id\", \"date_id\", \"row_id\"]\n    feat = feat.drop(list_cols_drop, axis=1)\n\n    sample_prediction[\"target\"] = ensemble_predict(model_paths, feat)\n    env.predict(sample_prediction)\n    counter += 1","metadata":{"_cell_guid":"d30f3862-dca2-4242-9db0-ab9750118622","_uuid":"efd9073c-aaef-4135-bf7c-1e892e9aa831","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":105.467568,"end_time":"2023-10-29T17:18:31.345732","exception":false,"start_time":"2023-10-29T17:16:45.878164","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:14:33.361985Z","iopub.status.idle":"2023-11-01T21:14:33.362302Z","shell.execute_reply.started":"2023-11-01T21:14:33.362144Z","shell.execute_reply":"2023-11-01T21:14:33.362159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    list_cols_drop = [\"stock_id\", \"date_id\", \"row_id\"]\n    feat = feat.drop(list_cols_drop, axis=1)","metadata":{"_cell_guid":"1bca4965-2df1-4a88-bc93-1e6d8fea7ac3","_uuid":"0a5200ae-92df-4b21-bf5c-6e255b90676f","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.031034,"end_time":"2023-10-29T17:18:31.400229","exception":false,"start_time":"2023-10-29T17:18:31.369195","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:14:33.363852Z","iopub.status.idle":"2023-11-01T21:14:33.364187Z","shell.execute_reply.started":"2023-11-01T21:14:33.364020Z","shell.execute_reply":"2023-11-01T21:14:33.364036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.022343,"end_time":"2023-10-29T17:18:31.445104","exception":false,"start_time":"2023-10-29T17:18:31.422761","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.02223,"end_time":"2023-10-29T17:18:31.490205","exception":false,"start_time":"2023-10-29T17:18:31.467975","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.022172,"end_time":"2023-10-29T17:18:31.534807","exception":false,"start_time":"2023-10-29T17:18:31.512635","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.022005,"end_time":"2023-10-29T17:18:31.579172","exception":false,"start_time":"2023-10-29T17:18:31.557167","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"18344629-3cbc-4244-ac34-c8af6b88b0d8","_uuid":"667a4d83-d235-446e-a72c-cf02718a1a7b","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.022032,"end_time":"2023-10-29T17:18:31.623976","exception":false,"start_time":"2023-10-29T17:18:31.601944","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.022491,"end_time":"2023-10-29T17:18:31.668688","exception":false,"start_time":"2023-10-29T17:18:31.646197","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#clean_directory_except_one('/kaggle/working/', 'submission.csv')","metadata":{"papermill":{"duration":0.030147,"end_time":"2023-10-29T17:18:31.721197","exception":false,"start_time":"2023-10-29T17:18:31.691050","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T21:14:33.365910Z","iopub.status.idle":"2023-11-01T21:14:33.366270Z","shell.execute_reply.started":"2023-11-01T21:14:33.366082Z","shell.execute_reply":"2023-11-01T21:14:33.366098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"3ef4ae54-1bb4-4cc3-a7da-a6691a272d30","_uuid":"495a4e04-554d-4ef1-919d-62bc59f089c4","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.022039,"end_time":"2023-10-29T17:18:31.765571","exception":false,"start_time":"2023-10-29T17:18:31.743532","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.023232,"end_time":"2023-10-29T17:18:31.811015","exception":false,"start_time":"2023-10-29T17:18:31.787783","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"5498ae4b-62e8-4050-91e7-075fc549380f","_uuid":"ce9653b2-7dff-4c5b-af77-5f0ef88b6e86","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.022222,"end_time":"2023-10-29T17:18:31.856624","exception":false,"start_time":"2023-10-29T17:18:31.834402","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"92a8ed18-3a63-464e-9d62-17cea3baed59","_uuid":"0b017968-3b5a-4465-820e-e89659b10afd","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.022485,"end_time":"2023-10-29T17:18:31.901283","exception":false,"start_time":"2023-10-29T17:18:31.878798","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"f9d19e8d-0074-4ae2-adfb-4c039b700215","_uuid":"b6096d27-d452-4593-9832-d15bfbd83e1b","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.022606,"end_time":"2023-10-29T17:18:31.946090","exception":false,"start_time":"2023-10-29T17:18:31.923484","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"855f8db3-e344-4d4d-b577-36499775f352","_uuid":"fde5edb9-d23d-41ac-92c6-593f299230c2","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.021902,"end_time":"2023-10-29T17:18:31.990239","exception":false,"start_time":"2023-10-29T17:18:31.968337","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"82330d89-f35e-4cae-876c-de852438527d","_uuid":"f90f329d-b882-464c-84fc-74a815cfe1cd","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.021851,"end_time":"2023-10-29T17:18:32.034578","exception":false,"start_time":"2023-10-29T17:18:32.012727","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"ed96eca6-9765-4c90-a6bf-3071518ba2f0","_uuid":"ca1d48b9-5537-491b-9de2-57360edd9844","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.022409,"end_time":"2023-10-29T17:18:32.079037","exception":false,"start_time":"2023-10-29T17:18:32.056628","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"06b24b0a-6515-48c6-b4a0-240865cfc1ea","_uuid":"5e9b8536-f812-432a-ba05-c2f0b0f8994f","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.021691,"end_time":"2023-10-29T17:18:32.123180","exception":false,"start_time":"2023-10-29T17:18:32.101489","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}