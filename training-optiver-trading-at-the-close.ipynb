{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2b4c4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:46.598715Z",
     "iopub.status.busy": "2023-11-02T12:57:46.598320Z",
     "iopub.status.idle": "2023-11-02T12:57:47.376059Z",
     "shell.execute_reply": "2023-11-02T12:57:47.374655Z"
    },
    "papermill": {
     "duration": 0.800691,
     "end_time": "2023-11-02T12:57:47.378988",
     "exception": false,
     "start_time": "2023-11-02T12:57:46.578297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants\n",
    "TRAIN = False\n",
    "OVERWRITE = False\n",
    "DEBUG = False\n",
    "\n",
    "models_dir = \"models_4\"\n",
    "\n",
    "N_TRIALS = 3\n",
    "\n",
    "VERSION_NB = 4\n",
    "\n",
    "state = 42\n",
    "\n",
    "download_kaggle_data = False\n",
    "\n",
    "# External general-purpose modules\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import glob\n",
    "from itertools import combinations\n",
    "from warnings import simplefilter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from dotenv import load_dotenv\n",
    "from joblib import dump\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Setting pandas options and warning filters\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedd9784",
   "metadata": {
    "_cell_guid": "3bdaa15b-0b9e-4b3b-9c47-58e6b9b18b5e",
    "_uuid": "206043b9-f1d5-4691-b03a-935f2177086d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:47.418280Z",
     "iopub.status.busy": "2023-11-02T12:57:47.417771Z",
     "iopub.status.idle": "2023-11-02T12:57:47.439888Z",
     "shell.execute_reply": "2023-11-02T12:57:47.438697Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.045267,
     "end_time": "2023-11-02T12:57:47.443184",
     "exception": false,
     "start_time": "2023-11-02T12:57:47.397917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "path_project_dir = os.getcwd()\n",
    "if path_project_dir not in [\"/kaggle/working\", \"/content\"]:\n",
    "    path_project_dir = os.getenv(\"ROOT_PATH\")\n",
    "\n",
    "# Imports and setup for training\n",
    "if TRAIN:\n",
    "    \n",
    "    import itertools as itt\n",
    "    # Install packages and import logging libraries\n",
    "    if path_project_dir == '/kaggle/working':\n",
    "        !pip install loguru mlflow optuna > /dev/null\n",
    "        \n",
    "\n",
    "    from utils import log_feature_importance, create_model, log_training_details, aggregate_feature_importance,  get_data, clean_directory_except_one\n",
    "    \n",
    "    from loguru import logger\n",
    "    import mlflow\n",
    "    import optuna\n",
    "    from optuna.integration.mlflow import MLflowCallback\n",
    "    from mlflow.tracking import MlflowClient\n",
    "    import zipfile\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "\n",
    "    # Import machine learning libraries\n",
    "    import lightgbm as lgbm\n",
    "    \n",
    "    from lightgbm import log_evaluation, early_stopping, LGBMRegressor as LGBMR\n",
    "    from sklearn.model_selection import KFold\n",
    "    from xgboost import XGBRegressor as XGBR\n",
    "\n",
    "    # Set logging\n",
    "    logger.add(\"logs.log\", format=\"{time:YYYY-MM-DD HH:mm} | {level} | {message}\")\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning)\n",
    "    \n",
    "    # Auto-reload modules\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "    # Initialize MLflow callback\n",
    "    mlflow_callback = MLflowCallback(\n",
    "        tracking_uri=mlflow.get_tracking_uri(), metric_name=\"mae\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82b2040a",
   "metadata": {
    "_cell_guid": "9765420b-f8ab-46ba-8b4c-e4487eb04b76",
    "_uuid": "c4174134-1441-41f8-adbf-f03ad3f7d7dc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:47.483266Z",
     "iopub.status.busy": "2023-11-02T12:57:47.482890Z",
     "iopub.status.idle": "2023-11-02T12:57:47.493617Z",
     "shell.execute_reply": "2023-11-02T12:57:47.492586Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034255,
     "end_time": "2023-11-02T12:57:47.495816",
     "exception": false,
     "start_time": "2023-11-02T12:57:47.461561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if path_project_dir == \"/kaggle/working\":\n",
    "    path_data_project_dir = \"/kaggle/input/optiver-trading-at-the-close\"\n",
    "    path_experiments_storage = os.path.join(path_project_dir, \"experiments_storage\")\n",
    "\n",
    "    path_dataset_train_raw = \"/kaggle/input/optiver-trading-at-the-close/train.csv\"\n",
    "    path_dataset_test_raw = (\n",
    "        \"/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv\"\n",
    "    )\n",
    "\n",
    "    path_dataset_processed = \"/kaggle/working/processed_data\"\n",
    "    path_dataset_train = os.path.join(path_dataset_processed, \"train.csv\")\n",
    "    path_dataset_test = os.path.join(path_dataset_processed, \"test.csv\")\n",
    "\n",
    "else:\n",
    "    name_folder_data_project = \"kaggle_optiver_trading_at_the_close\"\n",
    "\n",
    "    path_data_dir = os.path.join(path_project_dir, \"data\")\n",
    "    path_dataset_train_raw = os.path.join(\n",
    "        path_data_dir, \"kaggle_optiver_trading_at_the_close/raw\", \"train.csv\"\n",
    "    )\n",
    "    path_dataset_processed = os.path.join(\n",
    "        path_data_dir, \"kaggle_optiver_trading_at_the_close/processed\"\n",
    "    )\n",
    "\n",
    "    path_data_project_dir = os.path.join(path_data_dir, name_folder_data_project)\n",
    "\n",
    "    path_config_dir = os.path.join(path_project_dir, \"config\")\n",
    "    path_config_train = os.path.join(path_config_dir, \"train_config.yaml\")\n",
    "\n",
    "    path_experiments_storage = os.path.join(\n",
    "        path_data_project_dir, \"experiments_storage\"\n",
    "    )\n",
    "\n",
    "    if download_kaggle_data:\n",
    "        dataset_name = \"ravi20076/optiver-memoryreduceddatasets\"\n",
    "        kaggle_json_path = os.path.join(path_project_dir, \"kaggle.json\")\n",
    "        get_data(\n",
    "            kaggle_json_path,\n",
    "            path_data_project_dir,\n",
    "            dataset_name=dataset_name,\n",
    "            specific_file=None,\n",
    "        )\n",
    "\n",
    "    file_name_df_train = \"train.csv\"\n",
    "    file_name_df_test = \"test.csv\"\n",
    "\n",
    "    path_dataset_train = os.path.join(path_data_project_dir, file_name_df_train)\n",
    "    path_dataset_test = os.path.join(path_data_project_dir, file_name_df_test)\n",
    "\n",
    "if TRAIN:\n",
    "    mlflow.set_tracking_uri(path_experiments_storage)\n",
    "    client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d36b115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:47.535297Z",
     "iopub.status.busy": "2023-11-02T12:57:47.534893Z",
     "iopub.status.idle": "2023-11-02T12:57:47.552431Z",
     "shell.execute_reply": "2023-11-02T12:57:47.551294Z"
    },
    "papermill": {
     "duration": 0.040653,
     "end_time": "2023-11-02T12:57:47.555094",
     "exception": false,
     "start_time": "2023-11-02T12:57:47.514441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=0):\n",
    "    \"\"\"\n",
    "    Iterate through all numeric columns of a dataframe and modify the data type\n",
    "    to reduce memory usage.\n",
    "    \"\"\"\n",
    "\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if (col_type != object) and (col != \"target\"):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    if verbose:\n",
    "        logger.info(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n",
    "        end_mem = df.memory_usage().sum() / 1024**2\n",
    "        logger.info(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n",
    "        decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "        logger.info(f\"Decreased by {decrease:.2f}%\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138fbaa0",
   "metadata": {
    "papermill": {
     "duration": 0.018839,
     "end_time": "2023-11-02T12:57:47.593382",
     "exception": false,
     "start_time": "2023-11-02T12:57:47.574543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4026b348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:47.632532Z",
     "iopub.status.busy": "2023-11-02T12:57:47.632175Z",
     "iopub.status.idle": "2023-11-02T12:57:47.638422Z",
     "shell.execute_reply": "2023-11-02T12:57:47.637606Z"
    },
    "papermill": {
     "duration": 0.028477,
     "end_time": "2023-11-02T12:57:47.640800",
     "exception": false,
     "start_time": "2023-11-02T12:57:47.612323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    if not os.path.exists(path_dataset_processed):\n",
    "        os.makedirs(path_dataset_processed)\n",
    "\n",
    "    if not os.path.exists(path_dataset_train) or OVERWRITE:\n",
    "        df_train_raw = pd.read_csv(path_dataset_train_raw)\n",
    "        \n",
    "    else:\n",
    "        df_train_raw = pd.read_csv(path_dataset_train)\n",
    "\n",
    "    if DEBUG:\n",
    "        df_train_raw = df_train_raw[df_train_raw[\"stock_id\"].isin([0, 1, 2])]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe54f48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:47.679238Z",
     "iopub.status.busy": "2023-11-02T12:57:47.678625Z",
     "iopub.status.idle": "2023-11-02T12:57:47.684133Z",
     "shell.execute_reply": "2023-11-02T12:57:47.683253Z"
    },
    "papermill": {
     "duration": 0.026972,
     "end_time": "2023-11-02T12:57:47.686410",
     "exception": false,
     "start_time": "2023-11-02T12:57:47.659438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    # Dropping rows with null targets:-\n",
    "    drop_idx = df_train_raw.loc[df_train_raw[\"target\"].isna(), \"target\"].index.to_list()\n",
    "    df_train_raw = df_train_raw.drop(drop_idx, axis=0)\n",
    "    df_train_raw.reset_index(drop=True, inplace=True)\n",
    "    df_train_raw = df_train_raw.drop([\"time_id\",\"row_id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cddf2e1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:47.725165Z",
     "iopub.status.busy": "2023-11-02T12:57:47.724265Z",
     "iopub.status.idle": "2023-11-02T12:57:47.781153Z",
     "shell.execute_reply": "2023-11-02T12:57:47.779975Z"
    },
    "papermill": {
     "duration": 0.079601,
     "end_time": "2023-11-02T12:57:47.783768",
     "exception": false,
     "start_time": "2023-11-02T12:57:47.704167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feat_engineering(df_train):\n",
    "    df = pl.DataFrame(df_train)\n",
    "    # 7. Handle Missing Values\n",
    "    df = df.with_columns(\n",
    "        [\n",
    "            pl.col(\"far_price\").fill_null(strategy=\"forward\").alias(\"far_price\"),\n",
    "            pl.col(\"near_price\").fill_null(strategy=\"forward\").alias(\"near_price\"),\n",
    "        ]\n",
    "    )\n",
    "    # Level 1 Features\n",
    "    level_one_features = [\n",
    "        (pl.col(\"imbalance_size\") / pl.col(\"matched_size\")).alias(\n",
    "            \"imbalance_to_matched_size\"\n",
    "        ),\n",
    "        (pl.col(\"imbalance_size\") * pl.col(\"imbalance_buy_sell_flag\")).alias(\n",
    "            \"imbalance_flag_to_size\"\n",
    "        ),\n",
    "        (pl.col(\"ask_price\") - pl.col(\"bid_price\")).alias(\"spread\"),\n",
    "        (pl.col(\"bid_size\") - pl.col(\"ask_size\")).alias(\"bid_ask_imbalance\"),\n",
    "        (pl.col(\"bid_size\") / pl.col(\"ask_size\")).alias(\"liquidity\"),\n",
    "      #  (pl.col(\"ask_size\") - pl.col(\"wap\")).alias(\"size_diff_ask_to_wap\"),\n",
    "        (pl.col(\"wap\") - pl.col(\"wap\").shift(1).over([\"stock_id\", \"date_id\"])).alias(\n",
    "            \"wap_velocity\"\n",
    "        ),\n",
    "        (\n",
    "            pl.col(\"wap\") / pl.col(\"wap\").shift(5).over([\"stock_id\", \"date_id\"]) - 1\n",
    "        ).alias(\"wap_momentum_5\"),\n",
    "        (\n",
    "            pl.col(\"wap\")\n",
    "            .std()\n",
    "            .over([\"stock_id\", \"date_id\"])\n",
    "            .alias(\"short_term_volatility\")\n",
    "        ),\n",
    "        (\n",
    "            (\n",
    "                pl.col(\"imbalance_size\")\n",
    "                / (pl.col(\"matched_size\") + pl.col(\"imbalance_size\"))\n",
    "            ).alias(\"price_impact\")\n",
    "        ),\n",
    "        (\n",
    "            (pl.col(\"bid_size\") - pl.col(\"ask_size\"))\n",
    "            / (pl.col(\"bid_size\") + pl.col(\"ask_size\"))\n",
    "        ).alias(\"order_imbalance_ratio\"),\n",
    "        (\n",
    "            (pl.col(\"ask_price\") - pl.col(\"bid_price\"))\n",
    "            / (pl.col(\"ask_price\") + pl.col(\"bid_price\"))\n",
    "        ).alias(\"price_skewness\"),\n",
    "        (pl.col(\"seconds_in_bucket\") / 600).alias(\"time_decay\"),\n",
    "    ]\n",
    "\n",
    "    # Level 2 Features\n",
    "    level_two_features = [\n",
    "        (\n",
    "            pl.col(\"wap_velocity\")\n",
    "            - pl.col(\"wap_velocity\").shift(1).over([\"stock_id\", \"date_id\"])\n",
    "        ).alias(\"wap_acceleration\"),\n",
    "        (\n",
    "            pl.col(\"short_term_volatility\").shift(1).over([\"stock_id\", \"date_id\"])\n",
    "            - pl.col(\"short_term_volatility\")\n",
    "        ).alias(\"volatility_rate_of_change\"),\n",
    "        (\n",
    "            (\n",
    "                pl.col(\"liquidity\")\n",
    "                - pl.col(\"liquidity\").shift(1).over([\"stock_id\", \"date_id\"])\n",
    "            )\n",
    "            / pl.col(\"liquidity\").shift(1).over([\"stock_id\", \"date_id\"])\n",
    "        ).alias(\"liquidity_ratio_change\"),\n",
    "        (\n",
    "            (\n",
    "                pl.col(\"order_imbalance_ratio\")\n",
    "                - pl.col(\"order_imbalance_ratio\").shift(1).over([\"stock_id\", \"date_id\"])\n",
    "            )\n",
    "            / pl.col(\"order_imbalance_ratio\").shift(1).over([\"stock_id\", \"date_id\"])\n",
    "        ).alias(\"order_imbalance_over_time\"),\n",
    "        (\n",
    "            (\n",
    "                pl.col(\"price_skewness\")\n",
    "                - pl.col(\"price_skewness\").shift(1).over([\"stock_id\", \"date_id\"])\n",
    "            )\n",
    "            / pl.col(\"price_skewness\").shift(1).over([\"stock_id\", \"date_id\"])\n",
    "        ).alias(\"price_skewness_rate_of_change\"),\n",
    "    ]\n",
    "\n",
    "    # Level 3 Features\n",
    "    level_three_aggregations = [\n",
    "        pl.col(\"wap\").mean().alias(\"avg_wap_by_market\"),\n",
    "        pl.col(\"near_price\").mean().alias(\"avg_near_price_by_market\"),\n",
    "        pl.col(\"matched_size\").mean().alias(\"avg_matched_size_by_market\"),\n",
    "        pl.col(\"imbalance_to_matched_size\")\n",
    "        .mean()\n",
    "        .alias(\"avg_imbalance_to_matched_size_by_market\"),\n",
    "        pl.col(\"spread\").mean().alias(\"avg_spread_by_market\"),\n",
    "        pl.col(\"liquidity\").mean().alias(\"avg_liquidity_by_market\"),\n",
    "        pl.col(\"short_term_volatility\").mean().alias(\"avg_market_volatility\"),\n",
    "        pl.col(\"order_imbalance_ratio\").mean().alias(\"avg_market_imbalance\"),\n",
    "        pl.col(\"liquidity\").mean().alias(\"avg_market_liquidity\"),\n",
    "        pl.col(\"price_impact\").mean().alias(\"avg_market_price_impact\"),\n",
    "        pl.col(\"price_skewness\").mean().alias(\"avg_market_price_skewness\"),\n",
    "    ]\n",
    "\n",
    "    # Adding all features and performing join operation\n",
    "    df = df.with_columns(level_one_features)\n",
    "    df = df.with_columns(level_two_features)\n",
    "    group_by_market = df.groupby([\"date_id\", \"seconds_in_bucket\"]).agg(\n",
    "        *level_three_aggregations\n",
    "    )\n",
    "    df = df.join(group_by_market, on=[\"date_id\", \"seconds_in_bucket\"], how=\"left\")\n",
    "\n",
    "    polynomial_and_interaction_features = [\n",
    "        (pl.col(\"seconds_in_bucket\") * pl.col(\"near_price\")).alias(\n",
    "            \"seconds_in_bucket_X_near_price\"\n",
    "        ),\n",
    "        (pl.col(\"matched_size\") * pl.col(\"near_price\")).alias(\n",
    "            \"matched_size_X_near_price\"\n",
    "        ),\n",
    "        (pl.col(\"near_price\") ** 2).alias(\"near_price_squared\"),\n",
    "        (pl.col(\"matched_size\") ** 2).alias(\"matched_size_squared\"),\n",
    "        (pl.col(\"seconds_in_bucket\") * pl.col(\"imbalance_flag_to_size\")).alias(\n",
    "            \"seconds_in_bucket_X_imbalance_flag_to_size\"\n",
    "        ),\n",
    "        (pl.col(\"seconds_in_bucket\") ** 2).alias(\"seconds_in_bucket_squared\"),\n",
    "        (pl.col(\"imbalance_flag_to_size\") ** 2).alias(\"imbalance_flag_to_size_squared\"),\n",
    "    ]\n",
    "\n",
    "    # Relative to Market Features\n",
    "    relative_to_market_features = [\n",
    "        (pl.col(\"wap\") / pl.col(\"avg_wap_by_market\")).alias(\"relative_wap_to_market\"),\n",
    "        (pl.col(\"near_price\") / pl.col(\"avg_near_price_by_market\")).alias(\n",
    "            \"relative_near_price_to_market\"\n",
    "        ),\n",
    "        (pl.col(\"matched_size\") / pl.col(\"avg_matched_size_by_market\")).alias(\n",
    "            \"relative_matched_size_to_market\"\n",
    "        ),\n",
    "        (\n",
    "            pl.col(\"imbalance_to_matched_size\")\n",
    "            / pl.col(\"avg_imbalance_to_matched_size_by_market\")\n",
    "        ).alias(\"relative_imbalance_to_matched_size_to_market\"),\n",
    "        (pl.col(\"spread\") / pl.col(\"avg_spread_by_market\")).alias(\n",
    "            \"relative_spread_to_market\"\n",
    "        ),\n",
    "        (pl.col(\"liquidity\") / pl.col(\"avg_liquidity_by_market\")).alias(\n",
    "            \"relative_liquidity_to_market\"\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Combine all Level 4 features and add them to the DataFrame\n",
    "    all_level_four_features = (\n",
    "        polynomial_and_interaction_features + relative_to_market_features\n",
    "    )\n",
    "    df = df.with_columns(all_level_four_features)\n",
    "\n",
    "    for window in [5, 10]:\n",
    "        rolling_group = df.group_by_rolling(\n",
    "            index_column=\"seconds_in_bucket\",\n",
    "            period=f\"{window}i\",  # 'i' denotes index count (integer)\n",
    "            by=[\"stock_id\", \"date_id\"],\n",
    "            closed=\"left\",  # Adjust as needed\n",
    "        )\n",
    "\n",
    "        # Apply to basic and new features\n",
    "        for col in [\n",
    "            \"wap\",\n",
    "            \"imbalance_size\",\n",
    "            \"bid_price\",\n",
    "            \"ask_price\",\n",
    "            \"relative_wap_to_market\",\n",
    "            \"wap_momentum_5\",\n",
    "        ]:\n",
    "            df = df.join(\n",
    "                rolling_group.agg(pl.col(col).mean().alias(f\"{col}_mean_{window}\")),\n",
    "                on=[\"stock_id\", \"date_id\", \"seconds_in_bucket\"],\n",
    "                how=\"left\",\n",
    "            )\n",
    "\n",
    "    low_importance_cols = [\n",
    "        \"wap_mean_5\",\n",
    "        #\"imbalance_buy_sell_flag\",\n",
    "        \"imbalance_flag_to_size_squared\",\n",
    "        \"imbalance_size_mean_5\",\n",
    "        \"bid_price_mean_5\",\n",
    "        \"ask_price_mean_5\",\n",
    "        \"wap_momentum_5_mean_5\",\n",
    "        \"relative_wap_to_market_mean_5\",\n",
    "        \"volatility_rate_of_change\",\n",
    "        \"avg_market_liquidity\",\n",
    "        \"seconds_in_bucket_squared\",\n",
    "        \"order_imbalance_over_time\"\n",
    "        # Add more columns as needed\n",
    "    ]\n",
    "\n",
    "    existing_cols = df.columns\n",
    "\n",
    "    # Drop columns only if they exist in DataFrame\n",
    "    cols_to_drop = [col for col in low_importance_cols if col in existing_cols]\n",
    "\n",
    "    \n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "\n",
    "   \n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"ask_size\") + pl.col(\"bid_size\")).alias(\"volume\")\n",
    "    )\n",
    "    df = df.with_columns(\n",
    "        ((pl.col(\"ask_price\") + pl.col(\"bid_price\")) / 2).alias(\"mid_price\")\n",
    "    )\n",
    "    df = df.with_columns(\n",
    "        ((pl.col(\"bid_size\") - pl.col(\"ask_size\")) / (pl.col(\"bid_size\") + pl.col(\"ask_size\"))).alias(\"liquidity_imbalance\")\n",
    "    )\n",
    "\n",
    "    for c in combinations(prices, 2):\n",
    "        df = df.with_columns(\n",
    "            ((pl.col(c[0]) - pl.col(c[1])) / (pl.col(c[0]) + pl.col(c[1]))).alias(f\"{c[0]}_{c[1]}_imb\")\n",
    "        )\n",
    "    \n",
    "    \n",
    "    if cols_to_drop:\n",
    "        engineered_df = df.drop(cols_to_drop)\n",
    "    else:\n",
    "        engineered_df = df.to_pandas()\n",
    "\n",
    "    engineered_df = engineered_df.to_pandas()\n",
    "    \n",
    "  \n",
    "\n",
    "    print(\"# V2\")\n",
    "    engineered_df[\"imbalance_momentum\"] = engineered_df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / engineered_df['matched_size']\n",
    " \n",
    "\n",
    "    engineered_df['price_pressure'] = engineered_df['imbalance_size'] * (engineered_df['ask_price'] - engineered_df['bid_price'])\n",
    "    engineered_df['market_urgency'] = engineered_df['spread'] * engineered_df['liquidity_imbalance']\n",
    "    engineered_df['depth_pressure'] = (engineered_df['ask_size'] - engineered_df['bid_size']) * (engineered_df['far_price'] - engineered_df['near_price'])\n",
    "    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n",
    "        engineered_df[f\"all_prices_{func}\"] = engineered_df[prices].agg(func, axis=1)\n",
    "        engineered_df[f\"all_sizes_{func}\"] = engineered_df[sizes].agg(func, axis=1)\n",
    "        \n",
    "    for c in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(c, engineered_df)\n",
    "        engineered_df[triplet_feature.columns] = triplet_feature.values\n",
    "\n",
    "    print(\"V3\")\n",
    "    for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n",
    "        for window in [ 3]:\n",
    "            engineered_df[f\"{col}_shift_{window}\"] = engineered_df.groupby(['stock_id','date_id'])[col].shift(window)\n",
    "            engineered_df[f\"{col}_ret_{window}\"] = engineered_df.groupby(['stock_id','date_id'])[col].pct_change(window)\n",
    "            \n",
    "    for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size']:\n",
    "        for window in [ 3]:\n",
    "            engineered_df[f\"{col}_diff_{window}\"] = engineered_df.groupby([\"stock_id\",'date_id'])[col].diff(window)\n",
    "    \n",
    "    engineered_df[\"dow\"] = engineered_df[\"date_id\"] % 5\n",
    "    engineered_df[\"seconds\"] = engineered_df[\"seconds_in_bucket\"] % 60\n",
    "    engineered_df[\"minute\"] = engineered_df[\"seconds_in_bucket\"] // 60\n",
    "    \n",
    "    \n",
    "    \n",
    "    cols_to_drop = ['near_price_squared', 'matched_size_bid_size_imbalance_size_imb2',\n",
    "       'minute', 'all_prices_kurt', 'imbalance_size_mean_10',\n",
    "       'avg_liquidity_by_market', 'imbalance_size',\n",
    "       'far_price_ask_price_imb', 'far_price_bid_price_imb',\n",
    "       'wap_mean_10', 'matched_size_ask_size_imbalance_size_imb2',\n",
    "       'all_prices_skew', 'all_sizes_skew', 'price_pressure',\n",
    "       'all_sizes_kurt', 'reference_price_far_price_imb',\n",
    "       'far_price_wap_imb', 'relative_liquidity_to_market',\n",
    "       'bid_size_diff_3', 'imbalance_buy_sell_flag',\n",
    "       'matched_size_squared', 'liquidity_ratio_change', 'price_impact',\n",
    "       'ask_price_bid_price_imb', 'seconds',\n",
    "       'bid_size_ask_size_imbalance_size_imb2', 'wap_acceleration',\n",
    "       'ask_size_diff_3', 'depth_pressure',\n",
    "       'imbalance_buy_sell_flag_ret_3','reference_price_far_price_imb', 'all_sizes_skew',\n",
    "       'matched_imbalance', 'relative_near_price_to_market',\n",
    "       'avg_market_imbalance', 'all_sizes_kurt',\n",
    "       'avg_market_price_skewness',\n",
    "       'relative_imbalance_to_matched_size_to_market', 'liquidity',\n",
    "       'far_price_wap_imb', 'relative_wap_to_market_mean_10',\n",
    "       'time_decay', 'matched_size', 'wap_velocity', 'bid_size_diff_3',\n",
    "       'imbalance_to_matched_size',\n",
    "       'bid_size_ask_size_imbalance_size_imb2', 'ask_size_diff_3',\n",
    "       'matched_size_X_near_price', 'bid_size', 'depth_pressure',\n",
    "       'relative_spread_to_market', 'seconds', 'spread',\n",
    "       'bid_price_mean_10', 'ask_price_mean_10', 'ask_size',\n",
    "       'order_imbalance_ratio', 'price_skewness', 'bid_ask_imbalance',\n",
    "       'price_skewness_rate_of_change', 'imbalance_size_mean_10',\n",
    "       'avg_liquidity_by_market', 'imbalance_buy_sell_flag',\n",
    "       'imbalance_size', 'size_diff_ask_to_wap', 'price_diff_ask_to_wap',\n",
    "       'price_diff_bid_to_wap', 'size_diff_bid_to_wap',\n",
    "       'imbalance_buy_sell_flag_ret_3', 'wap_mean_10', 'price_spread',\n",
    "       'wap_acceleration', 'liquidity_ratio_change',\n",
    "       'ask_price_bid_price_imb', 'near_price_squared',\n",
    "       'relative_liquidity_to_market', 'minute', 'liquidity_imbalance',\n",
    "       'price_impact', 'matched_size_squared', 'size_imbalance',\n",
    "       'ask_price_mean_1', 'wap_mean_1', 'wap_momentum_5_mean_3',\n",
    "       'wap_momentum_5_mean_2', 'wap_momentum_5_mean_1', 'wap_mean_3',\n",
    "       'wap_mean_2', 'bid_price_mean_2', 'bid_price_mean_3',\n",
    "       'imbalance_size_mean_2', 'ask_price_mean_3', 'ask_price_mean_2',\n",
    "       'imbalance_size_mean_1', 'relative_wap_to_market_mean_1',\n",
    "       'bid_price_mean_1', 'relative_wap_to_market_mean_2',\n",
    "       'relative_wap_to_market_mean_3', 'imbalance_size_mean_3']\n",
    "    cols_drop_in = [col for col in cols_to_drop if col in engineered_df.columns]\n",
    "    \n",
    "    engineered_df = engineered_df.drop(cols_drop_in, axis=1)\n",
    "\n",
    "            \n",
    "    return engineered_df.replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c27ad",
   "metadata": {
    "papermill": {
     "duration": 0.017498,
     "end_time": "2023-11-02T12:57:47.819363",
     "exception": false,
     "start_time": "2023-11-02T12:57:47.801865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2c9f1bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:47.857094Z",
     "iopub.status.busy": "2023-11-02T12:57:47.856661Z",
     "iopub.status.idle": "2023-11-02T12:57:47.867186Z",
     "shell.execute_reply": "2023-11-02T12:57:47.866024Z"
    },
    "papermill": {
     "duration": 0.031939,
     "end_time": "2023-11-02T12:57:47.869445",
     "exception": false,
     "start_time": "2023-11-02T12:57:47.837506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feat_engineering(df_train):\n",
    "    df = pl.DataFrame(df_train)\n",
    "    df = df.sort([\"stock_id\", \"date_id\", \"seconds_in_bucket\"])\n",
    "\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"seconds_in_bucket\") / 10).cast(pl.Int32).alias(\"seconds_in_bucket\")\n",
    "    )\n",
    "    for window in range(1, 30, 3):\n",
    "        if TRAIN:\n",
    "            print(f\"Processing window size: {window}\")\n",
    "        rolling_group = df.group_by_rolling(\n",
    "            index_column=\"seconds_in_bucket\",\n",
    "            period=f\"{window}i\",  # 'i' denotes index count (integer)\n",
    "            by=[\"stock_id\", \"date_id\"],\n",
    "            closed=\"left\",  # Adjust as needed\n",
    "        )\n",
    "\n",
    "        # Apply to basic and new features\n",
    "        for col in [\"wap\", \"bid_price\", \"ask_price\", \"imbalance_size\"]:\n",
    "            df = df.join(\n",
    "                rolling_group.agg(pl.col(col).mean().alias(f\"{col}_mean_{window}\")),\n",
    "                on=[\"stock_id\", \"date_id\", \"seconds_in_bucket\"],\n",
    "                how=\"left\",\n",
    "            )\n",
    "\n",
    "            df = df.join(\n",
    "                rolling_group.agg(pl.col(col).std().alias(f\"{col}_std_{window}\")),\n",
    "                on=[\"stock_id\", \"date_id\", \"seconds_in_bucket\"],\n",
    "                how=\"left\",\n",
    "            )\n",
    "\n",
    "\n",
    "    return df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87aea14c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:47.907668Z",
     "iopub.status.busy": "2023-11-02T12:57:47.906943Z",
     "iopub.status.idle": "2023-11-02T12:57:47.912383Z",
     "shell.execute_reply": "2023-11-02T12:57:47.911242Z"
    },
    "papermill": {
     "duration": 0.027597,
     "end_time": "2023-11-02T12:57:47.915249",
     "exception": false,
     "start_time": "2023-11-02T12:57:47.887652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    df_train = feat_engineering(df_train_raw)\n",
    "    \n",
    "    #df_train = reduce_mem_usage(df_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa2894",
   "metadata": {
    "papermill": {
     "duration": 0.036415,
     "end_time": "2023-11-02T12:57:48.034902",
     "exception": false,
     "start_time": "2023-11-02T12:57:47.998487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064821a0",
   "metadata": {
    "papermill": {
     "duration": 0.018265,
     "end_time": "2023-11-02T12:57:48.071832",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.053567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3581a9dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:48.111841Z",
     "iopub.status.busy": "2023-11-02T12:57:48.111411Z",
     "iopub.status.idle": "2023-11-02T12:57:48.116364Z",
     "shell.execute_reply": "2023-11-02T12:57:48.115039Z"
    },
    "papermill": {
     "duration": 0.027594,
     "end_time": "2023-11-02T12:57:48.118940",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.091346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#engineered_df = df_train.copy()\n",
    "#numerical_cols = list(engineered_df.select_dtypes(include=['number']).columns)\n",
    "#list_cols = [col for col in numerical_cols if col not in ['stock_id', 'date_id', 'seconds_in_bucket']]\n",
    "#correlation_matrix = engineered_df[list_cols].corr()\n",
    "#high_correlation = correlation_matrix[correlation_matrix > 0.8]\n",
    "\n",
    "# Or, for the highest N correlations\n",
    "#N = 30\n",
    "#highest_correlations = correlation_matrix.unstack().sort_values(ascending=False).drop_duplicates()\n",
    "#highest_N_correlations = highest_correlations.head(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2b711",
   "metadata": {
    "papermill": {
     "duration": 0.018753,
     "end_time": "2023-11-02T12:57:48.156893",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.138140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a2322f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:48.197053Z",
     "iopub.status.busy": "2023-11-02T12:57:48.196622Z",
     "iopub.status.idle": "2023-11-02T12:57:48.209016Z",
     "shell.execute_reply": "2023-11-02T12:57:48.207655Z"
    },
    "papermill": {
     "duration": 0.035584,
     "end_time": "2023-11-02T12:57:48.211701",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.176117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def time_series_split(X, n_splits, n_test_splits, embargo_td=2):\n",
    "    factorized_indices = np.unique(X[\"factorized\"])\n",
    "\n",
    "    # Compute the fold boundaries\n",
    "    fold_bounds = [\n",
    "        (fold[0], fold[-1] + 1) for fold in np.array_split(factorized_indices, n_splits)\n",
    "    ]\n",
    "\n",
    "    # Create the list of all tests test_fold_bounds that will become the test sets\n",
    "    selected_fold_bounds = list(itt.combinations(fold_bounds, n_test_splits))\n",
    "\n",
    "    # Reverse to start the testing from the most recent part of the dataset\n",
    "    selected_fold_bounds.reverse()\n",
    "\n",
    "    for fold_bound_list in selected_fold_bounds:\n",
    "        test_factorized_indices = np.empty(0)\n",
    "        test_fold_bounds = []\n",
    "\n",
    "        for fold_start, fold_end in fold_bound_list:\n",
    "            # Records the boundaries of the current test split\n",
    "            if not test_fold_bounds or fold_start != test_fold_bounds[-1][-1]:\n",
    "                test_fold_bounds.append((fold_start, fold_end))\n",
    "            elif fold_start == test_fold_bounds[-1][-1]:\n",
    "                test_fold_bounds[-1] = (test_fold_bounds[-1][0], fold_end)\n",
    "\n",
    "            test_factorized_indices = np.union1d(\n",
    "                test_factorized_indices, factorized_indices[fold_start:fold_end]\n",
    "            ).astype(int)\n",
    "\n",
    "        # Compute the train set indices\n",
    "        train_indices = np.setdiff1d(factorized_indices, test_factorized_indices)\n",
    "\n",
    "        # Purge and embargo can be added here if needed\n",
    "        # ...\n",
    "\n",
    "        yield train_indices, test_factorized_indices\n",
    "\n",
    "\n",
    "# # Example usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "782b1de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:48.252611Z",
     "iopub.status.busy": "2023-11-02T12:57:48.251400Z",
     "iopub.status.idle": "2023-11-02T12:57:48.258103Z",
     "shell.execute_reply": "2023-11-02T12:57:48.257072Z"
    },
    "papermill": {
     "duration": 0.029259,
     "end_time": "2023-11-02T12:57:48.260600",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.231341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    col_split = \"date_id\"\n",
    "    df_train.sort_values([col_split], inplace=True)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_train[\"factorized\"] = pd.factorize(df_train[col_split])[0]\n",
    "    \n",
    "    list_cols_drop = [\"date_id\",\"stock_id\"]\n",
    "    df_train.drop(list_cols_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c49cce",
   "metadata": {
    "papermill": {
     "duration": 0.018324,
     "end_time": "2023-11-02T12:57:48.297324",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.279000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c997754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:48.335939Z",
     "iopub.status.busy": "2023-11-02T12:57:48.335510Z",
     "iopub.status.idle": "2023-11-02T12:57:48.340490Z",
     "shell.execute_reply": "2023-11-02T12:57:48.339504Z"
    },
    "papermill": {
     "duration": 0.02737,
     "end_time": "2023-11-02T12:57:48.342718",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.315348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    n_estimators_min =n_estimators_max= 50\n",
    "else:\n",
    "    n_estimators_min = 500\n",
    "    n_estimators_max = 500\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665c1f5",
   "metadata": {
    "papermill": {
     "duration": 0.018546,
     "end_time": "2023-11-02T12:57:48.380110",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.361564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b5857e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:48.420076Z",
     "iopub.status.busy": "2023-11-02T12:57:48.418965Z",
     "iopub.status.idle": "2023-11-02T12:57:48.433515Z",
     "shell.execute_reply": "2023-11-02T12:57:48.432183Z"
    },
    "papermill": {
     "duration": 0.037381,
     "end_time": "2023-11-02T12:57:48.436349",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.398968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpu_switch = \"OFF\"\n",
    "n_splits = 5\n",
    "n_test_split = 1\n",
    "embargo_td = 100\n",
    "\n",
    "n_repeats = 1\n",
    "nbrnd_erly_stp = 130\n",
    "\n",
    "cv_mthd = \"KF\"\n",
    "\n",
    "# Cross-Validation Setup\n",
    "if TRAIN:\n",
    "    all_cv = {\"KF\": KFold(n_splits=n_splits, shuffle=True, random_state=state)}\n",
    "    cv = all_cv[cv_mthd]\n",
    "\n",
    "    model_params_dict = {\n",
    "        \"LGBMR\": {\n",
    "            \"static_params\": {\n",
    "                \"device\": \"gpu\" if gpu_switch == \"ON\" else \"cpu\",\n",
    "                \"objective\": \"mae\",\n",
    "                \"boosting_type\": \"gbdt\",\n",
    "                \"random_state\": state,\n",
    "                \"n_jobs\" : 4,\n",
    "                \"verbose\": -1,\n",
    "                \"importance_type\" : \"gain\",\n",
    "            },\n",
    "            \"dynamic_params\": {\n",
    "                \"n_estimators\": {\n",
    "                    \"type\": \"int\",\n",
    "                    \"low\": n_estimators_min,\n",
    "                    \"high\": n_estimators_max,\n",
    "                },\n",
    "                \"learning_rate\": {\n",
    "                    \"type\": \"float\",\n",
    "                    \"low\": 0.01,\n",
    "                    \"high\": 0.05,\n",
    "                },\n",
    "                \"max_depth\": {\"type\": \"int\", \"low\": 20, \"high\": 70},\n",
    "                \"num_leaves\": {\n",
    "                    \"type\": \"int\",\n",
    "                    \"low\": 60,\n",
    "                    \"high\": 300,\n",
    "                },\n",
    "                \"min_child_samples\": {\n",
    "                    \"type\": \"int\",\n",
    "                    \"low\": 20,\n",
    "                    \"high\": 40,\n",
    "                },\n",
    "                \"subsample\": {\n",
    "                    \"type\": \"float\",\n",
    "                    \"low\": 0.7,\n",
    "                    \"high\": 1,\n",
    "                },\n",
    "                \"colsample_bytree\": {\n",
    "                    \"type\": \"float\",\n",
    "                    \"low\": 1,\n",
    "                    \"high\": 1,\n",
    "                },\n",
    "                \"min_split_gain\": {\n",
    "                    \"type\": \"float\",\n",
    "                    \"low\": 0,\n",
    "                    \"high\": 1,\n",
    "                },\n",
    "                \"reg_alpha\": {\n",
    "                    \"type\": \"float\",\n",
    "                    \"low\": 0,\n",
    "                    \"high\": 1,\n",
    "                },\n",
    "                \"reg_lambda\": {\n",
    "                    \"type\": \"float\",\n",
    "                    \"low\": 0,\n",
    "                    \"high\": 1,\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    dict_models = {\"LGBMR\": LGBMR}\n",
    "\n",
    "    log_model = True\n",
    "\n",
    "    experiment_date_str = datetime.now().strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "    experiment_purpose = \"optiver_trading_at_the_close\"\n",
    "    experiment_name = f\"{experiment_purpose}_{experiment_date_str}\"\n",
    "\n",
    "    mlflow.set_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6354e8fc",
   "metadata": {
    "_cell_guid": "334e81a6-b09b-4a3d-96a1-fe0278deff13",
    "_uuid": "4288a49c-b472-4af2-b2bb-95cf0cd2bd6d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:48.475530Z",
     "iopub.status.busy": "2023-11-02T12:57:48.475116Z",
     "iopub.status.idle": "2023-11-02T12:57:48.496214Z",
     "shell.execute_reply": "2023-11-02T12:57:48.495102Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.044377,
     "end_time": "2023-11-02T12:57:48.499294",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.454917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def objective(trial, df_train):\n",
    "    try:\n",
    "        print(f\"trial: {trial.number}\")\n",
    "        with mlflow.start_run() as run:\n",
    "            mlflow.log_param(\"cv_mthd\", cv_mthd)\n",
    "            mlflow.set_tag(\"experiment_purpose\", experiment_purpose)\n",
    "            mlflow.set_tag(\"experiment_name\", experiment_name)\n",
    "            mlflow.set_tag(\"version_nb\", VERSION_NB)\n",
    "            for model_name, model_class in dict_models.items():\n",
    "                model = create_model(\n",
    "                    trial,\n",
    "                    dict_models[model_name],\n",
    "                    model_params_dict[model_name][\"static_params\"],\n",
    "                    model_params_dict[model_name][\"dynamic_params\"],\n",
    "                )\n",
    "                mae_list = []\n",
    "\n",
    "                log_training_details(logger, model, trial, model_name)\n",
    "\n",
    "                for fold_n, (train_indices, test_indices) in enumerate(time_series_split(df_train, n_splits = n_splits, n_test_splits = n_test_split)\n",
    "                ):\n",
    "                  \n",
    "                    with mlflow.start_run(\n",
    "                        run_name=f\"fold_{fold_n+1}\", nested=True\n",
    "                    ) as nested_run:\n",
    "                        mask_train = df_train[\"factorized\"].isin(list(train_indices))\n",
    "                        mask_test = df_train[\"factorized\"].isin(list(test_indices))\n",
    "\n",
    "                        # Filter based on the 'factorized' field\n",
    "                        y_train = df_train.loc[mask_train, \"target\"].squeeze()\n",
    "                        y_val = df_train.loc[mask_test, \"target\"].squeeze()\n",
    "                        X_train = df_train[mask_train].drop([\"target\",\"factorized\"], axis=1)\n",
    "                        X_val = df_train[mask_test].drop([\"target\",\"factorized\"], axis=1)\n",
    "\n",
    "                        mlflow.log_param(\"training_data_rows\", X_train.shape[0])\n",
    "                        mlflow.log_param(\"training_data_columns\", X_train.shape[1])\n",
    "                        \n",
    "                        \n",
    "\n",
    "                        model.fit(\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            eval_set=[(X_val, y_val)],\n",
    "                            eval_metric=\"mae\",\n",
    "                            callbacks=[\n",
    "                                lgbm.callback.early_stopping(stopping_rounds=100),\n",
    "                                lgbm.callback.log_evaluation(period=100),\n",
    "                            ],\n",
    "                            \n",
    "                        )\n",
    "\n",
    "                        log_feature_importance(\n",
    "                            trial.number,\n",
    "                            model,\n",
    "                            X_train,\n",
    "                            fold_n,\n",
    "                            experiment_purpose,\n",
    "                            experiment_date_str,\n",
    "                        )\n",
    "\n",
    "                        fold_mae = model.best_score_[\"valid_0\"][\"l1\"]\n",
    "                        print(model.best_score_)\n",
    "                        mae_list.append(fold_mae)\n",
    "                        logger.info(f\"{fold_n + 1:<5} {'|':<2} {fold_mae:<20}\")\n",
    "\n",
    "                      \n",
    "                        mlflow.log_param(\"fold_number\", fold_n + 1)\n",
    "                        mlflow.log_param(\"model_name\", model_name)\n",
    "                        mlflow.log_param(\"log_model\", log_model)\n",
    "\n",
    "                        params_to_log = model.get_params()\n",
    "                        mlflow.log_params(params_to_log)\n",
    "\n",
    "                        if log_model:\n",
    "                            current_time_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                            model_log_name = (\n",
    "                                f\"{model_name}_{trial.number}_{current_time_str}\"\n",
    "                            )\n",
    "\n",
    "                            mlflow.log_param(\"model_log_name\", model_log_name)\n",
    "\n",
    "                            mlflow.sklearn.log_model(model, model_log_name)\n",
    "\n",
    "                            mlflow.log_param(\"run_time\", current_time_str)\n",
    "\n",
    "                        nested_run_id = nested_run.info.run_id\n",
    "                        model_path = f\"{path_experiments_storage}/{run.info.experiment_id}/{nested_run_id}/artifacts/{model_log_name}/model.pkl\"\n",
    "                        mlflow.log_param(\"model_path\", model_path)\n",
    "                avg_mae = sum(mae_list) / len(mae_list)\n",
    "\n",
    "                mlflow.log_param(\"model_name\", model_name)\n",
    "                mlflow.log_param(\"mae\", avg_mae)\n",
    "\n",
    "                return avg_mae\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An exception occurred: {e}\")\n",
    "        return float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73eaab16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:48.542348Z",
     "iopub.status.busy": "2023-11-02T12:57:48.541653Z",
     "iopub.status.idle": "2023-11-02T12:57:48.547196Z",
     "shell.execute_reply": "2023-11-02T12:57:48.546320Z"
    },
    "papermill": {
     "duration": 0.0282,
     "end_time": "2023-11-02T12:57:48.549478",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.521278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the Optuna study\n",
    "if TRAIN:\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        study_name=\"Your Study Name\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    study.optimize(lambda trial: objective(trial, df_train), n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1f0681",
   "metadata": {
    "papermill": {
     "duration": 0.018287,
     "end_time": "2023-11-02T12:57:48.586457",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.568170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e8a7a2",
   "metadata": {
    "papermill": {
     "duration": 0.018808,
     "end_time": "2023-11-02T12:57:48.623800",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.604992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4a0118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:53:01.400365Z",
     "iopub.status.busy": "2023-11-02T12:53:01.399546Z",
     "iopub.status.idle": "2023-11-02T12:53:01.429458Z",
     "shell.execute_reply": "2023-11-02T12:53:01.428651Z",
     "shell.execute_reply.started": "2023-11-02T12:53:01.400335Z"
    },
    "papermill": {
     "duration": 0.017477,
     "end_time": "2023-11-02T12:57:48.659047",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.641570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8627ea",
   "metadata": {
    "papermill": {
     "duration": 0.018511,
     "end_time": "2023-11-02T12:57:48.695170",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.676659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd63d94",
   "metadata": {
    "papermill": {
     "duration": 0.018139,
     "end_time": "2023-11-02T12:57:48.731554",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.713415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "839461a0",
   "metadata": {
    "_cell_guid": "51030a77-aba3-469f-9c08-7963bc8a09d2",
    "_uuid": "6ff7d358-62f0-4ac9-b028-d1c920bb4eaf",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:48.769569Z",
     "iopub.status.busy": "2023-11-02T12:57:48.768889Z",
     "iopub.status.idle": "2023-11-02T12:57:48.779906Z",
     "shell.execute_reply": "2023-11-02T12:57:48.778891Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.033077,
     "end_time": "2023-11-02T12:57:48.782360",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.749283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def experiments_data(list_experiment_id = None, save_df = None, list_columns = None):\n",
    "    \"\"\"\n",
    "    Ogni volta che viene chiamata questa funzione legge tutti gli esperimenti e ritorna una nuova versione del file con tutti gli esperimenti storicizzati\n",
    "    \"\"\"\n",
    "    experiments = client.search_experiments()\n",
    "    all_runs_data = []\n",
    "    for exp in experiments:\n",
    "        experiment_id = exp.experiment_id\n",
    "        if (list_experiment_id == None) or (experiment_id in list_experiment_id):\n",
    "        \n",
    "            run_infos = client.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "            for run_info in run_infos:\n",
    "                run_data = {\n",
    "                    \"experiment_id\": experiment_id,\n",
    "                    \"experiment_name\": exp.name,\n",
    "                    \"run_id\": run_info.info.run_id,\n",
    "                }\n",
    "\n",
    "                # Add metrics to run_data\n",
    "                for key, value in run_info.data.metrics.items():\n",
    "                    run_data[f\"{key}\"] = value\n",
    "\n",
    "                # Add params to run_data\n",
    "                for key, value in run_info.data.params.items():\n",
    "                    run_data[f\"{key}\"] = value\n",
    "\n",
    "                all_runs_data.append(run_data)\n",
    "        \n",
    "    df_runs_new = pd.DataFrame(all_runs_data)\n",
    "    \n",
    "\n",
    "    \n",
    "    df_runs_new = df_runs_new[~df_runs_new[\"fold_number\"].isna()]\n",
    "    \n",
    "    if list_columns:\n",
    "        df_runs_new = df_runs_new[list_columns]\n",
    "        \n",
    "    if save_df:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "        csv_filename = f\"df_runs_{timestamp}.csv\"\n",
    "        df_runs_new.to_csv(csv_filename, index=False)\n",
    "\n",
    "        print(f\"DataFrame saved to {csv_filename}, Shape: {df_unique.shape}\")\n",
    "\n",
    "    return df_runs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68edcecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:48.821010Z",
     "iopub.status.busy": "2023-11-02T12:57:48.820087Z",
     "iopub.status.idle": "2023-11-02T12:57:48.828233Z",
     "shell.execute_reply": "2023-11-02T12:57:48.826727Z"
    },
    "papermill": {
     "duration": 0.029892,
     "end_time": "2023-11-02T12:57:48.831006",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.801114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    df_exp  = experiments_data(list_experiment_id = None, save_df = None, list_columns = None)\n",
    "    list_base_cols = ['run_time','experiment_id','model_name','fold_number','mae','training_data_rows','training_data_columns'] \n",
    "    list_dynamic_params = list(model_params_dict[\"LGBMR\"]['dynamic_params'].keys())\n",
    "    \n",
    "    \n",
    "    \n",
    "    list_cols_exp = list_base_cols + list_dynamic_params +['model_path']\n",
    "    \n",
    "    \n",
    "    df_exp = df_exp[list_cols_exp]\n",
    "    \n",
    "    df_exp['run_time'] = pd.to_datetime(df_exp['run_time'], format='%Y%m%d_%H%M%S', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f7af1e",
   "metadata": {
    "papermill": {
     "duration": 0.018554,
     "end_time": "2023-11-02T12:57:48.868231",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.849677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a1840f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:48.907309Z",
     "iopub.status.busy": "2023-11-02T12:57:48.906605Z",
     "iopub.status.idle": "2023-11-02T12:57:48.911452Z",
     "shell.execute_reply": "2023-11-02T12:57:48.910633Z"
    },
    "papermill": {
     "duration": 0.027095,
     "end_time": "2023-11-02T12:57:48.913677",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.886582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    list_files_feat_importance = ['/kaggle/working/feat_impor_optiver_trading_at_the_close_20231101_072036.csv','/kaggle/working/feat_impor_optiver_trading_at_the_close_20231031_095537.csv','/kaggle/working/feat_impor_optiver_trading_at_the_close_20231031_132330.csv']\n",
    "\n",
    "\n",
    "\n",
    "    aggregate_feature_importance( list_files_feat_importance)['feat'][-70:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c84268d",
   "metadata": {
    "_cell_guid": "95e6c8a8-62ed-4412-944a-5b08508702fc",
    "_uuid": "60c6783c-1e42-43ca-ba32-bda313deb585",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:48.952243Z",
     "iopub.status.busy": "2023-11-02T12:57:48.951846Z",
     "iopub.status.idle": "2023-11-02T12:57:48.961258Z",
     "shell.execute_reply": "2023-11-02T12:57:48.960106Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.03161,
     "end_time": "2023-11-02T12:57:48.963631",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.932021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensemble_predict(model_paths, X_test):\n",
    "    models = []\n",
    "    predictions = []\n",
    "\n",
    "    # Load models based on full artifact paths\n",
    "    for model_path in model_paths:\n",
    "        try:\n",
    "            # If using direct path to pkl\n",
    "            if model_path.endswith(\".pkl\"):\n",
    "                model = joblib.load(model_path)\n",
    "            else:\n",
    "                print(f\"Unsupported model format for {model_path}. Skipping.\")\n",
    "                continue  # Skip this iteration\n",
    "\n",
    "            models.append(model)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load model at {model_path}. Error: {e}\")\n",
    "\n",
    "    # Make predictions\n",
    "    for model in models:\n",
    "        try:\n",
    "            pred = model.predict(X_test)\n",
    "            predictions.append(pred)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to make prediction with model. Error: {e}\")\n",
    "\n",
    "    # Average predictions\n",
    "    if len(predictions) > 0:\n",
    "        ensemble_pred = np.mean(predictions, axis=0)\n",
    "    else:\n",
    "        print(\"No valid models loaded. Cannot make ensemble predictions.\")\n",
    "        ensemble_pred = None\n",
    "\n",
    "    return ensemble_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c02a69c",
   "metadata": {
    "papermill": {
     "duration": 0.017933,
     "end_time": "2023-11-02T12:57:48.999590",
     "exception": false,
     "start_time": "2023-11-02T12:57:48.981657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e642b97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:49.039121Z",
     "iopub.status.busy": "2023-11-02T12:57:49.038699Z",
     "iopub.status.idle": "2023-11-02T12:57:49.048668Z",
     "shell.execute_reply": "2023-11-02T12:57:49.047819Z"
    },
    "papermill": {
     "duration": 0.032209,
     "end_time": "2023-11-02T12:57:49.051045",
     "exception": false,
     "start_time": "2023-11-02T12:57:49.018836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if TRAIN:\n",
    "    #model_paths = list(df_exp[df_exp['run_time'] >= pd.to_datetime(\"2023-11-01 22:10:54\")]['model_path'])\n",
    "    model_paths = list(df_exp['model_path'])\n",
    "    if not os.path.exists(models_dir):\n",
    "        os.makedirs(models_dir)\n",
    "\n",
    "    for model_path in model_paths:\n",
    "        print(f\"Checking if model path exists: {model_path}\")\n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"File does not exist: {model_path}\")\n",
    "            continue  # Skip to the next iteration\n",
    "\n",
    "        specific_part = model_path.split(\"/\")[-2]\n",
    "        dest_path = os.path.join(models_dir, f\"{specific_part}.pkl\")\n",
    "        if not os.path.exists(dest_path):\n",
    "            print(f\"Copying from {model_path} to {dest_path}\")\n",
    "            shutil.copy(model_path, dest_path)\n",
    "        else:\n",
    "            print(f\"File {dest_path} already exists. Skipping copy.\")\n",
    "\n",
    "    zipf = zipfile.ZipFile(\n",
    "        f\"/kaggle/working/{models_dir}.zip\", \"w\", zipfile.ZIP_DEFLATED\n",
    "    )\n",
    "\n",
    "    # Navigate through the folder and add each file to the ZIP\n",
    "    for root, dirs, files in os.walk(f\"/kaggle/working/{models_dir}\"):\n",
    "        for file in files:\n",
    "            zipf.write(\n",
    "                os.path.join(root, file),\n",
    "                os.path.relpath(\n",
    "                    os.path.join(root, file), f\"/kaggle/working/{models_dir}\"\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    zipf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56af434",
   "metadata": {
    "papermill": {
     "duration": 0.018306,
     "end_time": "2023-11-02T12:57:49.087278",
     "exception": false,
     "start_time": "2023-11-02T12:57:49.068972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4e9a15",
   "metadata": {
    "papermill": {
     "duration": 0.017788,
     "end_time": "2023-11-02T12:57:49.124298",
     "exception": false,
     "start_time": "2023-11-02T12:57:49.106510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52ade04d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:49.163808Z",
     "iopub.status.busy": "2023-11-02T12:57:49.163056Z",
     "iopub.status.idle": "2023-11-02T12:57:49.176785Z",
     "shell.execute_reply": "2023-11-02T12:57:49.175783Z"
    },
    "papermill": {
     "duration": 0.036475,
     "end_time": "2023-11-02T12:57:49.179083",
     "exception": false,
     "start_time": "2023-11-02T12:57:49.142608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of file paths: ['/kaggle/input/models-4/LGBMR_0_20231102_113839.pkl', '/kaggle/input/models-4/LGBMR_0_20231102_121251.pkl', '/kaggle/input/models-4/LGBMR_1_20231102_123627.pkl', '/kaggle/input/models-4/LGBMR_0_20231102_114958.pkl', '/kaggle/input/models-4/LGBMR_0_20231102_122359.pkl', '/kaggle/input/models-4/LGBMR_0_20231102_120127.pkl']\n"
     ]
    }
   ],
   "source": [
    "model_paths = []\n",
    "models_dir_input = models_dir.replace(\"_\", \"-\")\n",
    "directory = f\"/kaggle/input/{models_dir_input}\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(directory):\n",
    "    # Traverse the directory and collect file paths\n",
    "    for filename in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Check if the item is a file (and not a sub-directory)\n",
    "        if os.path.isfile(full_path):\n",
    "            model_paths.append(full_path)\n",
    "else:\n",
    "    print(f\"The directory {directory} does not exist.\")\n",
    "\n",
    "# Print or return the list of file paths\n",
    "print(\"List of file paths:\", model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31fb093",
   "metadata": {
    "papermill": {
     "duration": 0.017759,
     "end_time": "2023-11-02T12:57:49.216343",
     "exception": false,
     "start_time": "2023-11-02T12:57:49.198584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ba2c7",
   "metadata": {
    "papermill": {
     "duration": 0.018855,
     "end_time": "2023-11-02T12:57:49.256814",
     "exception": false,
     "start_time": "2023-11-02T12:57:49.237959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a802351",
   "metadata": {
    "_cell_guid": "79aa495a-7580-497c-b913-8941cf7d0c61",
    "_uuid": "b3efe16f-ca61-4000-94d7-568364d0e11b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:49.296552Z",
     "iopub.status.busy": "2023-11-02T12:57:49.295838Z",
     "iopub.status.idle": "2023-11-02T12:57:49.299904Z",
     "shell.execute_reply": "2023-11-02T12:57:49.299024Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.027415,
     "end_time": "2023-11-02T12:57:49.302776",
     "exception": false,
     "start_time": "2023-11-02T12:57:49.275361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming X_test for predict\n",
    "# ensemble_predictions = ensemble_predict(model_paths, df_test, mlflow_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e6cca21",
   "metadata": {
    "_cell_guid": "d4bfb979-2758-4fe9-8947-399b1c3a574c",
    "_uuid": "bef1a199-0988-4743-813e-99d4308fc9bb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:49.341842Z",
     "iopub.status.busy": "2023-11-02T12:57:49.341126Z",
     "iopub.status.idle": "2023-11-02T12:57:49.363282Z",
     "shell.execute_reply": "2023-11-02T12:57:49.361836Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.04472,
     "end_time": "2023-11-02T12:57:49.366077",
     "exception": false,
     "start_time": "2023-11-02T12:57:49.321357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d9baa8a",
   "metadata": {
    "_cell_guid": "d30f3862-dca2-4242-9db0-ab9750118622",
    "_uuid": "efd9073c-aaef-4135-bf7c-1e892e9aa831",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-02T12:57:49.405387Z",
     "iopub.status.busy": "2023-11-02T12:57:49.404983Z",
     "iopub.status.idle": "2023-11-02T12:58:59.716583Z",
     "shell.execute_reply": "2023-11-02T12:58:59.715627Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 70.33418,
     "end_time": "2023-11-02T12:58:59.719420",
     "exception": false,
     "start_time": "2023-11-02T12:57:49.385240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for test, revealed_targets, sample_prediction in iter_test:\n",
    "    # df_test_raw = pl.DataFrame(test)\n",
    "\n",
    "    feat = feat_engineering(test)\n",
    "    \n",
    "    list_cols_drop = [\"date_id\",\"stock_id\",\"row_id\"]\n",
    "    feat.drop(list_cols_drop, axis=1, inplace=True)\n",
    "\n",
    "    # feat = df_test.to_pandas()\n",
    "\n",
    "    #list_cols_drop = [\"stock_id\", \"date_id\", \"row_id\"]\n",
    "    #feat = feat.drop(list_cols_drop, axis=1)\n",
    "\n",
    "    sample_prediction[\"target\"] = ensemble_predict(model_paths, feat)\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34607df7",
   "metadata": {
    "papermill": {
     "duration": 0.018699,
     "end_time": "2023-11-02T12:58:59.757168",
     "exception": false,
     "start_time": "2023-11-02T12:58:59.738469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1fb042",
   "metadata": {
    "papermill": {
     "duration": 0.018111,
     "end_time": "2023-11-02T12:58:59.793522",
     "exception": false,
     "start_time": "2023-11-02T12:58:59.775411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b347cc",
   "metadata": {
    "papermill": {
     "duration": 0.018275,
     "end_time": "2023-11-02T12:58:59.829879",
     "exception": false,
     "start_time": "2023-11-02T12:58:59.811604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4456160f",
   "metadata": {
    "papermill": {
     "duration": 0.018986,
     "end_time": "2023-11-02T12:58:59.867281",
     "exception": false,
     "start_time": "2023-11-02T12:58:59.848295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe1a2a",
   "metadata": {
    "_cell_guid": "18344629-3cbc-4244-ac34-c8af6b88b0d8",
    "_uuid": "667a4d83-d235-446e-a72c-cf02718a1a7b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01781,
     "end_time": "2023-11-02T12:58:59.904042",
     "exception": false,
     "start_time": "2023-11-02T12:58:59.886232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56360392",
   "metadata": {
    "papermill": {
     "duration": 0.017754,
     "end_time": "2023-11-02T12:58:59.939916",
     "exception": false,
     "start_time": "2023-11-02T12:58:59.922162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ad82644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T12:58:59.981223Z",
     "iopub.status.busy": "2023-11-02T12:58:59.980136Z",
     "iopub.status.idle": "2023-11-02T12:58:59.985201Z",
     "shell.execute_reply": "2023-11-02T12:58:59.984092Z"
    },
    "papermill": {
     "duration": 0.02804,
     "end_time": "2023-11-02T12:58:59.987546",
     "exception": false,
     "start_time": "2023-11-02T12:58:59.959506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#clean_directory_except_one('/kaggle/working/', 'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaaef12",
   "metadata": {
    "_cell_guid": "3ef4ae54-1bb4-4cc3-a7da-a6691a272d30",
    "_uuid": "495a4e04-554d-4ef1-919d-62bc59f089c4",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017845,
     "end_time": "2023-11-02T12:59:00.023660",
     "exception": false,
     "start_time": "2023-11-02T12:59:00.005815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559007d9",
   "metadata": {
    "papermill": {
     "duration": 0.017941,
     "end_time": "2023-11-02T12:59:00.060150",
     "exception": false,
     "start_time": "2023-11-02T12:59:00.042209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f8f7e",
   "metadata": {
    "_cell_guid": "5498ae4b-62e8-4050-91e7-075fc549380f",
    "_uuid": "ce9653b2-7dff-4c5b-af77-5f0ef88b6e86",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017756,
     "end_time": "2023-11-02T12:59:00.096541",
     "exception": false,
     "start_time": "2023-11-02T12:59:00.078785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4feae",
   "metadata": {
    "_cell_guid": "92a8ed18-3a63-464e-9d62-17cea3baed59",
    "_uuid": "0b017968-3b5a-4465-820e-e89659b10afd",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01778,
     "end_time": "2023-11-02T12:59:00.132454",
     "exception": false,
     "start_time": "2023-11-02T12:59:00.114674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f38ef",
   "metadata": {
    "_cell_guid": "f9d19e8d-0074-4ae2-adfb-4c039b700215",
    "_uuid": "b6096d27-d452-4593-9832-d15bfbd83e1b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018525,
     "end_time": "2023-11-02T12:59:00.169024",
     "exception": false,
     "start_time": "2023-11-02T12:59:00.150499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21e03c",
   "metadata": {
    "_cell_guid": "855f8db3-e344-4d4d-b577-36499775f352",
    "_uuid": "fde5edb9-d23d-41ac-92c6-593f299230c2",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01776,
     "end_time": "2023-11-02T12:59:00.205384",
     "exception": false,
     "start_time": "2023-11-02T12:59:00.187624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea01bc3",
   "metadata": {
    "_cell_guid": "82330d89-f35e-4cae-876c-de852438527d",
    "_uuid": "f90f329d-b882-464c-84fc-74a815cfe1cd",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017741,
     "end_time": "2023-11-02T12:59:00.241205",
     "exception": false,
     "start_time": "2023-11-02T12:59:00.223464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d2c91",
   "metadata": {
    "_cell_guid": "ed96eca6-9765-4c90-a6bf-3071518ba2f0",
    "_uuid": "ca1d48b9-5537-491b-9de2-57360edd9844",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017877,
     "end_time": "2023-11-02T12:59:00.277588",
     "exception": false,
     "start_time": "2023-11-02T12:59:00.259711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a2161",
   "metadata": {
    "_cell_guid": "06b24b0a-6515-48c6-b4a0-240865cfc1ea",
    "_uuid": "5e9b8536-f812-432a-ba05-c2f0b0f8994f",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017726,
     "end_time": "2023-11-02T12:59:00.313435",
     "exception": false,
     "start_time": "2023-11-02T12:59:00.295709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 78.548959,
   "end_time": "2023-11-02T12:59:01.153612",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-02T12:57:42.604653",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
