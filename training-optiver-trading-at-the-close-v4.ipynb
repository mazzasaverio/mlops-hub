{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":200.508893,"end_time":"2023-11-10T14:47:32.653955","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-11-10T14:44:12.145062","version":"2.4.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# Constants and Configuration Variables\nDEBUG = True\nTRAIN = True\nTUNING = False\nOVERWRITE_PROCESSED_DATA = True\nN_TRIALS = 10\nSTATE = 42\n\nVERSION_NB = 1\nEXPERIMENT_PURPOSE = \"optiver_trading_at_the_close\"\n\n\n# External general-purpose modules\nimport gc\nimport zipfile\nimport shutil\nimport os\nimport itertools as itt\nfrom itertools import combinations, product\nfrom datetime import datetime\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport joblib\nfrom pathlib import Path\nimport warnings\n\nfrom dotenv import load_dotenv\n\n# Setting pandas options and warning filters\npd.set_option(\"display.max_columns\", None)\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"AWS_ACCESS_KEY_ID\")\nsecret_value_1 = user_secrets.get_secret(\"AWS_DEFAULT_REGION\")\nsecret_value_2 = user_secrets.get_secret(\"AWS_SECRET_ACCESS_KEY\")\ns3_bucket_name = user_secrets.get_secret(\"S3_BUCKET\")\n\n# Set AWS credentials in the environment variables\nos.environ['AWS_ACCESS_KEY_ID'] = secret_value_0\nos.environ['AWS_SECRET_ACCESS_KEY'] = secret_value_2\nos.environ['AWS_DEFAULT_REGION'] = secret_value_1\n\n# Load environment variables\nload_dotenv()\npath_root_project = Path.cwd()\nif path_root_project.name not in [\"working\", \"content\"]:\n    path_root_project = Path(os.getenv(\"ROOT_PATH\") or path_root_project)\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:11:46.345494Z","iopub.execute_input":"2023-11-11T14:11:46.346469Z","iopub.status.idle":"2023-11-11T14:11:47.673482Z","shell.execute_reply.started":"2023-11-11T14:11:46.346418Z","shell.execute_reply":"2023-11-11T14:11:47.672081Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class PathManager:\n    def __init__(self, path_project_dir):\n        self.path_root_project = Path(path_project_dir)\n\n        self.path_data_dir = None\n        self.path_experiments_dir = None\n        self.name_train_file = None\n        self.name_test_file = None\n\n        self.name_project_dir = None\n\n        self.path_experiments_dir = (\n            \"http://ec2-13-38-228-107.eu-west-3.compute.amazonaws.com:5000\"\n        )\n        self.path_artifact_location = (\n            f\"s3://mlflow-v1/kaggle_optiver_trading_at_the_close/\"\n        )\n\n        self.initialize_paths()\n\n    def initialize_paths(self):\n        if self.path_root_project.name == \"working\":\n            self.setup_kaggle_paths()\n        else:\n            self.setup_local_paths()\n\n    def setup_kaggle_paths(self):\n        self.name_project_dir = \"optiver-trading-at-the-close\"\n\n        self.name_train_file = \"train.csv\"\n        self.name_test_file = \"test.csv\"\n\n        self.data_dir = Path(\"/kaggle/input\") / self.name_project_dir\n        self.path_data_train_raw = self.data_dir / self.name_train_file\n        self.path_data_test_raw = self.data_dir / self.name_test_file\n\n        self.path_dataset_processed = \"/kaggle/working/processed_data\"\n        # path_dataset_train = os.path.join(path_dataset_processed, \"train.csv\")\n        # path_dataset_test = os.path.join(path_dataset_processed, \"test.csv\")\n\n    def setup_local_paths(self):\n        self.name_project_dir = \"kaggle_optiver_trading_at_the_close\"\n        self.data_dir = self.path_root_project / \"data\" / self.name_project_dir\n\n        self.path_data_train_raw = self.data_dir / \"raw\" / \"train.csv\"\n        self.path_data_test_raw = self.data_dir / \"raw\" / \"test.csv\"\n\n        self.path_dataset_processed = self.path_root_project / \"data\" / \"processed\"\n        # path_dataset_train = path_dataset_processed / \"train.csv\"\n        # path_dataset_test = path_dataset_processed / \"test.csv\"\n        \npm = PathManager(path_root_project)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:11:47.682572Z","iopub.execute_input":"2023-11-11T14:11:47.683066Z","iopub.status.idle":"2023-11-11T14:11:47.696422Z","shell.execute_reply.started":"2023-11-11T14:11:47.683018Z","shell.execute_reply":"2023-11-11T14:11:47.694861Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Conditional imports and settings based on TRAIN constant\nif TRAIN:\n    if pm.path_root_project.name == \"working\":\n        !pip install loguru mlflow optuna > /dev/null\n\n    # External Libraries\n    import boto3\n    import lightgbm as lgbm\n    import mlflow\n    import optuna\n    from mlflow.tracking import MlflowClient\n    from optuna.integration.mlflow import MLflowCallback\n    from sklearn.model_selection import KFold\n    from tqdm import tqdm\n    from xgboost import XGBRegressor as XGBR\n    from lightgbm import log_evaluation, early_stopping, LGBMRegressor as LGBMR\n\n    # Local Modules Imports\n    from utils import log_feature_importance, create_model, log_training_details, aggregate_feature_importance, get_data, clean_directory_except_one, experiments_data, reduce_mem_usage\n    from fe_optiver_trading_at_the_close import calculate_triplet_imbalance_numba, compute_triplet_imbalance, convert_weights_to_dict\n    \n    # Auto-reload modules - Specific to Jupyter Notebooks\n    %load_ext autoreload\n    %autoreload 2\n\n    mlflow.set_tracking_uri(pm.path_experiments_dir)\n    client = MlflowClient()\n    \n    s3_client = boto3.client('s3')\n","metadata":{"papermill":{"duration":2.491736,"end_time":"2023-11-10T14:44:18.409438","exception":false,"start_time":"2023-11-10T14:44:15.917702","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:11:47.698635Z","iopub.execute_input":"2023-11-11T14:11:47.699166Z","iopub.status.idle":"2023-11-11T14:12:07.466354Z","shell.execute_reply.started":"2023-11-11T14:11:47.699130Z","shell.execute_reply":"2023-11-11T14:12:07.464938Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    if not os.path.exists(pm.path_dataset_processed) or OVERWRITE_PROCESSED_DATA:\n        df_train_raw = pd.read_csv(pm.path_data_train_raw)\n\n        if DEBUG:\n            df_train_raw = df_train_raw[df_train_raw[\"stock_id\"].isin([0, 1, 2])]\n\n        drop_idx = df_train_raw.loc[\n            df_train_raw[\"target\"].isna(), \"target\"\n        ].index.to_list()\n        df_train = df_train_raw.drop(drop_idx, axis=0)\n        df_train.reset_index(drop=True, inplace=True)\n    else:\n        df_train = pd.read_csv(pm.path_dataset_processed)\n        if DEBUG:\n            df_train = df_train[df_train[\"stock_id\"].isin([0, 1, 2])]","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:12:07.470265Z","iopub.execute_input":"2023-11-11T14:12:07.471158Z","iopub.status.idle":"2023-11-11T14:12:25.775322Z","shell.execute_reply.started":"2023-11-11T14:12:07.471118Z","shell.execute_reply":"2023-11-11T14:12:25.773948Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    global_stock_id_feats = {\n        \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median()\n        + df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n        \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std()\n        + df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n        \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max()\n        - df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n        \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median()\n        + df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n        \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std()\n        + df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n        \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max()\n        - df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n    }","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:12:25.777064Z","iopub.execute_input":"2023-11-11T14:12:25.777426Z","iopub.status.idle":"2023-11-11T14:12:25.881404Z","shell.execute_reply.started":"2023-11-11T14:12:25.777396Z","shell.execute_reply":"2023-11-11T14:12:25.880399Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\ndef get_experiments_df(client):\n    experiments =client.search_experiments()\n    data = []\n    for exp in experiments:\n        exp_detail = {\n            \"Experiment ID\": exp.experiment_id,\n            \"Creation Time\": datetime.fromtimestamp(exp.creation_time / 1000.0),\n            \"Name\": exp.name,\n            \"Artifact Location\": exp.artifact_location,\n            \"Lifecycle Stage\": exp.lifecycle_stage\n        }\n        data.append(exp_detail)\n\n    df = pd.DataFrame(data)\n    return df\n\ndf_experiments = get_experiments_df(client)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:12:25.883702Z","iopub.execute_input":"2023-11-11T14:12:25.884174Z","iopub.status.idle":"2023-11-11T14:12:26.311848Z","shell.execute_reply.started":"2023-11-11T14:12:25.884143Z","shell.execute_reply":"2023-11-11T14:12:26.310635Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_experiments","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:12:26.313837Z","iopub.execute_input":"2023-11-11T14:12:26.314211Z","iopub.status.idle":"2023-11-11T14:12:26.388432Z","shell.execute_reply.started":"2023-11-11T14:12:26.314179Z","shell.execute_reply":"2023-11-11T14:12:26.387084Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"        Experiment ID           Creation Time  \\\n0  462236245386961179 2023-11-11 13:50:58.934   \n1  275946284308535692 2023-11-11 13:44:48.776   \n2  592537742477651992 2023-11-11 13:39:12.211   \n3  500744986040112169 2023-11-11 13:38:11.856   \n4  195291970476306379 2023-11-11 13:37:52.807   \n5                   0 2023-11-10 19:26:01.927   \n\n                                         Name  \\\n0             optiver_trading_at_the_close_v1   \n1  23_11_11_1344_optiver_trading_at_the_close   \n2  23_11_11_1339_optiver_trading_at_the_close   \n3  23_11_11_1338_optiver_trading_at_the_close   \n4  23_11_11_1337_optiver_trading_at_the_close   \n5                                     Default   \n\n                                   Artifact Location Lifecycle Stage  \n0  s3://mlflow-v1/kaggle_optiver_trading_at_the_c...          active  \n1  s3://mlflow-v1/kaggle_optiver_trading_at_the_c...          active  \n2  s3://mlflow-v1/kaggle_optiver_trading_at_the_c...          active  \n3  s3://mlflow-v1/kaggle_optiver_trading_at_the_c...          active  \n4  s3://mlflow-v1/kaggle_optiver_trading_at_the_c...          active  \n5  s3://mlflow-v1/kaggle_optiver_trading_at_the_c...          active  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Experiment ID</th>\n      <th>Creation Time</th>\n      <th>Name</th>\n      <th>Artifact Location</th>\n      <th>Lifecycle Stage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>462236245386961179</td>\n      <td>2023-11-11 13:50:58.934</td>\n      <td>optiver_trading_at_the_close_v1</td>\n      <td>s3://mlflow-v1/kaggle_optiver_trading_at_the_c...</td>\n      <td>active</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>275946284308535692</td>\n      <td>2023-11-11 13:44:48.776</td>\n      <td>23_11_11_1344_optiver_trading_at_the_close</td>\n      <td>s3://mlflow-v1/kaggle_optiver_trading_at_the_c...</td>\n      <td>active</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>592537742477651992</td>\n      <td>2023-11-11 13:39:12.211</td>\n      <td>23_11_11_1339_optiver_trading_at_the_close</td>\n      <td>s3://mlflow-v1/kaggle_optiver_trading_at_the_c...</td>\n      <td>active</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>500744986040112169</td>\n      <td>2023-11-11 13:38:11.856</td>\n      <td>23_11_11_1338_optiver_trading_at_the_close</td>\n      <td>s3://mlflow-v1/kaggle_optiver_trading_at_the_c...</td>\n      <td>active</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>195291970476306379</td>\n      <td>2023-11-11 13:37:52.807</td>\n      <td>23_11_11_1337_optiver_trading_at_the_close</td>\n      <td>s3://mlflow-v1/kaggle_optiver_trading_at_the_c...</td>\n      <td>active</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>2023-11-10 19:26:01.927</td>\n      <td>Default</td>\n      <td>s3://mlflow-v1/kaggle_optiver_trading_at_the_c...</td>\n      <td>active</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import boto3\nfrom mlflow.tracking import MlflowClient\nfrom mlflow.exceptions import MlflowException\n\ndef delete_experiment_and_artifacts(experiment_ids, bucket_name):\n    client = MlflowClient()\n    s3 = boto3.resource('s3')\n    bucket = s3.Bucket(bucket_name)\n\n    for exp_id in experiment_ids:\n        try:\n            # Get experiment data to find the artifact location\n            experiment_data = client.get_experiment(exp_id)\n            artifact_uri = experiment_data.artifact_location\n\n            # Assuming the artifact URI is an S3 path\n            if \"s3://\" in artifact_uri:\n                artifact_path = artifact_uri.replace(f\"s3://{bucket_name}/\", \"\")\n\n                # Delete artifacts from S3 corresponding to the experiment ID\n                # It's crucial that the artifact_path is specific to the experiment\n                if exp_id in artifact_path:\n                    bucket.objects.filter(Prefix=artifact_path).delete()\n\n            # Delete the experiment from MLflow\n            client.delete_experiment(exp_id)\n            print(f\"Deleted experiment {exp_id} and its artifacts.\")\n\n        except MlflowException as e:\n            print(f\"Error deleting experiment {exp_id}: {e}\")\n\n# Example usage\nexperiment_ids_to_delete = [\"521097711691933856\"]  \ndelete_experiment_and_artifacts(experiment_ids_to_delete, s3_bucket_name)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:12:26.390641Z","iopub.execute_input":"2023-11-11T14:12:26.391546Z","iopub.status.idle":"2023-11-11T14:12:27.037812Z","shell.execute_reply.started":"2023-11-11T14:12:26.391497Z","shell.execute_reply":"2023-11-11T14:12:27.036849Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Error deleting experiment 521097711691933856: RESOURCE_DOES_NOT_EXIST: Could not find experiment with ID 521097711691933856\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate imbalance features\ndef imbalance_features(df):\n    prices = [\n        \"reference_price\",\n        \"far_price\",\n        \"near_price\",\n        \"ask_price\",\n        \"bid_price\",\n        \"wap\",\n    ]\n    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n\n    # V1\n    df[\"volume\"] = df.eval(\"ask_size + bid_size\")\n    df[\"mid_price\"] = df.eval(\"(ask_price + bid_price) / 2\")\n    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n    df[\"matched_imbalance\"] = df.eval(\n        \"(imbalance_size-matched_size)/(matched_size+imbalance_size)\"\n    )\n    df[\"size_imbalance\"] = df.eval(\"bid_size / ask_size\")\n\n    for c in combinations(prices, 2):\n        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\")\n\n    for c in [[\"ask_price\", \"bid_price\", \"wap\", \"reference_price\"], sizes]:\n        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n        df[triplet_feature.columns] = triplet_feature.values\n\n    # V2\n    weights = convert_weights_to_dict()\n    df[\"stock_weights\"] = df[\"stock_id\"].map(weights)\n    df[\"weighted_wap\"] = df[\"stock_weights\"] * df[\"wap\"]\n    df[\"wap_momentum\"] = df.groupby(\"stock_id\")[\"weighted_wap\"].pct_change(periods=6)\n    df[\"imbalance_momentum\"] = (\n        df.groupby([\"stock_id\"])[\"imbalance_size\"].diff(periods=1) / df[\"matched_size\"]\n    )\n    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n    df[\"spread_intensity\"] = df.groupby([\"stock_id\"])[\"price_spread\"].diff()\n    df[\"price_pressure\"] = df[\"imbalance_size\"] * (df[\"ask_price\"] - df[\"bid_price\"])\n    df[\"market_urgency\"] = df[\"price_spread\"] * df[\"liquidity_imbalance\"]\n    df[\"depth_pressure\"] = (df[\"ask_size\"] - df[\"bid_size\"]) * (\n        df[\"far_price\"] - df[\"near_price\"]\n    )\n    df[\"spread_depth_ratio\"] = (df[\"ask_price\"] - df[\"bid_price\"]) / (\n        df[\"bid_size\"] + df[\"ask_size\"]\n    )\n    df[\"mid_price_movement\"] = (\n        df[\"mid_price\"]\n        .diff(periods=5)\n        .apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n    )\n    df[\"micro_price\"] = (\n        (df[\"bid_price\"] * df[\"ask_size\"]) + (df[\"ask_price\"] * df[\"bid_size\"])\n    ) / (df[\"bid_size\"] + df[\"ask_size\"])\n    df[\"relative_spread\"] = (df[\"ask_price\"] - df[\"bid_price\"]) / df[\"wap\"]\n\n    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n\n    # V3\n    for col in [\n        \"matched_size\",\n        \"imbalance_size\",\n        \"reference_price\",\n        \"imbalance_buy_sell_flag\",\n    ]:\n        for window in [1, 2, 3, 5, 10]:\n            df[f\"{col}_shift_{window}\"] = df.groupby([\"stock_id\"])[col].shift(window)\n            df[f\"{col}_ret_{window}\"] = df.groupby([\"stock_id\"])[col].pct_change(window)\n\n    for col in [\n        \"ask_price\",\n        \"bid_price\",\n        \"ask_size\",\n        \"bid_size\",\n        \"wap\",\n        \"near_price\",\n        \"far_price\",\n    ]:\n        for window in [1, 2, 3, 5, 10]:\n            df[f\"{col}_diff_{window}\"] = df.groupby([\"stock_id\"])[col].diff(window)\n\n    return df.replace([np.inf, -np.inf], 0)\n\n\n# generate time & stock features\ndef other_features(df):\n    df[\"dow\"] = df[\"date_id\"] % 5\n    df[\"dom\"] = df[\"date_id\"] % 20\n    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60\n    df[\"minute\"] = df[\"seconds_in_bucket\"] // 60\n\n    for key, value in global_stock_id_feats.items():\n        df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n\n    return df\n\n\n# generate all features\ndef feat_engineering(df):\n    cols = [c for c in df.columns if c not in [\"row_id\"]]\n    df = df[cols]\n    df = imbalance_features(df)\n    df = other_features(df)\n    gc.collect()\n\n    list_cols = [i for i in df.columns if i not in [\"row_id\"]]\n\n    return df[list_cols]","metadata":{"papermill":{"duration":0.162358,"end_time":"2023-11-10T14:44:19.098720","exception":false,"start_time":"2023-11-10T14:44:18.936362","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:12:27.039457Z","iopub.execute_input":"2023-11-11T14:12:27.039864Z","iopub.status.idle":"2023-11-11T14:12:27.121045Z","shell.execute_reply.started":"2023-11-11T14:12:27.039831Z","shell.execute_reply":"2023-11-11T14:12:27.120076Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    df_train_feats = feat_engineering(df_train)\n    print(\"Build Online Train Feats Finished.\")\n\n    df_train_feats = reduce_mem_usage(df_train_feats)\n\n    df_train = df_train_feats.copy()\n\n    del df_train_feats","metadata":{"papermill":{"duration":0.031835,"end_time":"2023-11-10T14:44:19.195928","exception":false,"start_time":"2023-11-10T14:44:19.164093","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:12:27.122189Z","iopub.execute_input":"2023-11-11T14:12:27.122545Z","iopub.status.idle":"2023-11-11T14:12:30.790190Z","shell.execute_reply.started":"2023-11-11T14:12:27.122514Z","shell.execute_reply":"2023-11-11T14:12:30.788847Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Build Online Train Feats Finished.\n","output_type":"stream"}]},{"cell_type":"code","source":"def time_series_split(X, n_splits, n_test_splits, embargo_td=2):\n    factorized_indices = np.unique(X[\"factorized\"])\n\n    # Compute the fold boundaries\n    fold_bounds = [\n        (fold[0], fold[-1] + 1) for fold in np.array_split(factorized_indices, n_splits)\n    ]\n\n    # Create the list of all tests test_fold_bounds that will become the test sets\n    selected_fold_bounds = list(itt.combinations(fold_bounds, n_test_splits))\n\n    # Reverse to start the testing from the most recent part of the dataset\n    selected_fold_bounds.reverse()\n\n    for fold_bound_list in selected_fold_bounds:\n        test_factorized_indices = np.empty(0)\n        test_fold_bounds = []\n\n        for fold_start, fold_end in fold_bound_list:\n            # Records the boundaries of the current test split\n            if not test_fold_bounds or fold_start != test_fold_bounds[-1][-1]:\n                test_fold_bounds.append((fold_start, fold_end))\n            elif fold_start == test_fold_bounds[-1][-1]:\n                test_fold_bounds[-1] = (test_fold_bounds[-1][0], fold_end)\n\n            test_factorized_indices = np.union1d(\n                test_factorized_indices, factorized_indices[fold_start:fold_end]\n            ).astype(int)\n\n        # Compute the train set indices\n        train_indices = np.setdiff1d(factorized_indices, test_factorized_indices)\n\n        # Purge and embargo can be added here if needed\n        # ...\n\n        yield train_indices, test_factorized_indices","metadata":{"papermill":{"duration":0.031577,"end_time":"2023-11-10T14:44:19.304003","exception":false,"start_time":"2023-11-10T14:44:19.272426","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:12:30.792156Z","iopub.execute_input":"2023-11-11T14:12:30.792519Z","iopub.status.idle":"2023-11-11T14:12:30.859118Z","shell.execute_reply.started":"2023-11-11T14:12:30.792486Z","shell.execute_reply":"2023-11-11T14:12:30.857538Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    col_split = \"date_id\"\n    df_train.sort_values([col_split], inplace=True)\n    df_train.reset_index(drop=True, inplace=True)\n    df_train[\"factorized\"] = pd.factorize(df_train[col_split])[0]\n\n    list_cols_drop = [\"date_id\", \"time_id\"]\n    df_train.drop(list_cols_drop, axis=1, inplace=True)","metadata":{"papermill":{"duration":0.026978,"end_time":"2023-11-10T14:44:19.346471","exception":false,"start_time":"2023-11-10T14:44:19.319493","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:12:30.861408Z","iopub.execute_input":"2023-11-11T14:12:30.863101Z","iopub.status.idle":"2023-11-11T14:12:30.964372Z","shell.execute_reply.started":"2023-11-11T14:12:30.863049Z","shell.execute_reply":"2023-11-11T14:12:30.962802Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.017992,"end_time":"2023-11-10T14:44:19.447847","exception":false,"start_time":"2023-11-10T14:44:19.429855","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEBUG:\n    n_estimators_min = n_estimators_max = 50\nelse:\n    n_estimators_min = 100\n    n_estimators_max = 100","metadata":{"papermill":{"duration":0.028073,"end_time":"2023-11-10T14:44:19.491497","exception":false,"start_time":"2023-11-10T14:44:19.463424","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:12:30.969121Z","iopub.execute_input":"2023-11-11T14:12:30.969508Z","iopub.status.idle":"2023-11-11T14:12:31.025538Z","shell.execute_reply.started":"2023-11-11T14:12:30.969478Z","shell.execute_reply":"2023-11-11T14:12:31.024082Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from collections import OrderedDict\nimport mlflow\n\ndef log_model_parameters(model, priority_params, excluded_params):\n    \"\"\"\n    Logs the model's parameters to MLflow, with priority parameters logged first.\n\n    Parameters:\n    model: The model object with a get_params() method.\n    priority_params (list): A list of parameter names to log first.\n    excluded_params (list): A list of parameter names to exclude from logging.\n    \"\"\"\n    params_to_log = model.get_params()\n    \n    # Create an OrderedDict to keep the priority parameters first\n    ordered_params = OrderedDict()\n\n    # Add the priority parameters with rounding if they are floats or ints\n    for key in priority_params:\n        if key in params_to_log:\n            value = params_to_log[key]\n            if isinstance(value, (int, float)):\n                ordered_params[key] = round(value, 5)\n            else:\n                ordered_params[key] = value\n\n    # Add the remaining parameters, excluding the ones in excluded_params and already added priority keys\n    for key, value in params_to_log.items():\n        if key not in excluded_params and key not in priority_params:\n            if isinstance(value, (int, float)):\n                ordered_params[key] = round(value, 5)\n            else:\n                ordered_params[key] = value\n\n    return ordered_params\n    \n","metadata":{"papermill":{"duration":0.015225,"end_time":"2023-11-10T14:44:19.523011","exception":false,"start_time":"2023-11-10T14:44:19.507786","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:12:31.027167Z","iopub.execute_input":"2023-11-11T14:12:31.027518Z","iopub.status.idle":"2023-11-11T14:12:31.090263Z","shell.execute_reply.started":"2023-11-11T14:12:31.027488Z","shell.execute_reply":"2023-11-11T14:12:31.088578Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_or_create_experiment(client, experiment_name, artifact_location):\n    \"\"\"\n    Get the ID of an existing MLflow experiment with the given name or create a new one if it\n    does not exist.\n\n    Parameters:\n    experiment_name (str): The name of the experiment.\n    artifact_location (str): The location for storing artifacts for the experiment.\n\n    Returns:\n    str: The experiment ID of the existing or newly created experiment.\n    \"\"\"\n\n    try:\n        # Check if the experiment already exists\n        experiment = client.get_experiment_by_name(experiment_name)\n        if experiment:\n            experiment_id = experiment.experiment_id\n            print(f\"Experiment '{experiment_name}' already exists with ID {experiment_id}.\")\n        else:\n            # If the experiment does not exist, create it\n            experiment_id = client.create_experiment(name=experiment_name, artifact_location=artifact_location)\n            print(f\"Created new experiment with ID {experiment_id}.\")\n            \n    except MlflowException as e:\n        raise e\n    \n    return experiment_id","metadata":{"execution":{"iopub.status.busy":"2023-11-11T14:16:03.586739Z","iopub.execute_input":"2023-11-11T14:16:03.587255Z","iopub.status.idle":"2023-11-11T14:16:03.814367Z","shell.execute_reply.started":"2023-11-11T14:16:03.587217Z","shell.execute_reply":"2023-11-11T14:16:03.812875Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"experiment_name = f\"{EXPERIMENT_PURPOSE}_v{VERSION_NB}\"\nname_folder_models = f\"models_v{VERSION_NB}\"\n\nexperiment_date_str = datetime.now().strftime(\"%y_%m_%d_%H%M\")\nexperiment_id = get_or_create_experiment(client, experiment_name, artifact_location=pm.path_artifact_location)\n\n\ngpu_switch = \"OFF\"\nn_splits = 6\nn_test_split = 1\nembargo_td = 100\n\nn_repeats = 1\nnbrnd_erly_stp = 130\n\ncv_mthd = \"KF\"\n\n# Cross-Validation Setup\nif TRAIN:\n    # Initialize MLflow callback\n    mlflow_callback = MLflowCallback(\n        tracking_uri=mlflow.get_tracking_uri(), metric_name=\"mae\"\n    )\n\n    all_cv = {\"KF\": KFold(n_splits=n_splits, shuffle=True, random_state=STATE)}\n    cv = all_cv[cv_mthd]\n\n    model_params_dict = {\n        \"LGBMR\": {\n            \"static_params\": {\n                \"device\": \"gpu\" if gpu_switch == \"ON\" else \"cpu\",\n                \"objective\": \"mae\",\n                \"boosting_type\": \"gbdt\",\n                \"random_state\": STATE,\n                \"n_jobs\": 4,\n                \"verbose\": -1,\n                \"importance_type\": \"gain\",\n            },\n            \"dynamic_params\": {\n                \"n_estimators\": {\n                    \"type\": \"int\",\n                    \"low\": n_estimators_min,\n                    \"high\": n_estimators_max,\n                },\n                \"learning_rate\": {\n                    \"type\": \"float\",\n                    \"low\": 0.005,\n                    \"high\": 0.06,\n                },\n                \"max_depth\": {\"type\": \"int\", \"low\": 10, \"high\": 90},\n                \"num_leaves\": {\n                    \"type\": \"int\",\n                    \"low\": 20,\n                    \"high\": 90,\n                },\n                \"min_child_samples\": {\n                    \"type\": \"int\",\n                    \"low\": 10,\n                    \"high\": 70,\n                },\n                \"subsample\": {\n                    \"type\": \"float\",\n                    \"low\": 0.7,\n                    \"high\": 1,\n                },\n                \"colsample_bytree\": {\n                    \"type\": \"float\",\n                    \"low\": 1,\n                    \"high\": 1,\n                },\n                \"min_split_gain\": {\n                    \"type\": \"float\",\n                    \"low\": 0,\n                    \"high\": 2,\n                },\n                \"reg_alpha\": {\n                    \"type\": \"float\",\n                    \"low\": 0,\n                    \"high\": 3,\n                },\n                \"reg_lambda\": {\n                    \"type\": \"float\",\n                    \"low\": 0,\n                    \"high\": 3,\n                },\n            },\n        },\n    }\n\n    dict_models = {\"LGBMR\": LGBMR}\n\n    log_model = True\n\n   \n\n    \n    \n\ndef get_params_trained_models(model_path):\n    model = joblib.load(model_path)\n    return model.get_params()\n\n\nif TRAIN:\n    dict_fixed_model_params = get_params_trained_models(\n        \"/kaggle/input/models-6/LGBMR_0_20231108_235435.pkl\"\n    )\n\nif TRAIN:\n    args = {\n        \"cv_mthd\": cv_mthd,\n        \"experiment_purpose\": EXPERIMENT_PURPOSE,\n        \"experiment_name\": experiment_name,\n        \"dict_models\": dict_models,\n        \"model_params_dict\": model_params_dict,\n        \"n_splits\": n_splits,\n        \"n_test_split\": n_test_split,\n        \"experiment_date_str\": experiment_date_str,\n        \"path_experiments_storage\": pm.path_experiments_dir,\n        \"target_col\": \"target\",\n    }\n\ndef run_mlflow_experiment(df_train, args, trial=None):\n    cv_mthd = args[\"cv_mthd\"]\n    experiment_purpose = args[\"experiment_purpose\"]\n    experiment_name = args[\"experiment_name\"]\n    dict_models = args[\"dict_models\"]\n    model_params_dict = args[\"model_params_dict\"]\n\n    n_splits = args[\"n_splits\"]\n    n_test_split = args[\"n_test_split\"]\n    experiment_date_str = args[\"experiment_date_str\"]\n    path_experiments_storage = args[\"path_experiments_storage\"]\n    target_col = args[\"target_col\"]\n\n    if trial == None:\n        trial = optuna.trial.FixedTrial(\n            {\n                \"n_estimators\": 500,\n                \"learning_rate\": 0.005,\n                \"max_depth\": 10,\n                \"num_leaves\": 20,\n                \"min_child_samples\": 10,\n                \"subsample\": 0.7,\n                \"colsample_bytree\": 1.0,\n                \"min_split_gain\": 0.0,\n                \"reg_alpha\": 0.0,\n                \"reg_lambda\": 0.0,\n                \"device\": \"gpu\" if gpu_switch == \"ON\" else \"cpu\",\n            }\n        )\n\n    run_time_start_trial = datetime.now().strftime(\"%y_%m_%d_%H%M%S\")\n    \n    with mlflow.start_run(run_name=run_time_start_trial, experiment_id = experiment_id) as run:\n        score_list = []\n        \n        mlflow.set_tag(\"cv_mthd\", cv_mthd)\n\n        for model_name, model_class in dict_models.items():\n            if TUNING:\n                model = create_model(\n                    trial,\n                    model_class,\n                    model_params_dict[model_name][\"static_params\"],\n                    model_params_dict[model_name][\"dynamic_params\"],\n                )\n            else:\n                \n                model = model_class(**dict_fixed_model_params)\n                \n\n            priority_params = ['learning_rate', 'max_depth']\n            excluded_params = ['device', 'class_weight','random_state','silent','verbose','n_jobs']\n\n            \n            ordered_params = log_model_parameters(model, priority_params, excluded_params)\n\n            mlflow.log_params(ordered_params)\n         \n            print(ordered_params)\n            \n\n            for fold_n, (train_indices, test_indices) in enumerate(\n                time_series_split(\n                    df_train, n_splits=n_splits, n_test_splits=n_test_split\n                )\n            ):\n                with mlflow.start_run(\n                    run_name=f\"fold_{fold_n+1}\", nested=True, experiment_id = experiment_id\n                ) as nested_run:\n                    \n                    mlflow.set_tag(\"n_trial\", str(trial.number))\n            \n                    mask_train = df_train[\"factorized\"].isin(train_indices)\n                    mask_test = df_train[\"factorized\"].isin(test_indices)\n\n                    y_train = df_train.loc[mask_train, target_col]\n                    y_val = df_train.loc[mask_test, target_col]\n                    X_train = df_train.loc[mask_train].drop(\n                        [target_col, \"factorized\"], axis=1\n                    )\n                    X_val = df_train.loc[mask_test].drop(\n                        [target_col, \"factorized\"], axis=1\n                    )\n\n                    mlflow.log_param(\"train_rows\", X_train.shape[0])\n                    mlflow.log_param(\"train_cols\", X_train.shape[1])\n\n                    model.fit(\n                        X_train,\n                        y_train,\n                        eval_set=[(X_val, y_val)],\n                        eval_metric=\"mae\",\n                        callbacks=[\n                            lgbm.callback.early_stopping(stopping_rounds=100),\n                            lgbm.callback.log_evaluation(period=100000),\n                        ],\n                    )\n\n                    log_feature_importance(\n                        trial.number,\n                        model,\n                        X_train,\n                        fold_n,\n                        experiment_purpose,\n                        experiment_date_str,\n                    )\n\n                    fold_score = model.best_score_[\"valid_0\"][\"l1\"]\n\n                    score_list.append(fold_score)\n\n          \n                    mlflow.log_metric(\"fold_score\", round(fold_score, 6))\n                    mlflow.log_param(\"fold_number\", fold_n + 1)\n                    mlflow.log_param(\"model_name\", model_name)\n\n\n                    mlflow.log_params(rounded_params)\n\n                    current_time_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n                    model_log_name = f\"{model_name}_{trial.number}_{current_time_str}\"\n\n                  \n                    mlflow.sklearn.log_model(model, model_log_name)\n\n                    mlflow.log_param(\"run_time\", current_time_str)\n\n                    nested_run_id = nested_run.info.run_id\n                    model_path = f\"{path_experiments_storage}/{run.info.experiment_id}/{nested_run_id}/artifacts/{model_log_name}/model.pkl\"\n                    mlflow.log_param(\"model_path\", model_path)\n\n            avg_score = sum(score_list) / len(score_list)\n            median_score = np.median(score_list) \n            mlflow.log_metric(\"avg score\",round(avg_score,6))\n            mlflow.log_metric(\"median score\",round(median_score,6))\n\n        return avg_score\n\n\n\ndef objective(trial, df_train):\n    avg_score = run_mlflow_experiment(df_train, args, trial)\n    return avg_score\n\n\n# Run the Optuna study\nif TRAIN:\n    study = optuna.create_study(\n        direction=\"minimize\",\n        study_name=\"Your Study Name\",\n        load_if_exists=True,\n    )\n    study.optimize(lambda trial: objective(trial, df_train), n_trials=N_TRIALS)","metadata":{"papermill":{"duration":0.03573,"end_time":"2023-11-10T14:44:19.574211","exception":false,"start_time":"2023-11-10T14:44:19.538481","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:17:42.778864Z","iopub.execute_input":"2023-11-11T14:17:42.779296Z","iopub.status.idle":"2023-11-11T14:18:18.938622Z","shell.execute_reply.started":"2023-11-11T14:17:42.779265Z","shell.execute_reply":"2023-11-11T14:18:18.936566Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"[I 2023-11-11 14:17:43,182] A new study created in memory with name: Your Study Name\n","output_type":"stream"},{"name":"stdout","text":"Experiment 'optiver_trading_at_the_close_v1' already exists with ID 462236245386961179.\nOrderedDict([('learning_rate', 0.01395), ('max_depth', 43), ('boosting_type', 'gbdt'), ('colsample_bytree', 1.0), ('importance_type', 'gain'), ('min_child_samples', 18), ('min_child_weight', 0.001), ('min_split_gain', 0.20082), ('n_estimators', 500), ('n_jobs', 4), ('num_leaves', 60), ('objective', 'mae'), ('reg_alpha', 1.78651), ('reg_lambda', 2.54073), ('subsample', 0.93474), ('subsample_for_bin', 200000), ('subsample_freq', 0)])\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[218]\tvalid_0's l1: 6.31829\n","output_type":"stream"},{"name":"stderr","text":"[W 2023-11-11 14:18:18,566] Trial 0 failed with parameters: {} because of the following error: NameError(\"name 'rounded_params' is not defined\").\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n    value_or_values = func(trial)\n  File \"/tmp/ipykernel_1542/1971828427.py\", line 275, in <lambda>\n    study.optimize(lambda trial: objective(trial, df_train), n_trials=N_TRIALS)\n  File \"/tmp/ipykernel_1542/1971828427.py\", line 264, in objective\n    avg_score = run_mlflow_experiment(df_train, args, trial)\n  File \"/tmp/ipykernel_1542/1971828427.py\", line 240, in run_mlflow_experiment\n    mlflow.log_params(rounded_params)\nNameError: name 'rounded_params' is not defined\n[W 2023-11-11 14:18:18,567] Trial 0 failed with value None.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 275\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAIN:\n\u001b[1;32m    270\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m    271\u001b[0m         direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    272\u001b[0m         study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour Study Name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    273\u001b[0m         load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m     )\n\u001b[0;32m--> 275\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[21], line 275\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAIN:\n\u001b[1;32m    270\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m    271\u001b[0m         direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    272\u001b[0m         study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour Study Name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    273\u001b[0m         load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m     )\n\u001b[0;32m--> 275\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39mN_TRIALS)\n","Cell \u001b[0;32mIn[21], line 264\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, df_train)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(trial, df_train):\n\u001b[0;32m--> 264\u001b[0m     avg_score \u001b[38;5;241m=\u001b[39m \u001b[43mrun_mlflow_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_score\n","Cell \u001b[0;32mIn[21], line 240\u001b[0m, in \u001b[0;36mrun_mlflow_experiment\u001b[0;34m(df_train, args, trial)\u001b[0m\n\u001b[1;32m    236\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_number\u001b[39m\u001b[38;5;124m\"\u001b[39m, fold_n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    237\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name)\n\u001b[0;32m--> 240\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_params(\u001b[43mrounded_params\u001b[49m)\n\u001b[1;32m    242\u001b[0m current_time_str \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    243\u001b[0m model_log_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_time_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n","\u001b[0;31mNameError\u001b[0m: name 'rounded_params' is not defined"],"ename":"NameError","evalue":"name 'rounded_params' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.016242,"end_time":"2023-11-10T14:44:19.900436","exception":false,"start_time":"2023-11-10T14:44:19.884194","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"51030a77-aba3-469f-9c08-7963bc8a09d2","_uuid":"6ff7d358-62f0-4ac9-b028-d1c920bb4eaf","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.032999,"end_time":"2023-11-10T14:44:19.949435","exception":false,"start_time":"2023-11-10T14:44:19.916436","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    df_exp = experiments_data(\n        client, list_experiment_id=None, save_df=None, list_columns=None\n    )\n    list_base_cols = [\n        \"run_time\",\n        \"experiment_id\",\n        \"n_trial\",\n        \"run_id\",\n        \"model_name\",\n        \"fold_number\",\n        \"fold_score\",\n    ]\n    list_dynamic_params = list(model_params_dict[\"LGBMR\"][\"dynamic_params\"].keys())\n\n    df_exp[\"run_time\"] = pd.to_datetime(\n        df_exp[\"run_time\"], format=\"%Y%m%d_%H%M%S\", errors=\"coerce\"\n    )\n\n    for col in df_exp.columns:\n        df_exp[col] = pd.to_numeric(df_exp[col], errors=\"ignore\")\n\n    for col in df_exp.select_dtypes(include=[\"float\", \"int\"]):\n        df_exp[col] = df_exp[col].round(5)\n\n    list_cols_exp = [\"run_time\"] + list_base_cols + list_dynamic_params + [\"model_path\"]\n\n    df_exp = df_exp[list_cols_exp]","metadata":{"papermill":{"duration":0.029628,"end_time":"2023-11-10T14:44:19.995532","exception":false,"start_time":"2023-11-10T14:44:19.965904","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:12:32.580396Z","iopub.status.idle":"2023-11-11T14:12:32.581838Z","shell.execute_reply.started":"2023-11-11T14:12:32.581558Z","shell.execute_reply":"2023-11-11T14:12:32.581597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.015652,"end_time":"2023-11-10T14:44:20.027579","exception":false,"start_time":"2023-11-10T14:44:20.011927","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ensemble_predict(model_paths, X_test):\n    models = []\n    predictions = []\n\n    # Load models based on full artifact paths\n    for model_path in model_paths:\n        try:\n            # If using direct path to pkl\n            if model_path.endswith(\".pkl\"):\n                model = joblib.load(model_path)\n            else:\n                print(f\"Unsupported model format for {model_path}. Skipping.\")\n                continue  # Skip this iteration\n\n            models.append(model)\n        except Exception as e:\n            print(f\"Failed to load model at {model_path}. Error: {e}\")\n\n    # Make predictions\n    for model in models:\n        try:\n            pred = model.predict(X_test)\n            predictions.append(pred)\n        except Exception as e:\n            print(f\"Failed to make prediction with model. Error: {e}\")\n\n    # Average predictions\n    if len(predictions) > 0:\n        ensemble_pred = np.mean(predictions, axis=0)\n    else:\n        print(\"No valid models loaded. Cannot make ensemble predictions.\")\n        ensemble_pred = None\n\n    return ensemble_pred","metadata":{"_cell_guid":"95e6c8a8-62ed-4412-944a-5b08508702fc","_uuid":"60c6783c-1e42-43ca-ba32-bda313deb585","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.030622,"end_time":"2023-11-10T14:44:20.074568","exception":false,"start_time":"2023-11-10T14:44:20.043946","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:12:32.583093Z","iopub.status.idle":"2023-11-11T14:12:32.583499Z","shell.execute_reply.started":"2023-11-11T14:12:32.583290Z","shell.execute_reply":"2023-11-11T14:12:32.583308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.01664,"end_time":"2023-11-10T14:44:20.108743","exception":false,"start_time":"2023-11-10T14:44:20.092103","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.017846,"end_time":"2023-11-10T14:44:20.142834","exception":false,"start_time":"2023-11-10T14:44:20.124988","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    model_paths = [\n        path\n        for path in list(\n            df_exp[df_exp[\"experiment_id\"] == 223740748204133848][\"model_path\"]\n        )\n        if path is not np.nan\n    ]\n\n    if not os.path.exists(models_dir):\n        os.makedirs(models_dir)\n\n    for model_path in model_paths:\n        if not os.path.exists(model_path):\n            print(f\"File does not exist: {model_path}\")\n            continue  # Skip to the next iteration\n\n        specific_part = model_path.split(\"/\")[-2]\n        dest_path = os.path.join(models_dir, f\"{specific_part}.pkl\")\n        if not os.path.exists(dest_path):\n            print(f\"Copying model to {dest_path}\")\n            shutil.copy(model_path, dest_path)\n        else:\n            print(f\"File {dest_path} already exists. Skipping copy.\")\n\n    zipf = zipfile.ZipFile(\n        f\"/kaggle/working/{models_dir}.zip\", \"w\", zipfile.ZIP_DEFLATED\n    )\n\n    # Navigate through the folder and add each file to the ZIP\n    for root, dirs, files in os.walk(f\"/kaggle/working/{models_dir}\"):\n        for file in files:\n            zipf.write(\n                os.path.join(root, file),\n                os.path.relpath(\n                    os.path.join(root, file), f\"/kaggle/working/{models_dir}\"\n                ),\n            )\n\n    zipf.close()","metadata":{"papermill":{"duration":0.032021,"end_time":"2023-11-10T14:44:20.190910","exception":false,"start_time":"2023-11-10T14:44:20.158889","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:12:32.586435Z","iopub.status.idle":"2023-11-11T14:12:32.587717Z","shell.execute_reply.started":"2023-11-11T14:12:32.587317Z","shell.execute_reply":"2023-11-11T14:12:32.587352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.01577,"end_time":"2023-11-10T14:44:20.223457","exception":false,"start_time":"2023-11-10T14:44:20.207687","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.016247,"end_time":"2023-11-10T14:44:20.256463","exception":false,"start_time":"2023-11-10T14:44:20.240216","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_paths = []\nmodels_dir_input = models_dir.replace(\"_\", \"-\")\ndirectory = f\"/kaggle/input/{models_dir_input}\"\n\n# Check if the directory exists\nif os.path.exists(directory):\n    # Traverse the directory and collect file paths\n    for filename in os.listdir(directory):\n        full_path = os.path.join(directory, filename)\n\n        # Check if the item is a file (and not a sub-directory)\n        if os.path.isfile(full_path):\n            model_paths.append(full_path)\nelse:\n    print(f\"The directory {directory} does not exist.\")\n\n# Print or return the list of file paths\nprint(\"List of file paths:\", model_paths)","metadata":{"papermill":{"duration":0.035117,"end_time":"2023-11-10T14:44:20.310608","exception":false,"start_time":"2023-11-10T14:44:20.275491","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:12:32.589322Z","iopub.status.idle":"2023-11-11T14:12:32.589974Z","shell.execute_reply.started":"2023-11-11T14:12:32.589653Z","shell.execute_reply":"2023-11-11T14:12:32.589683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.016211,"end_time":"2023-11-10T14:44:20.343671","exception":false,"start_time":"2023-11-10T14:44:20.327460","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming X_test for predict\n# ensemble_predictions = ensemble_predict(model_paths, df_test, mlflow_client)","metadata":{"_cell_guid":"79aa495a-7580-497c-b913-8941cf7d0c61","_uuid":"b3efe16f-ca61-4000-94d7-568364d0e11b","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.025272,"end_time":"2023-11-10T14:44:20.385877","exception":false,"start_time":"2023-11-10T14:44:20.360605","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:12:32.592421Z","iopub.status.idle":"2023-11-11T14:12:32.593091Z","shell.execute_reply.started":"2023-11-11T14:12:32.592767Z","shell.execute_reply":"2023-11-11T14:12:32.592796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optiver2023\n\nenv = optiver2023.make_env()\niter_test = env.iter_test()","metadata":{"_cell_guid":"d4bfb979-2758-4fe9-8947-399b1c3a574c","_uuid":"bef1a199-0988-4743-813e-99d4308fc9bb","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.047897,"end_time":"2023-11-10T14:44:20.450561","exception":false,"start_time":"2023-11-10T14:44:20.402664","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:12:32.595086Z","iopub.status.idle":"2023-11-11T14:12:32.595713Z","shell.execute_reply.started":"2023-11-11T14:12:32.595380Z","shell.execute_reply":"2023-11-11T14:12:32.595407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/optiver-trading-at-the-close/train.csv\")\nglobal_stock_id_feats = {\n    \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median()\n    + df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n    \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std()\n    + df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n    \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max()\n    - df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n    \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median()\n    + df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n    \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std()\n    + df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n    \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max()\n    - df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n}","metadata":{"papermill":{"duration":25.763647,"end_time":"2023-11-10T14:44:46.231581","exception":false,"start_time":"2023-11-10T14:44:20.467934","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:12:32.597770Z","iopub.status.idle":"2023-11-11T14:12:32.598221Z","shell.execute_reply.started":"2023-11-11T14:12:32.598024Z","shell.execute_reply":"2023-11-11T14:12:32.598043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counter = 0\ndf_tot_test = []\nfor test, revealed_targets, sample_prediction in iter_test:\n    test[\"time_id\"] = counter\n    test[\"target\"] = \"none\"\n\n    if counter < 17:\n        df_tot_test.append(test)\n    else:\n        df_tot_test = df_tot_test[1:]\n        df_tot_test.append(test)\n\n    df_test = pd.concat(df_tot_test, axis=0, ignore_index=True)\n\n    feat = feat_engineering(df_test)\n    feat = feat.sort_values([\"date_id\", \"seconds_in_bucket\", \"stock_id\"])[-len(test) :]\n\n    list_cols_drop = [\"date_id\"]\n    feat.drop(list_cols_drop, axis=1, inplace=True)\n\n    model = joblib.load(\"/kaggle/input/models-12/LGBMR_0_20231110_100236.pkl\")\n\n    list_features = model.feature_name_\n    feat = feat[list_features]\n    sample_prediction[\"target\"] = ensemble_predict(model_paths, feat)\n    env.predict(sample_prediction)\n    counter += 1","metadata":{"_cell_guid":"d30f3862-dca2-4242-9db0-ab9750118622","_uuid":"efd9073c-aaef-4135-bf7c-1e892e9aa831","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":164.759051,"end_time":"2023-11-10T14:47:31.007995","exception":false,"start_time":"2023-11-10T14:44:46.248944","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-11T14:12:32.600645Z","iopub.status.idle":"2023-11-11T14:12:32.601711Z","shell.execute_reply.started":"2023-11-11T14:12:32.601314Z","shell.execute_reply":"2023-11-11T14:12:32.601346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"5498ae4b-62e8-4050-91e7-075fc549380f","_uuid":"ce9653b2-7dff-4c5b-af77-5f0ef88b6e86","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.017701,"end_time":"2023-11-10T14:47:31.044079","exception":false,"start_time":"2023-11-10T14:47:31.026378","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"92a8ed18-3a63-464e-9d62-17cea3baed59","_uuid":"0b017968-3b5a-4465-820e-e89659b10afd","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.016233,"end_time":"2023-11-10T14:47:31.077055","exception":false,"start_time":"2023-11-10T14:47:31.060822","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"f9d19e8d-0074-4ae2-adfb-4c039b700215","_uuid":"b6096d27-d452-4593-9832-d15bfbd83e1b","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.016943,"end_time":"2023-11-10T14:47:31.110719","exception":false,"start_time":"2023-11-10T14:47:31.093776","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"855f8db3-e344-4d4d-b577-36499775f352","_uuid":"fde5edb9-d23d-41ac-92c6-593f299230c2","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.016193,"end_time":"2023-11-10T14:47:31.143403","exception":false,"start_time":"2023-11-10T14:47:31.127210","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"82330d89-f35e-4cae-876c-de852438527d","_uuid":"f90f329d-b882-464c-84fc-74a815cfe1cd","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.017088,"end_time":"2023-11-10T14:47:31.177101","exception":false,"start_time":"2023-11-10T14:47:31.160013","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"ed96eca6-9765-4c90-a6bf-3071518ba2f0","_uuid":"ca1d48b9-5537-491b-9de2-57360edd9844","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.016634,"end_time":"2023-11-10T14:47:31.210341","exception":false,"start_time":"2023-11-10T14:47:31.193707","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}