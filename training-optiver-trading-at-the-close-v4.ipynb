{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecfba22b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:33.405102Z",
     "iopub.status.busy": "2023-11-09T21:16:33.404688Z",
     "iopub.status.idle": "2023-11-09T21:16:36.324167Z",
     "shell.execute_reply": "2023-11-09T21:16:36.322765Z"
    },
    "papermill": {
     "duration": 2.943605,
     "end_time": "2023-11-09T21:16:36.327098",
     "exception": false,
     "start_time": "2023-11-09T21:16:33.383493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants\n",
    "TRAIN = False\n",
    "OVERWRITE = False\n",
    "DEBUG = False\n",
    "\n",
    "tuning = False\n",
    "\n",
    "VERSION_NB = 4\n",
    "STATE = 42\n",
    "N_TRIALS = 1\n",
    "download_kaggle_data = False\n",
    "models_dir = \"models_8\"\n",
    "\n",
    "# External general-purpose modules\n",
    "import gc\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import shutil\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import itertools as itt\n",
    "from itertools import combinations, product\n",
    "from warnings import simplefilter\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from dotenv import load_dotenv\n",
    "from joblib import dump\n",
    "from numba import njit, prange\n",
    "\n",
    "# Setting pandas options and warning filters\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232e3207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:36.365515Z",
     "iopub.status.busy": "2023-11-09T21:16:36.364766Z",
     "iopub.status.idle": "2023-11-09T21:16:36.371084Z",
     "shell.execute_reply": "2023-11-09T21:16:36.369603Z"
    },
    "papermill": {
     "duration": 0.028012,
     "end_time": "2023-11-09T21:16:36.373741",
     "exception": false,
     "start_time": "2023-11-09T21:16:36.345729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from utils import aggregate_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73df4ce8",
   "metadata": {
    "_cell_guid": "3bdaa15b-0b9e-4b3b-9c47-58e6b9b18b5e",
    "_uuid": "206043b9-f1d5-4691-b03a-935f2177086d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:36.410455Z",
     "iopub.status.busy": "2023-11-09T21:16:36.409961Z",
     "iopub.status.idle": "2023-11-09T21:16:36.430903Z",
     "shell.execute_reply": "2023-11-09T21:16:36.429831Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.042417,
     "end_time": "2023-11-09T21:16:36.433459",
     "exception": false,
     "start_time": "2023-11-09T21:16:36.391042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_project_dir = os.getcwd()\n",
    "if path_project_dir not in [\"/kaggle/working\", \"/content\"]:\n",
    "    path_project_dir = os.getenv(\"ROOT_PATH\")\n",
    "\n",
    "# Conditional imports and settings based on TRAIN constant\n",
    "if TRAIN:\n",
    "\n",
    "    if path_project_dir == '/kaggle/working':\n",
    "        !pip install loguru mlflow optuna > /dev/null\n",
    "\n",
    "    # External Libraries\n",
    "    import lightgbm as lgbm\n",
    "    import mlflow\n",
    "    import optuna\n",
    "    from loguru import logger\n",
    "    from mlflow.tracking import MlflowClient\n",
    "    from optuna.integration.mlflow import MLflowCallback\n",
    "    from sklearn.model_selection import KFold\n",
    "    from tqdm import tqdm\n",
    "    from xgboost import XGBRegressor as XGBR\n",
    "    from lightgbm import log_evaluation, early_stopping, LGBMRegressor as LGBMR\n",
    "\n",
    "    # Local Modules Imports\n",
    "    from utils import log_feature_importance, create_model, log_training_details, aggregate_feature_importance, get_data, clean_directory_except_one, experiments_data\n",
    "\n",
    "\n",
    "    # Logger setup\n",
    "    logger.add(\"logs.log\", format=\"{time:YYYY-MM-DD HH:mm} | {level} | {message}\")\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning)\n",
    "    \n",
    "    # Auto-reload modules - Specific to Jupyter Notebooks\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "    # Initialize MLflow callback\n",
    "    mlflow_callback = MLflowCallback(\n",
    "        tracking_uri=mlflow.get_tracking_uri(), metric_name=\"mae\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "978e75d6",
   "metadata": {
    "_cell_guid": "9765420b-f8ab-46ba-8b4c-e4487eb04b76",
    "_uuid": "c4174134-1441-41f8-adbf-f03ad3f7d7dc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:36.471421Z",
     "iopub.status.busy": "2023-11-09T21:16:36.470997Z",
     "iopub.status.idle": "2023-11-09T21:16:36.483105Z",
     "shell.execute_reply": "2023-11-09T21:16:36.481773Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034477,
     "end_time": "2023-11-09T21:16:36.485835",
     "exception": false,
     "start_time": "2023-11-09T21:16:36.451358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if path_project_dir == \"/kaggle/working\":\n",
    "    path_data_project_dir = \"/kaggle/input/optiver-trading-at-the-close\"\n",
    "    path_experiments_storage = os.path.join(path_project_dir, \"experiments_storage\")\n",
    "\n",
    "    path_dataset_train_raw = \"/kaggle/input/optiver-trading-at-the-close/train.csv\"\n",
    "    path_dataset_test_raw = (\n",
    "        \"/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv\"\n",
    "    )\n",
    "\n",
    "    path_dataset_processed = \"/kaggle/working/processed_data\"\n",
    "    path_dataset_train = os.path.join(path_dataset_processed, \"train.csv\")\n",
    "    path_dataset_test = os.path.join(path_dataset_processed, \"test.csv\")\n",
    "\n",
    "else:\n",
    "    name_folder_data_project = \"kaggle_optiver_trading_at_the_close\"\n",
    "\n",
    "    path_data_dir = os.path.join(path_project_dir, \"data\")\n",
    "    path_dataset_train_raw = os.path.join(\n",
    "        path_data_dir, \"kaggle_optiver_trading_at_the_close/raw\", \"train.csv\"\n",
    "    )\n",
    "    path_dataset_processed = os.path.join(\n",
    "        path_data_dir, \"kaggle_optiver_trading_at_the_close/processed\"\n",
    "    )\n",
    "\n",
    "    path_data_project_dir = os.path.join(path_data_dir, name_folder_data_project)\n",
    "\n",
    "    path_config_dir = os.path.join(path_project_dir, \"config\")\n",
    "    path_config_train = os.path.join(path_config_dir, \"train_config.yaml\")\n",
    "\n",
    "    path_experiments_storage = os.path.join(\n",
    "        path_data_project_dir, \"experiments_storage\"\n",
    "    )\n",
    "\n",
    "    if download_kaggle_data:\n",
    "        dataset_name = \"ravi20076/optiver-memoryreduceddatasets\"\n",
    "        kaggle_json_path = os.path.join(path_project_dir, \"kaggle.json\")\n",
    "        get_data(\n",
    "            kaggle_json_path,\n",
    "            path_data_project_dir,\n",
    "            dataset_name=dataset_name,\n",
    "            specific_file=None,\n",
    "        )\n",
    "\n",
    "    file_name_df_train = \"train.csv\"\n",
    "    file_name_df_test = \"test.csv\"\n",
    "\n",
    "    path_dataset_train = os.path.join(path_data_project_dir, file_name_df_train)\n",
    "    path_dataset_test = os.path.join(path_data_project_dir, file_name_df_test)\n",
    "\n",
    "if TRAIN:\n",
    "    mlflow.set_tracking_uri(path_experiments_storage)\n",
    "    client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf1f594",
   "metadata": {
    "papermill": {
     "duration": 0.017987,
     "end_time": "2023-11-09T21:16:36.522380",
     "exception": false,
     "start_time": "2023-11-09T21:16:36.504393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711d45da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:36.561927Z",
     "iopub.status.busy": "2023-11-09T21:16:36.561515Z",
     "iopub.status.idle": "2023-11-09T21:16:36.657117Z",
     "shell.execute_reply": "2023-11-09T21:16:36.655970Z"
    },
    "papermill": {
     "duration": 0.118499,
     "end_time": "2023-11-09T21:16:36.660241",
     "exception": false,
     "start_time": "2023-11-09T21:16:36.541742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def compute_triplet_imbalance(df_values, comb_indices):\n",
    "    num_rows = df_values.shape[0]\n",
    "    num_combinations = len(comb_indices)\n",
    "    imbalance_features = np.empty((num_rows, num_combinations))\n",
    "\n",
    "    for i in prange(num_combinations):\n",
    "        a, b, c = comb_indices[i]\n",
    "        for j in range(num_rows):\n",
    "            max_val = max(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            min_val = min(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            mid_val = (\n",
    "                df_values[j, a] + df_values[j, b] + df_values[j, c] - min_val - max_val\n",
    "            )\n",
    "            if mid_val == min_val:  # Prevent division by zero\n",
    "                imbalance_features[j, i] = np.nan\n",
    "            else:\n",
    "                imbalance_features[j, i] = (max_val - mid_val) / (mid_val - min_val)\n",
    "\n",
    "    return imbalance_features\n",
    "\n",
    "\n",
    "def calculate_triplet_imbalance_numba(price, df):\n",
    "    # Convert DataFrame to numpy array for Numba compatibility\n",
    "    df_values = df[price].values\n",
    "    comb_indices = [\n",
    "        (price.index(a), price.index(b), price.index(c))\n",
    "        for a, b, c in combinations(price, 3)\n",
    "    ]\n",
    "\n",
    "    # Calculate the triplet imbalance\n",
    "    features_array = compute_triplet_imbalance(df_values, comb_indices)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    columns = [f\"{a}_{b}_{c}_imb2\" for a, b, c in combinations(price, 3)]\n",
    "    features = pd.DataFrame(features_array, columns=columns)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9150ff83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:36.699303Z",
     "iopub.status.busy": "2023-11-09T21:16:36.698777Z",
     "iopub.status.idle": "2023-11-09T21:16:36.716303Z",
     "shell.execute_reply": "2023-11-09T21:16:36.714760Z"
    },
    "papermill": {
     "duration": 0.040307,
     "end_time": "2023-11-09T21:16:36.719464",
     "exception": false,
     "start_time": "2023-11-09T21:16:36.679157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=0):\n",
    "    \"\"\"\n",
    "    Iterate through all numeric columns of a dataframe and modify the data type\n",
    "    to reduce memory usage.\n",
    "    \"\"\"\n",
    "\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if (col_type != object) and (col != \"target\"):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    if verbose:\n",
    "        logger.info(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n",
    "        end_mem = df.memory_usage().sum() / 1024**2\n",
    "        logger.info(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n",
    "        decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "        logger.info(f\"Decreased by {decrease:.2f}%\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f91a412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:36.758268Z",
     "iopub.status.busy": "2023-11-09T21:16:36.757587Z",
     "iopub.status.idle": "2023-11-09T21:16:36.884305Z",
     "shell.execute_reply": "2023-11-09T21:16:36.883074Z"
    },
    "papermill": {
     "duration": 0.149299,
     "end_time": "2023-11-09T21:16:36.887226",
     "exception": false,
     "start_time": "2023-11-09T21:16:36.737927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate imbalance features\n",
    "def imbalance_features(df):\n",
    "    prices = [\n",
    "        \"reference_price\",\n",
    "        \"far_price\",\n",
    "        \"near_price\",\n",
    "        \"ask_price\",\n",
    "        \"bid_price\",\n",
    "        \"wap\",\n",
    "    ]\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "\n",
    "    # V1\n",
    "    df[\"volume\"] = df.eval(\"ask_size + bid_size\")\n",
    "    df[\"mid_price\"] = df.eval(\"(ask_price + bid_price) / 2\")\n",
    "    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
    "    df[\"matched_imbalance\"] = df.eval(\n",
    "        \"(imbalance_size-matched_size)/(matched_size+imbalance_size)\"\n",
    "    )\n",
    "    df[\"size_imbalance\"] = df.eval(\"bid_size / ask_size\")\n",
    "\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\")\n",
    "\n",
    "    for c in [[\"ask_price\", \"bid_price\", \"wap\", \"reference_price\"], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n",
    "        df[triplet_feature.columns] = triplet_feature.values\n",
    "\n",
    "    # V2\n",
    "    df[\"stock_weights\"] = df[\"stock_id\"].map(weights)\n",
    "    df[\"weighted_wap\"] = df[\"stock_weights\"] * df[\"wap\"]\n",
    "    df[\"wap_momentum\"] = df.groupby(\"stock_id\")[\"weighted_wap\"].pct_change(periods=6)\n",
    "    df[\"imbalance_momentum\"] = (\n",
    "        df.groupby([\"stock_id\"])[\"imbalance_size\"].diff(periods=1) / df[\"matched_size\"]\n",
    "    )\n",
    "    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df[\"spread_intensity\"] = df.groupby([\"stock_id\"])[\"price_spread\"].diff()\n",
    "    df[\"price_pressure\"] = df[\"imbalance_size\"] * (df[\"ask_price\"] - df[\"bid_price\"])\n",
    "    df[\"market_urgency\"] = df[\"price_spread\"] * df[\"liquidity_imbalance\"]\n",
    "    df[\"depth_pressure\"] = (df[\"ask_size\"] - df[\"bid_size\"]) * (\n",
    "        df[\"far_price\"] - df[\"near_price\"]\n",
    "    )\n",
    "    df[\"spread_depth_ratio\"] = (df[\"ask_price\"] - df[\"bid_price\"]) / (\n",
    "        df[\"bid_size\"] + df[\"ask_size\"]\n",
    "    )\n",
    "    df[\"mid_price_movement\"] = (\n",
    "        df[\"mid_price\"]\n",
    "        .diff(periods=5)\n",
    "        .apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "    )\n",
    "    df[\"micro_price\"] = (\n",
    "        (df[\"bid_price\"] * df[\"ask_size\"]) + (df[\"ask_price\"] * df[\"bid_size\"])\n",
    "    ) / (df[\"bid_size\"] + df[\"ask_size\"])\n",
    "    df[\"relative_spread\"] = (df[\"ask_price\"] - df[\"bid_price\"]) / df[\"wap\"]\n",
    "\n",
    "    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n",
    "        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n",
    "        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n",
    "\n",
    "    # V3\n",
    "    for col in [\n",
    "        \"matched_size\",\n",
    "        \"imbalance_size\",\n",
    "        \"reference_price\",\n",
    "        \"imbalance_buy_sell_flag\",\n",
    "    ]:\n",
    "        for window in [1, 2, 3, 5, 10]:\n",
    "            df[f\"{col}_shift_{window}\"] = df.groupby([\"stock_id\",\"date_id\"])[col].shift(window)\n",
    "            df[f\"{col}_ret_{window}\"] = df.groupby([\"stock_id\",\"date_id\"])[col].pct_change(window)\n",
    "\n",
    "    for col in [\n",
    "        \"ask_price\",\n",
    "        \"bid_price\",\n",
    "        \"ask_size\",\n",
    "        \"bid_size\",\n",
    "        \"wap\",\n",
    "        \"near_price\",\n",
    "        \"far_price\",\n",
    "    ]:\n",
    "        for window in [1, 2, 3, 5, 10]:\n",
    "            df[f\"{col}_diff_{window}\"] = df.groupby([\"stock_id\",\"date_id\"])[col].diff(window)\n",
    "\n",
    "    return df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "\n",
    "# generate time & stock features\n",
    "def other_features(df):\n",
    "    df[\"dow\"] = df[\"date_id\"] % 5\n",
    "    df[\"dom\"] = df[\"date_id\"] % 20\n",
    "    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60\n",
    "    df[\"minute\"] = df[\"seconds_in_bucket\"] // 60\n",
    "\n",
    "    for key, value in global_stock_id_feats.items():\n",
    "        df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# generate all features\n",
    "def feat_engineering(df):\n",
    "    cols = [c for c in df.columns if c not in [\"row_id\", \"time_id\"]]\n",
    "    df = df[cols]\n",
    "    df = imbalance_features(df)\n",
    "    df = other_features(df)\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "    feature_name = [\n",
    "        i for i in df.columns if i not in [\"row_id\", \"time_id\"]\n",
    "    ]\n",
    "\n",
    "    return df[feature_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb9d83",
   "metadata": {
    "papermill": {
     "duration": 0.017022,
     "end_time": "2023-11-09T21:16:36.922588",
     "exception": false,
     "start_time": "2023-11-09T21:16:36.905566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3122a3fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:36.960059Z",
     "iopub.status.busy": "2023-11-09T21:16:36.959416Z",
     "iopub.status.idle": "2023-11-09T21:16:36.967088Z",
     "shell.execute_reply": "2023-11-09T21:16:36.966279Z"
    },
    "papermill": {
     "duration": 0.029592,
     "end_time": "2023-11-09T21:16:36.969417",
     "exception": false,
     "start_time": "2023-11-09T21:16:36.939825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    if not os.path.exists(path_dataset_processed):\n",
    "        os.makedirs(path_dataset_processed)\n",
    "\n",
    "    if not os.path.exists(path_dataset_train) or OVERWRITE:\n",
    "        df_train_raw = pd.read_csv(path_dataset_train_raw)\n",
    "\n",
    "    else:\n",
    "        df_train_raw = pd.read_csv(path_dataset_train)\n",
    "\n",
    "    if DEBUG:\n",
    "        df_train_raw = df_train_raw[df_train_raw[\"stock_id\"].isin([0, 1, 2])]\n",
    "\n",
    "    drop_idx = df_train_raw.loc[df_train_raw[\"target\"].isna(), \"target\"].index.to_list()\n",
    "    df_train = df_train_raw.drop(drop_idx, axis=0)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # df_train_raw = df_train_raw.drop([\"time_id\",\"row_id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bae642ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:37.006072Z",
     "iopub.status.busy": "2023-11-09T21:16:37.005455Z",
     "iopub.status.idle": "2023-11-09T21:16:37.022998Z",
     "shell.execute_reply": "2023-11-09T21:16:37.022008Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.039036,
     "end_time": "2023-11-09T21:16:37.025637",
     "exception": false,
     "start_time": "2023-11-09T21:16:36.986601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = [\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.008,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.008,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.04,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.04,\n",
    "    0.002,\n",
    "    0.001,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.001,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.008,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.008,\n",
    "    0.02,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.02,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.001,\n",
    "    0.02,\n",
    "    0.006,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.006,\n",
    "    0.001,\n",
    "    0.04,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.008,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.008,\n",
    "    0.006,\n",
    "    0.008,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.001,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.008,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.008,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.04,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.02,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.02,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.04,\n",
    "    0.002,\n",
    "    0.008,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.004,\n",
    "]\n",
    "\n",
    "weights = {int(k): v for k, v in enumerate(weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b491b4b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:37.135396Z",
     "iopub.status.busy": "2023-11-09T21:16:37.134948Z",
     "iopub.status.idle": "2023-11-09T21:16:37.143927Z",
     "shell.execute_reply": "2023-11-09T21:16:37.142758Z"
    },
    "papermill": {
     "duration": 0.1031,
     "end_time": "2023-11-09T21:16:37.146193",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.043093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    global_stock_id_feats = {\n",
    "        \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median()\n",
    "        + df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n",
    "        \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std()\n",
    "        + df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n",
    "        \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max()\n",
    "        - df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n",
    "        \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median()\n",
    "        + df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n",
    "        \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std()\n",
    "        + df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n",
    "        \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max()\n",
    "        - df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n",
    "    }\n",
    "\n",
    "    df_train_feats = feat_engineering(df_train)\n",
    "    print(\"Build Online Train Feats Finished.\")\n",
    "\n",
    "    df_train_feats = reduce_mem_usage(df_train_feats)\n",
    "    \n",
    "    df_train = df_train_feats.copy()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2cd46e",
   "metadata": {
    "papermill": {
     "duration": 0.017004,
     "end_time": "2023-11-09T21:16:37.181634",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.164630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa00e3",
   "metadata": {
    "papermill": {
     "duration": 0.017183,
     "end_time": "2023-11-09T21:16:37.216683",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.199500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6128ea98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:37.255529Z",
     "iopub.status.busy": "2023-11-09T21:16:37.255061Z",
     "iopub.status.idle": "2023-11-09T21:16:37.266845Z",
     "shell.execute_reply": "2023-11-09T21:16:37.265415Z"
    },
    "papermill": {
     "duration": 0.034577,
     "end_time": "2023-11-09T21:16:37.269686",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.235109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time_series_split(X, n_splits, n_test_splits, embargo_td=2):\n",
    "    factorized_indices = np.unique(X[\"factorized\"])\n",
    "\n",
    "    # Compute the fold boundaries\n",
    "    fold_bounds = [\n",
    "        (fold[0], fold[-1] + 1) for fold in np.array_split(factorized_indices, n_splits)\n",
    "    ]\n",
    "\n",
    "    # Create the list of all tests test_fold_bounds that will become the test sets\n",
    "    selected_fold_bounds = list(itt.combinations(fold_bounds, n_test_splits))\n",
    "\n",
    "    # Reverse to start the testing from the most recent part of the dataset\n",
    "    selected_fold_bounds.reverse()\n",
    "\n",
    "    for fold_bound_list in selected_fold_bounds:\n",
    "        test_factorized_indices = np.empty(0)\n",
    "        test_fold_bounds = []\n",
    "\n",
    "        for fold_start, fold_end in fold_bound_list:\n",
    "            # Records the boundaries of the current test split\n",
    "            if not test_fold_bounds or fold_start != test_fold_bounds[-1][-1]:\n",
    "                test_fold_bounds.append((fold_start, fold_end))\n",
    "            elif fold_start == test_fold_bounds[-1][-1]:\n",
    "                test_fold_bounds[-1] = (test_fold_bounds[-1][0], fold_end)\n",
    "\n",
    "            test_factorized_indices = np.union1d(\n",
    "                test_factorized_indices, factorized_indices[fold_start:fold_end]\n",
    "            ).astype(int)\n",
    "\n",
    "        # Compute the train set indices\n",
    "        train_indices = np.setdiff1d(factorized_indices, test_factorized_indices)\n",
    "\n",
    "        # Purge and embargo can be added here if needed\n",
    "        # ...\n",
    "\n",
    "        yield train_indices, test_factorized_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "187660ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:37.308493Z",
     "iopub.status.busy": "2023-11-09T21:16:37.308009Z",
     "iopub.status.idle": "2023-11-09T21:16:37.315032Z",
     "shell.execute_reply": "2023-11-09T21:16:37.313516Z"
    },
    "papermill": {
     "duration": 0.029525,
     "end_time": "2023-11-09T21:16:37.317425",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.287900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    col_split = \"date_id\"\n",
    "    df_train.sort_values([col_split], inplace=True)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_train[\"factorized\"] = pd.factorize(df_train[col_split])[0]\n",
    "\n",
    "    list_cols_drop = [\"date_id\"]\n",
    "    df_train.drop(list_cols_drop, axis=1, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7e3e1",
   "metadata": {
    "papermill": {
     "duration": 0.018799,
     "end_time": "2023-11-09T21:16:37.354756",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.335957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df5885ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:37.393738Z",
     "iopub.status.busy": "2023-11-09T21:16:37.392951Z",
     "iopub.status.idle": "2023-11-09T21:16:37.400649Z",
     "shell.execute_reply": "2023-11-09T21:16:37.399244Z"
    },
    "papermill": {
     "duration": 0.030694,
     "end_time": "2023-11-09T21:16:37.403610",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.372916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    n_estimators_min = n_estimators_max = 50\n",
    "else:\n",
    "    n_estimators_min = 500\n",
    "    n_estimators_max = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b668dc",
   "metadata": {
    "papermill": {
     "duration": 0.018438,
     "end_time": "2023-11-09T21:16:37.440627",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.422189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c05594d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:37.479453Z",
     "iopub.status.busy": "2023-11-09T21:16:37.478928Z",
     "iopub.status.idle": "2023-11-09T21:16:37.494175Z",
     "shell.execute_reply": "2023-11-09T21:16:37.492688Z"
    },
    "papermill": {
     "duration": 0.038393,
     "end_time": "2023-11-09T21:16:37.497287",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.458894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpu_switch = \"OFF\"\n",
    "n_splits = 6\n",
    "n_test_split = 1\n",
    "embargo_td = 100\n",
    "\n",
    "n_repeats = 1\n",
    "nbrnd_erly_stp = 130\n",
    "\n",
    "cv_mthd = \"KF\"\n",
    "\n",
    "# Cross-Validation Setup\n",
    "if TRAIN:\n",
    "    all_cv = {\"KF\": KFold(n_splits=n_splits, shuffle=True, random_state=STATE)}\n",
    "    cv = all_cv[cv_mthd]\n",
    "\n",
    "    model_params_dict = {\n",
    "        \"LGBMR\": {\n",
    "            \"static_params\": {\n",
    "                \"device\": \"gpu\" if gpu_switch == \"ON\" else \"cpu\",\n",
    "                \"objective\": \"mae\",\n",
    "                \"boosting_type\": \"gbdt\",\n",
    "                \"random_state\": STATE,\n",
    "                \"n_jobs\": 4,\n",
    "                \"verbose\": -1,\n",
    "                \"importance_type\": \"gain\",\n",
    "            },\n",
    "            \"dynamic_params\": {\n",
    "                \"n_estimators\": {\n",
    "                    \"type\": \"int\",\n",
    "                    \"low\": n_estimators_min,\n",
    "                    \"high\": n_estimators_max,\n",
    "                },\n",
    "                \"learning_rate\": {\n",
    "                    \"type\": \"float\",\n",
    "                    \"low\": 0.005,\n",
    "                    \"high\": 0.06,\n",
    "                },\n",
    "                \"max_depth\": {\"type\": \"int\", \"low\": 10, \"high\": 90},\n",
    "                \"num_leaves\": {\n",
    "                    \"type\": \"int\",\n",
    "                    \"low\": 20,\n",
    "                    \"high\": 90,\n",
    "                },\n",
    "                \"min_child_samples\": {\n",
    "                    \"type\": \"int\",\n",
    "                    \"low\": 10,\n",
    "                    \"high\": 70,\n",
    "                },\n",
    "                \"subsample\": {\n",
    "                    \"type\": \"float\",\n",
    "                    \"low\": 0.7,\n",
    "                    \"high\": 1,\n",
    "                },\n",
    "                \"colsample_bytree\": {\n",
    "                    \"type\": \"float\",\n",
    "                    \"low\": 1,\n",
    "                    \"high\": 1,\n",
    "                },\n",
    "                \"min_split_gain\": {\n",
    "                    \"type\": \"float\",\n",
    "                    \"low\": 0,\n",
    "                    \"high\": 2,\n",
    "                },\n",
    "                \"reg_alpha\": {\n",
    "                    \"type\": \"float\",\n",
    "                    \"low\": 0,\n",
    "                    \"high\": 3,\n",
    "                },\n",
    "                \"reg_lambda\": {\n",
    "                    \"type\": \"float\",\n",
    "                    \"low\": 0,\n",
    "                    \"high\": 3,\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    dict_models = {\"LGBMR\": LGBMR}\n",
    "\n",
    "    log_model = True\n",
    "\n",
    "    experiment_date_str = datetime.now().strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "    experiment_purpose = \"optiver_trading_at_the_close\"\n",
    "    experiment_name = f\"{experiment_purpose}_{experiment_date_str}\"\n",
    "\n",
    "    mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6714114c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:37.537974Z",
     "iopub.status.busy": "2023-11-09T21:16:37.537543Z",
     "iopub.status.idle": "2023-11-09T21:16:37.543312Z",
     "shell.execute_reply": "2023-11-09T21:16:37.542147Z"
    },
    "papermill": {
     "duration": 0.029476,
     "end_time": "2023-11-09T21:16:37.546034",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.516558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_params_trained_models(model_path):\n",
    "    model = joblib.load(model_path)\n",
    "    return model.get_params()\n",
    "\n",
    "if TRAIN:\n",
    "    dict_fixed_model_params = get_params_trained_models('/kaggle/input/models-6/LGBMR_0_20231108_235435.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb388ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:15:28.093694Z",
     "iopub.status.busy": "2023-11-09T21:15:28.093171Z",
     "iopub.status.idle": "2023-11-09T21:15:28.175394Z",
     "shell.execute_reply": "2023-11-09T21:15:28.171821Z",
     "shell.execute_reply.started": "2023-11-09T21:15:28.093655Z"
    },
    "papermill": {
     "duration": 0.018683,
     "end_time": "2023-11-09T21:16:37.583961",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.565278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10bb2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:15:38.135678Z",
     "iopub.status.busy": "2023-11-09T21:15:38.135189Z",
     "iopub.status.idle": "2023-11-09T21:15:38.186754Z",
     "shell.execute_reply": "2023-11-09T21:15:38.186007Z",
     "shell.execute_reply.started": "2023-11-09T21:15:38.135643Z"
    },
    "papermill": {
     "duration": 0.018373,
     "end_time": "2023-11-09T21:16:37.620655",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.602282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "514110fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:37.660432Z",
     "iopub.status.busy": "2023-11-09T21:16:37.660012Z",
     "iopub.status.idle": "2023-11-09T21:16:37.667281Z",
     "shell.execute_reply": "2023-11-09T21:16:37.665791Z"
    },
    "papermill": {
     "duration": 0.030636,
     "end_time": "2023-11-09T21:16:37.670612",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.639976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    args = {\n",
    "        \"cv_mthd\": cv_mthd,\n",
    "        \"experiment_purpose\": experiment_purpose,\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"VERSION_NB\": VERSION_NB,\n",
    "        \"dict_models\": dict_models,\n",
    "        \"model_params_dict\": model_params_dict,\n",
    "        \"logger\": logger,\n",
    "        \"n_splits\": n_splits,\n",
    "        \"n_test_split\": n_test_split,\n",
    "        \"experiment_date_str\": experiment_date_str,\n",
    "        \"path_experiments_storage\": path_experiments_storage,\n",
    "        \"target_col\": \"target\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e571617",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:37.713227Z",
     "iopub.status.busy": "2023-11-09T21:16:37.712795Z",
     "iopub.status.idle": "2023-11-09T21:16:37.739726Z",
     "shell.execute_reply": "2023-11-09T21:16:37.738411Z"
    },
    "papermill": {
     "duration": 0.052966,
     "end_time": "2023-11-09T21:16:37.743414",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.690448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_mlflow_experiment(df_train, args, trial=None):\n",
    "    cv_mthd = args[\"cv_mthd\"]\n",
    "    experiment_purpose = args[\"experiment_purpose\"]\n",
    "    experiment_name = args[\"experiment_name\"]\n",
    "    VERSION_NB = args[\"VERSION_NB\"]\n",
    "    dict_models = args[\"dict_models\"]\n",
    "    model_params_dict = args[\"model_params_dict\"]\n",
    "    logger = args[\"logger\"]\n",
    "    n_splits = args[\"n_splits\"]\n",
    "    n_test_split = args[\"n_test_split\"]\n",
    "    experiment_date_str = args[\"experiment_date_str\"]\n",
    "    path_experiments_storage = args[\"path_experiments_storage\"]\n",
    "    target_col = args[\"target_col\"]\n",
    "\n",
    "    if trial == None:\n",
    "        trial = optuna.trial.FixedTrial(\n",
    "            {\n",
    "                \"n_estimators\": 500,\n",
    "                \"learning_rate\": 0.005,\n",
    "                \"max_depth\": 10,\n",
    "                \"num_leaves\": 20,\n",
    "                \"min_child_samples\": 10,\n",
    "                \"subsample\": 0.7,\n",
    "                \"colsample_bytree\": 1.0,\n",
    "                \"min_split_gain\": 0.0,\n",
    "                \"reg_alpha\": 0.0,\n",
    "                \"reg_lambda\": 0.0,\n",
    "                \"device\": \"gpu\" if gpu_switch == \"ON\" else \"cpu\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        mlflow.log_param(\"cv_mthd\", cv_mthd)\n",
    "        mlflow.set_tag(\"experiment_purpose\", experiment_purpose)\n",
    "        mlflow.set_tag(\"experiment_name\", experiment_name)\n",
    "        mlflow.set_tag(\"version_nb\", VERSION_NB)\n",
    "        mlflow.set_tag(\"n_trial\", trial.number)\n",
    "\n",
    "        score_list = []\n",
    "        for model_name, model_class in dict_models.items():\n",
    "            \n",
    "            \n",
    "            \n",
    "            if tuning:\n",
    "                model = create_model(\n",
    "                    trial,\n",
    "                    model_class,\n",
    "                    model_params_dict[model_name][\"static_params\"],\n",
    "                    model_params_dict[model_name][\"dynamic_params\"],\n",
    "                )\n",
    "            else:\n",
    "                print(dict_fixed_model_params)\n",
    "                model = model_class(**dict_fixed_model_params)\n",
    "\n",
    "            log_training_details(logger, model, trial, model_name)\n",
    "\n",
    "            for fold_n, (train_indices, test_indices) in enumerate(\n",
    "                time_series_split(\n",
    "                    df_train, n_splits=n_splits, n_test_splits=n_test_split\n",
    "                )\n",
    "            ):\n",
    "                with mlflow.start_run(\n",
    "                    run_name=f\"fold_{fold_n+1}\", nested=True\n",
    "                ) as nested_run:\n",
    "                    mask_train = df_train[\"factorized\"].isin(train_indices)\n",
    "                    mask_test = df_train[\"factorized\"].isin(test_indices)\n",
    "\n",
    "                    \n",
    "                    y_train = df_train.loc[mask_train, target_col]\n",
    "                    y_val = df_train.loc[mask_test, target_col]\n",
    "                    X_train = df_train.loc[mask_train].drop(\n",
    "                        [target_col, \"factorized\"], axis=1\n",
    "                    )\n",
    "                    X_val = df_train.loc[mask_test].drop(\n",
    "                        [target_col, \"factorized\"], axis=1\n",
    "                    )\n",
    "\n",
    "                    mlflow.log_param(\"train_rows\", X_train.shape[0])\n",
    "                    mlflow.log_param(\"train_cols\", X_train.shape[1])\n",
    "                    \n",
    "                    list_features = list(aggregate_feature_importance(['/kaggle/working/feat_impor_optiver_trading_at_the_close_20231109_11_14_13.csv'])['feat'][:80])\n",
    "                    X_train = X_train[list_features]\n",
    "                    X_val = X_val[list_features]\n",
    "\n",
    "                    model.fit(\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        eval_set=[(X_val, y_val)],\n",
    "                        eval_metric=\"mae\",\n",
    "                        callbacks=[\n",
    "                            lgbm.callback.early_stopping(stopping_rounds=100),\n",
    "                            lgbm.callback.log_evaluation(period=100),\n",
    "                        ],\n",
    "                    )\n",
    "\n",
    "                    log_feature_importance(\n",
    "                        trial.number,\n",
    "                        model,\n",
    "                        X_train,\n",
    "                        fold_n,\n",
    "                        experiment_purpose,\n",
    "                        experiment_date_str,\n",
    "                    )\n",
    "\n",
    "                    fold_score = model.best_score_[\"valid_0\"][\"l1\"]\n",
    "\n",
    "                    score_list.append(fold_score)\n",
    "\n",
    "                    mlflow.log_param(\"fold_score\", fold_score)\n",
    "                    mlflow.log_param(\"fold_number\", fold_n + 1)\n",
    "                    mlflow.log_param(\"model_name\", model_name)\n",
    "\n",
    "                    params_to_log = model.get_params()\n",
    "                    mlflow.log_params(params_to_log)\n",
    "\n",
    "                    current_time_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    model_log_name = f\"{model_name}_{trial.number}_{current_time_str}\"\n",
    "\n",
    "                    mlflow.log_param(\"model_log_name\", model_log_name)\n",
    "                    mlflow.sklearn.log_model(model, model_log_name)\n",
    "\n",
    "                    mlflow.log_param(\"run_time\", current_time_str)\n",
    "\n",
    "                    nested_run_id = nested_run.info.run_id\n",
    "                    model_path = f\"{path_experiments_storage}/{run.info.experiment_id}/{nested_run_id}/artifacts/{model_log_name}/model.pkl\"\n",
    "                    mlflow.log_param(\"model_path\", model_path)\n",
    "\n",
    "        avg_score = sum(score_list) / len(score_list)\n",
    "\n",
    "        return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "354005d3",
   "metadata": {
    "_cell_guid": "334e81a6-b09b-4a3d-96a1-fe0278deff13",
    "_uuid": "4288a49c-b472-4af2-b2bb-95cf0cd2bd6d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:37.783984Z",
     "iopub.status.busy": "2023-11-09T21:16:37.783235Z",
     "iopub.status.idle": "2023-11-09T21:16:37.788168Z",
     "shell.execute_reply": "2023-11-09T21:16:37.787342Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.027568,
     "end_time": "2023-11-09T21:16:37.790585",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.763017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial, df_train):\n",
    "    avg_score = run_mlflow_experiment(df_train, args, trial)\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e4b1599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:37.830517Z",
     "iopub.status.busy": "2023-11-09T21:16:37.829751Z",
     "iopub.status.idle": "2023-11-09T21:16:37.837278Z",
     "shell.execute_reply": "2023-11-09T21:16:37.835869Z"
    },
    "papermill": {
     "duration": 0.031252,
     "end_time": "2023-11-09T21:16:37.840677",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.809425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the Optuna study\n",
    "if TRAIN:\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        study_name=\"Your Study Name\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    study.optimize(lambda trial: objective(trial, df_train), n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f971f",
   "metadata": {
    "papermill": {
     "duration": 0.017879,
     "end_time": "2023-11-09T21:16:37.878167",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.860288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d2b72c",
   "metadata": {
    "_cell_guid": "51030a77-aba3-469f-9c08-7963bc8a09d2",
    "_uuid": "6ff7d358-62f0-4ac9-b028-d1c920bb4eaf",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017732,
     "end_time": "2023-11-09T21:16:37.914137",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.896405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28b73c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:37.953703Z",
     "iopub.status.busy": "2023-11-09T21:16:37.953282Z",
     "iopub.status.idle": "2023-11-09T21:16:37.960730Z",
     "shell.execute_reply": "2023-11-09T21:16:37.959296Z"
    },
    "papermill": {
     "duration": 0.030145,
     "end_time": "2023-11-09T21:16:37.963224",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.933079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    df_exp = experiments_data(client, list_experiment_id=None, save_df=None, list_columns=None)\n",
    "    list_base_cols = [\n",
    "        \"run_time\",\n",
    "        \"experiment_id\",\n",
    "        \"run_id\",\n",
    "        \"model_name\",\n",
    "        \"fold_number\"\n",
    "    ]\n",
    "    list_dynamic_params = list(model_params_dict[\"LGBMR\"][\"dynamic_params\"].keys())\n",
    "\n",
    "    list_cols_exp = list_base_cols + list_dynamic_params + [\"model_path\"]\n",
    "\n",
    "    df_exp = df_exp[list_cols_exp]\n",
    "\n",
    "    df_exp[\"run_time\"] = pd.to_datetime(\n",
    "        df_exp[\"run_time\"], format=\"%Y%m%d_%H%M%S\", errors=\"coerce\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669f9d7",
   "metadata": {
    "papermill": {
     "duration": 0.019013,
     "end_time": "2023-11-09T21:16:38.000650",
     "exception": false,
     "start_time": "2023-11-09T21:16:37.981637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4002ee67",
   "metadata": {
    "_cell_guid": "95e6c8a8-62ed-4412-944a-5b08508702fc",
    "_uuid": "60c6783c-1e42-43ca-ba32-bda313deb585",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:38.039972Z",
     "iopub.status.busy": "2023-11-09T21:16:38.039574Z",
     "iopub.status.idle": "2023-11-09T21:16:38.048514Z",
     "shell.execute_reply": "2023-11-09T21:16:38.047455Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.03127,
     "end_time": "2023-11-09T21:16:38.050859",
     "exception": false,
     "start_time": "2023-11-09T21:16:38.019589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensemble_predict(model_paths, X_test):\n",
    "    models = []\n",
    "    predictions = []\n",
    "\n",
    "    # Load models based on full artifact paths\n",
    "    for model_path in model_paths:\n",
    "        try:\n",
    "            # If using direct path to pkl\n",
    "            if model_path.endswith(\".pkl\"):\n",
    "                model = joblib.load(model_path)\n",
    "            else:\n",
    "                print(f\"Unsupported model format for {model_path}. Skipping.\")\n",
    "                continue  # Skip this iteration\n",
    "\n",
    "            models.append(model)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load model at {model_path}. Error: {e}\")\n",
    "\n",
    "    # Make predictions\n",
    "    for model in models:\n",
    "        try:\n",
    "            pred = model.predict(X_test)\n",
    "            predictions.append(pred)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to make prediction with model. Error: {e}\")\n",
    "\n",
    "    # Average predictions\n",
    "    if len(predictions) > 0:\n",
    "        ensemble_pred = np.median(predictions, axis=0)\n",
    "    else:\n",
    "        print(\"No valid models loaded. Cannot make ensemble predictions.\")\n",
    "        ensemble_pred = None\n",
    "\n",
    "    return ensemble_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e6aa9",
   "metadata": {
    "papermill": {
     "duration": 0.017519,
     "end_time": "2023-11-09T21:16:38.086519",
     "exception": false,
     "start_time": "2023-11-09T21:16:38.069000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77bef58",
   "metadata": {
    "papermill": {
     "duration": 0.018044,
     "end_time": "2023-11-09T21:16:38.123211",
     "exception": false,
     "start_time": "2023-11-09T21:16:38.105167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d91c63",
   "metadata": {
    "papermill": {
     "duration": 0.018327,
     "end_time": "2023-11-09T21:16:38.159559",
     "exception": false,
     "start_time": "2023-11-09T21:16:38.141232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6d57586",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:38.199693Z",
     "iopub.status.busy": "2023-11-09T21:16:38.198810Z",
     "iopub.status.idle": "2023-11-09T21:16:38.208817Z",
     "shell.execute_reply": "2023-11-09T21:16:38.207900Z"
    },
    "papermill": {
     "duration": 0.032563,
     "end_time": "2023-11-09T21:16:38.211409",
     "exception": false,
     "start_time": "2023-11-09T21:16:38.178846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    model_paths = list(\n",
    "        df_exp[df_exp['experiment_id'] == '220790691490267461'\n",
    "        ][\"model_path\"]\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(models_dir):\n",
    "        os.makedirs(models_dir)\n",
    "\n",
    "    for model_path in model_paths:\n",
    "        \n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"File does not exist: {model_path}\")\n",
    "            continue  # Skip to the next iteration\n",
    "\n",
    "        specific_part = model_path.split(\"/\")[-2]\n",
    "        dest_path = os.path.join(models_dir, f\"{specific_part}.pkl\")\n",
    "        if not os.path.exists(dest_path):\n",
    "            print(f\"Copying from {model_path} to {dest_path}\")\n",
    "            shutil.copy(model_path, dest_path)\n",
    "        else:\n",
    "            print(f\"File {dest_path} already exists. Skipping copy.\")\n",
    "\n",
    "    zipf = zipfile.ZipFile(\n",
    "        f\"/kaggle/working/{models_dir}.zip\", \"w\", zipfile.ZIP_DEFLATED\n",
    "    )\n",
    "\n",
    "    # Navigate through the folder and add each file to the ZIP\n",
    "    for root, dirs, files in os.walk(f\"/kaggle/working/{models_dir}\"):\n",
    "        for file in files:\n",
    "            zipf.write(\n",
    "                os.path.join(root, file),\n",
    "                os.path.relpath(\n",
    "                    os.path.join(root, file), f\"/kaggle/working/{models_dir}\"\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    zipf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9cd255",
   "metadata": {
    "papermill": {
     "duration": 0.017235,
     "end_time": "2023-11-09T21:16:38.246550",
     "exception": false,
     "start_time": "2023-11-09T21:16:38.229315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd4fd2",
   "metadata": {
    "papermill": {
     "duration": 0.019197,
     "end_time": "2023-11-09T21:16:38.283957",
     "exception": false,
     "start_time": "2023-11-09T21:16:38.264760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "524b3630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:38.321838Z",
     "iopub.status.busy": "2023-11-09T21:16:38.320913Z",
     "iopub.status.idle": "2023-11-09T21:16:38.336116Z",
     "shell.execute_reply": "2023-11-09T21:16:38.335053Z"
    },
    "papermill": {
     "duration": 0.037492,
     "end_time": "2023-11-09T21:16:38.339036",
     "exception": false,
     "start_time": "2023-11-09T21:16:38.301544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of file paths: ['/kaggle/input/models-8/LGBMR_0_20231109_173044.pkl', '/kaggle/input/models-8/LGBMR_0_20231109_171503.pkl', '/kaggle/input/models-8/LGBMR_0_20231109_174647.pkl', '/kaggle/input/models-8/LGBMR_0_20231109_180232.pkl', '/kaggle/input/models-8/LGBMR_0_20231109_181820.pkl', '/kaggle/input/models-8/LGBMR_0_20231109_183341.pkl']\n"
     ]
    }
   ],
   "source": [
    "model_paths = []\n",
    "models_dir_input = models_dir.replace(\"_\", \"-\")\n",
    "directory = f\"/kaggle/input/{models_dir_input}\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(directory):\n",
    "    # Traverse the directory and collect file paths\n",
    "    for filename in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Check if the item is a file (and not a sub-directory)\n",
    "        if os.path.isfile(full_path):\n",
    "            model_paths.append(full_path)\n",
    "else:\n",
    "    print(f\"The directory {directory} does not exist.\")\n",
    "\n",
    "# Print or return the list of file paths\n",
    "print(\"List of file paths:\", model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540e220",
   "metadata": {
    "papermill": {
     "duration": 0.018675,
     "end_time": "2023-11-09T21:16:38.377726",
     "exception": false,
     "start_time": "2023-11-09T21:16:38.359051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f82dbd3",
   "metadata": {
    "_cell_guid": "79aa495a-7580-497c-b913-8941cf7d0c61",
    "_uuid": "b3efe16f-ca61-4000-94d7-568364d0e11b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:38.417538Z",
     "iopub.status.busy": "2023-11-09T21:16:38.416266Z",
     "iopub.status.idle": "2023-11-09T21:16:38.421899Z",
     "shell.execute_reply": "2023-11-09T21:16:38.420590Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.028943,
     "end_time": "2023-11-09T21:16:38.424606",
     "exception": false,
     "start_time": "2023-11-09T21:16:38.395663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming X_test for predict\n",
    "# ensemble_predictions = ensemble_predict(model_paths, df_test, mlflow_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f90ba795",
   "metadata": {
    "_cell_guid": "d4bfb979-2758-4fe9-8947-399b1c3a574c",
    "_uuid": "bef1a199-0988-4743-813e-99d4308fc9bb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:38.463800Z",
     "iopub.status.busy": "2023-11-09T21:16:38.463292Z",
     "iopub.status.idle": "2023-11-09T21:16:38.491159Z",
     "shell.execute_reply": "2023-11-09T21:16:38.490028Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.050899,
     "end_time": "2023-11-09T21:16:38.493994",
     "exception": false,
     "start_time": "2023-11-09T21:16:38.443095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45b6b458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:16:38.534114Z",
     "iopub.status.busy": "2023-11-09T21:16:38.533165Z",
     "iopub.status.idle": "2023-11-09T21:17:04.111441Z",
     "shell.execute_reply": "2023-11-09T21:17:04.109723Z"
    },
    "papermill": {
     "duration": 25.601435,
     "end_time": "2023-11-09T21:17:04.114696",
     "exception": false,
     "start_time": "2023-11-09T21:16:38.513261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')\n",
    "global_stock_id_feats = {\n",
    "    \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median()\n",
    "    + df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n",
    "    \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std()\n",
    "    + df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n",
    "    \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max()\n",
    "    - df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n",
    "    \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median()\n",
    "    + df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n",
    "    \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std()\n",
    "    + df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n",
    "    \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max()\n",
    "    - df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51c93075",
   "metadata": {
    "_cell_guid": "d30f3862-dca2-4242-9db0-ab9750118622",
    "_uuid": "efd9073c-aaef-4135-bf7c-1e892e9aa831",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-09T21:17:04.155611Z",
     "iopub.status.busy": "2023-11-09T21:17:04.155051Z",
     "iopub.status.idle": "2023-11-09T21:19:28.530069Z",
     "shell.execute_reply": "2023-11-09T21:19:28.527861Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 144.400851,
     "end_time": "2023-11-09T21:19:28.533982",
     "exception": false,
     "start_time": "2023-11-09T21:17:04.133131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "df_tot_test = []\n",
    "for test, revealed_targets, sample_prediction in iter_test:\n",
    "\n",
    "    if counter < 13:\n",
    "        df_tot_test.append(test)\n",
    "    else:\n",
    "        df_tot_test = df_tot_test[1:]\n",
    "        df_tot_test.append(test)\n",
    "        \n",
    "    df_test = pd.concat(df_tot_test, axis = 0, ignore_index = True)\n",
    "    \n",
    "\n",
    "\n",
    "    feat = feat_engineering(df_test)[-len(test):]\n",
    "    feat = feat.sort_values([\"date_id\",'seconds_in_bucket','stock_id'])[-len(test):]\n",
    "    \n",
    "    list_cols_drop = [\"date_id\"]\n",
    "    feat.drop(list_cols_drop, axis=1, inplace=True)\n",
    "    \n",
    "    model = joblib.load('/kaggle/input/models-8/LGBMR_0_20231109_171503.pkl')\n",
    "    \n",
    "    list_features = model.feature_name_\n",
    "    feat= feat[list_features]\n",
    "    sample_prediction[\"target\"] = ensemble_predict(model_paths, feat)\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f474c76",
   "metadata": {
    "papermill": {
     "duration": 0.020385,
     "end_time": "2023-11-09T21:19:28.575392",
     "exception": false,
     "start_time": "2023-11-09T21:19:28.555007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b8365c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T21:19:28.620077Z",
     "iopub.status.busy": "2023-11-09T21:19:28.618438Z",
     "iopub.status.idle": "2023-11-09T21:19:28.627562Z",
     "shell.execute_reply": "2023-11-09T21:19:28.625905Z"
    },
    "papermill": {
     "duration": 0.034123,
     "end_time": "2023-11-09T21:19:28.630370",
     "exception": false,
     "start_time": "2023-11-09T21:19:28.596247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean_directory_except_one('/kaggle/working/', 'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39ea5845",
   "metadata": {
    "_cell_guid": "3ef4ae54-1bb4-4cc3-a7da-a6691a272d30",
    "_uuid": "495a4e04-554d-4ef1-919d-62bc59f089c4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-09T21:19:28.673035Z",
     "iopub.status.busy": "2023-11-09T21:19:28.672298Z",
     "iopub.status.idle": "2023-11-09T21:19:28.724258Z",
     "shell.execute_reply": "2023-11-09T21:19:28.722432Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.078209,
     "end_time": "2023-11-09T21:19:28.727995",
     "exception": false,
     "start_time": "2023-11-09T21:19:28.649786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feat_engineering(df_train):\n",
    "    weights = [\n",
    "        0.004,\n",
    "        0.001,\n",
    "        0.002,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.006,\n",
    "        0.006,\n",
    "        0.002,\n",
    "        0.002,\n",
    "        0.008,\n",
    "        0.006,\n",
    "        0.002,\n",
    "        0.008,\n",
    "        0.006,\n",
    "        0.002,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.001,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.001,\n",
    "        0.001,\n",
    "        0.002,\n",
    "        0.002,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.006,\n",
    "        0.002,\n",
    "        0.002,\n",
    "        0.04,\n",
    "        0.002,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.04,\n",
    "        0.002,\n",
    "        0.001,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.006,\n",
    "        0.001,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.001,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.008,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.006,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.001,\n",
    "        0.002,\n",
    "        0.002,\n",
    "        0.008,\n",
    "        0.02,\n",
    "        0.004,\n",
    "        0.006,\n",
    "        0.002,\n",
    "        0.02,\n",
    "        0.002,\n",
    "        0.002,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.001,\n",
    "        0.02,\n",
    "        0.006,\n",
    "        0.001,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.001,\n",
    "        0.002,\n",
    "        0.006,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.006,\n",
    "        0.001,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.006,\n",
    "        0.006,\n",
    "        0.001,\n",
    "        0.04,\n",
    "        0.006,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.002,\n",
    "        0.006,\n",
    "        0.002,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.006,\n",
    "        0.006,\n",
    "        0.002,\n",
    "        0.002,\n",
    "        0.008,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.006,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.006,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.001,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.008,\n",
    "        0.006,\n",
    "        0.008,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.001,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.006,\n",
    "        0.008,\n",
    "        0.004,\n",
    "        0.001,\n",
    "        0.001,\n",
    "        0.002,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.001,\n",
    "        0.002,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.006,\n",
    "        0.008,\n",
    "        0.002,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.04,\n",
    "        0.002,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.002,\n",
    "        0.006,\n",
    "        0.02,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.006,\n",
    "        0.02,\n",
    "        0.001,\n",
    "        0.002,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.006,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.004,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.04,\n",
    "        0.002,\n",
    "        0.008,\n",
    "        0.002,\n",
    "        0.004,\n",
    "        0.001,\n",
    "        0.004,\n",
    "        0.006,\n",
    "        0.004,\n",
    "    ]\n",
    "    df = df_train.copy()\n",
    "    del df_train\n",
    "    weights = {int(k): v for k, v in enumerate(weights)}\n",
    "    df[\"stock_weights\"] = df[\"stock_id\"].map(weights)\n",
    "\n",
    "    df[\"volume\"] = df.eval(\"ask_size + bid_size\")\n",
    "    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
    "    df[\"matched_imbalance\"] = df.eval(\n",
    "        \"(imbalance_size-matched_size)/(matched_size+imbalance_size)\"\n",
    "    )\n",
    "    df[\"size_imbalance\"] = df.eval(\"bid_size / ask_size\")\n",
    "\n",
    "    prices = [\n",
    "        \"reference_price\",\n",
    "        \"far_price\",\n",
    "        \"near_price\",\n",
    "        \"ask_price\",\n",
    "        \"bid_price\",\n",
    "        \"wap\",\n",
    "    ]\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\")\n",
    "\n",
    "    for c in [[\"ask_price\", \"bid_price\", \"wap\", \"reference_price\"], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n",
    "        df[triplet_feature.columns] = triplet_feature.values\n",
    "\n",
    "    df[\"weighted_wap\"] = df[\"stock_weights\"] * df[\"wap\"]\n",
    "    df[\"wap_momentum\"] = df.groupby(\"stock_id\")[\"weighted_wap\"].pct_change(periods=6)\n",
    "    df[\"imbalance_momentum\"] = (\n",
    "        df.groupby([\"stock_id\"])[\"imbalance_size\"].diff(periods=1) / df[\"matched_size\"]\n",
    "    )\n",
    "    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df[\"spread_intensity\"] = df.groupby([\"stock_id\"])[\"price_spread\"].diff()\n",
    "    df[\"market_urgency\"] = df[\"price_spread\"] * df[\"liquidity_imbalance\"]\n",
    "    df[\"depth_pressure\"] = (df[\"ask_size\"] - df[\"bid_size\"]) * (\n",
    "        df[\"far_price\"] - df[\"near_price\"]\n",
    "    )\n",
    "    df[\"spread_depth_ratio\"] = (df[\"ask_price\"] - df[\"bid_price\"]) / (\n",
    "        df[\"bid_size\"] + df[\"ask_size\"]\n",
    "    )\n",
    "\n",
    "    for func in [\"mean\", \"std\", \"skew\"]:\n",
    "        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n",
    "        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n",
    "\n",
    "    df = df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    df = pl.DataFrame(df)\n",
    "    df = df.sort([\"stock_id\", \"date_id\", \"seconds_in_bucket\"])\n",
    "\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"seconds_in_bucket\") / 10).cast(pl.Int32).alias(\"seconds_in_bucket\")\n",
    "    )\n",
    "\n",
    "    list_cols = list(df.columns)\n",
    "    list_cols_ma = [\n",
    "        col\n",
    "        for col in list_cols\n",
    "        if col\n",
    "        not in [\n",
    "            \"stock_id\",\n",
    "            \"date_id\",\n",
    "            \"seconds_in_bucket\",\n",
    "            \"imbalance_buy_sell_flag\",\n",
    "            \"reference_price\",\n",
    "            \"matched_size\",\n",
    "            \"far_price\",\n",
    "            \"near_price\",\n",
    "            \"bid_price\",\n",
    "            \"bid_size\",\n",
    "            \"ask_price\",\n",
    "            \"ask_size\",\n",
    "            \"wap\",\n",
    "            \"target\",\n",
    "            \"time_id\",\n",
    "            \"row_id\",\n",
    "            \"stock_weights\",\n",
    "            \"near_price_ask_price_imb\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    list_cols = [\n",
    "        \"all_prices_mean\",\n",
    "        \"all_prices_mean_mean_15\",\n",
    "        \"all_prices_mean_mean_3\",\n",
    "        \"all_prices_mean_mean_8\",\n",
    "        \"all_prices_mean_std_8\",\n",
    "        \"all_prices_skew_mean_10\",\n",
    "        \"all_prices_skew_mean_15\",\n",
    "        \"all_prices_skew_std_10\",\n",
    "        \"all_prices_skew_std_8\",\n",
    "        \"all_prices_std_std_8\",\n",
    "        \"all_sizes_mean_mean_15\",\n",
    "        \"all_sizes_mean_std_10\",\n",
    "        \"all_sizes_mean_std_15\",\n",
    "        \"all_sizes_std\",\n",
    "        \"all_sizes_std_std_15\",\n",
    "        \"ask_price_bid_price_imb_std_10\",\n",
    "        \"ask_price_bid_price_imb_std_15\",\n",
    "        \"ask_price_bid_price_reference_price_imb2\",\n",
    "        \"ask_price_bid_price_reference_price_imb2_std_10\",\n",
    "        \"ask_price_bid_price_reference_price_imb2_std_15\",\n",
    "        \"ask_price_bid_price_reference_price_imb2_std_8\",\n",
    "        \"ask_price_bid_price_wap_imb2\",\n",
    "        \"ask_price_wap_imb\",\n",
    "        \"ask_price_wap_imb_mean_8\",\n",
    "        \"ask_price_wap_imb_std_10\",\n",
    "        \"ask_price_wap_imb_std_8\",\n",
    "        \"ask_price_wap_reference_price_imb2\",\n",
    "        \"ask_price_wap_reference_price_imb2_mean_15\",\n",
    "        \"bid_price_wap_imb\",\n",
    "        \"bid_price_wap_imb_std_10\",\n",
    "        \"bid_price_wap_imb_std_8\",\n",
    "        \"bid_price_wap_reference_price_imb2\",\n",
    "        \"bid_price_wap_reference_price_imb2_std_15\",\n",
    "        \"bid_price_wap_reference_price_imb2_std_8\",\n",
    "        \"bid_size_ask_size_imbalance_size_imb2_mean_8\",\n",
    "        \"far_price_near_price_imb_mean_3\",\n",
    "        \"far_price_near_price_imb_std_8\",\n",
    "        \"imbalance_momentum_mean_10\",\n",
    "        \"imbalance_momentum_mean_15\",\n",
    "        \"imbalance_momentum_mean_8\",\n",
    "        \"imbalance_momentum_std_15\",\n",
    "        \"imbalance_size\",\n",
    "        \"imbalance_size_mean_15\",\n",
    "        \"imbalance_size_std_10\",\n",
    "        \"imbalance_size_std_8\",\n",
    "        \"market_urgency\",\n",
    "        \"market_urgency_mean_8\",\n",
    "        \"matched_size_ask_size_imbalance_size_imb2_std_15\",\n",
    "        \"matched_size_bid_size_ask_size_imb2\",\n",
    "        \"matched_size_bid_size_ask_size_imb2_std_10\",\n",
    "        \"matched_size_bid_size_imbalance_size_imb2_std_8\",\n",
    "        \"price_spread_std_15\",\n",
    "        \"reference_price_ask_price_imb\",\n",
    "        \"reference_price_ask_price_imb_mean_10\",\n",
    "        \"reference_price_ask_price_imb_mean_15\",\n",
    "        \"reference_price_ask_price_imb_std_15\",\n",
    "        \"reference_price_bid_price_imb\",\n",
    "        \"reference_price_bid_price_imb_mean_15\",\n",
    "        \"reference_price_bid_price_imb_std_8\",\n",
    "        \"reference_price_wap_imb\",\n",
    "        \"reference_price_wap_imb_mean_10\",\n",
    "        \"reference_price_wap_imb_mean_15\",\n",
    "        \"reference_price_wap_imb_mean_8\",\n",
    "        \"reference_price_wap_imb_std_8\",\n",
    "        \"seconds_in_bucket\",\n",
    "        \"size_imbalance\",\n",
    "        \"spread_depth_ratio\",\n",
    "        \"spread_depth_ratio_mean_15\",\n",
    "        \"spread_depth_ratio_std_10\",\n",
    "        \"spread_depth_ratio_std_15\",\n",
    "        \"spread_depth_ratio_std_8\",\n",
    "        \"spread_intensity_std_10\",\n",
    "        \"spread_intensity_std_15\",\n",
    "        \"volume_mean_15\",\n",
    "        \"wap_momentum\",\n",
    "        \"wap_momentum_mean_10\",\n",
    "        \"wap_momentum_mean_15\",\n",
    "        \"wap_momentum_mean_3\",\n",
    "        \"wap_momentum_mean_6\",\n",
    "        \"wap_momentum_mean_8\",\n",
    "        \"weighted_wap\",\n",
    "        \"weighted_wap_mean_15\",\n",
    "        \"weighted_wap_mean_3\",\n",
    "        \"weighted_wap_mean_8\",\n",
    "        \"weighted_wap_std_15\",\n",
    "    ]\n",
    "\n",
    "    def rolling_polars(df, list_cols, col_group_by, index_column):\n",
    "        for col in list_cols:\n",
    "            if TRAIN:\n",
    "                print(col)\n",
    "            function = col.split(\"_\")[-2]\n",
    "            if function in [\"mean\", \"std\"]:\n",
    "                base_col = \"_\".join(col.split(\"_\")[:-2])\n",
    "\n",
    "                window = col.split(\"_\")[-1]\n",
    "\n",
    "                rolling_group = df.group_by_rolling(\n",
    "                    index_column=index_column,\n",
    "                    period=f\"{window}i\",  # 'i' denotes index count (integer)\n",
    "                    by=col_group_by,\n",
    "                    closed=\"left\",  # Adjust as needed\n",
    "                )\n",
    "                if function == \"mean\":\n",
    "                    df = df.join(\n",
    "                        rolling_group.agg(\n",
    "                            pl.col(base_col).mean().alias(f\"{base_col}_mean_{window}\")\n",
    "                        ),\n",
    "                        on=[\"stock_id\", \"date_id\", \"seconds_in_bucket\"],\n",
    "                        how=\"left\",\n",
    "                    )\n",
    "                elif function == \"std\":\n",
    "                    df = df.join(\n",
    "                        rolling_group.agg(\n",
    "                            pl.col(base_col).std().alias(f\"{base_col}_std_{window}\")\n",
    "                        ),\n",
    "                        on=[\"stock_id\", \"date_id\", \"seconds_in_bucket\"],\n",
    "                        how=\"left\",\n",
    "                    )\n",
    "        return df\n",
    "\n",
    "    df = rolling_polars(df, list_cols, [\"stock_id\", \"date_id\"], \"seconds_in_bucket\")\n",
    "\n",
    "    df = df.to_pandas()\n",
    "\n",
    "    if TRAIN:\n",
    "        return df[list_cols + [\"date_id\", \"stock_id\", \"target\"]]\n",
    "    else:\n",
    "        return df[list_cols + [\"date_id\", \"stock_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b832ed26",
   "metadata": {
    "papermill": {
     "duration": 0.017966,
     "end_time": "2023-11-09T21:19:28.765084",
     "exception": false,
     "start_time": "2023-11-09T21:19:28.747118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e4de41",
   "metadata": {
    "_cell_guid": "5498ae4b-62e8-4050-91e7-075fc549380f",
    "_uuid": "ce9653b2-7dff-4c5b-af77-5f0ef88b6e86",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018932,
     "end_time": "2023-11-09T21:19:28.802440",
     "exception": false,
     "start_time": "2023-11-09T21:19:28.783508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c29c1",
   "metadata": {
    "_cell_guid": "92a8ed18-3a63-464e-9d62-17cea3baed59",
    "_uuid": "0b017968-3b5a-4465-820e-e89659b10afd",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018933,
     "end_time": "2023-11-09T21:19:28.839729",
     "exception": false,
     "start_time": "2023-11-09T21:19:28.820796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9e4dc",
   "metadata": {
    "_cell_guid": "f9d19e8d-0074-4ae2-adfb-4c039b700215",
    "_uuid": "b6096d27-d452-4593-9832-d15bfbd83e1b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018023,
     "end_time": "2023-11-09T21:19:28.876280",
     "exception": false,
     "start_time": "2023-11-09T21:19:28.858257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3267458",
   "metadata": {
    "_cell_guid": "855f8db3-e344-4d4d-b577-36499775f352",
    "_uuid": "fde5edb9-d23d-41ac-92c6-593f299230c2",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018403,
     "end_time": "2023-11-09T21:19:28.912894",
     "exception": false,
     "start_time": "2023-11-09T21:19:28.894491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ce43e",
   "metadata": {
    "_cell_guid": "82330d89-f35e-4cae-876c-de852438527d",
    "_uuid": "f90f329d-b882-464c-84fc-74a815cfe1cd",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018613,
     "end_time": "2023-11-09T21:19:28.950035",
     "exception": false,
     "start_time": "2023-11-09T21:19:28.931422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686d22c",
   "metadata": {
    "_cell_guid": "ed96eca6-9765-4c90-a6bf-3071518ba2f0",
    "_uuid": "ca1d48b9-5537-491b-9de2-57360edd9844",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018582,
     "end_time": "2023-11-09T21:19:28.989978",
     "exception": false,
     "start_time": "2023-11-09T21:19:28.971396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 182.456726,
   "end_time": "2023-11-09T21:19:30.439185",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-09T21:16:27.982459",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
