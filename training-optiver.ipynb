{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%time \n\n# General library imports:-\nfrom IPython.display import display_html, clear_output, Markdown;\nfrom gc import collect;\n\nfrom copy import deepcopy;\nimport pandas as pd;\nimport numpy as np;\nimport joblib;\nfrom os import system, getpid, walk;\nfrom psutil import Process;\nimport ctypes;\nlibc = ctypes.CDLL(\"libc.so.6\");\n\nfrom pprint import pprint;\nfrom colorama import Fore, Style, init;\nfrom warnings import filterwarnings;\nfilterwarnings('ignore');\n\nfrom tqdm.notebook import tqdm;\n\nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:03:44.511001Z","iopub.execute_input":"2023-10-19T19:03:44.511955Z","iopub.status.idle":"2023-10-19T19:03:45.168318Z","shell.execute_reply.started":"2023-10-19T19:03:44.511909Z","shell.execute_reply":"2023-10-19T19:03:45.167005Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\nCPU times: user 473 ms, sys: 64.1 ms, total: 537 ms\nWall time: 610 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time \n\n# Model development:-\nfrom sklearn.model_selection import (RepeatedStratifiedKFold as RSKF, \n                                     StratifiedKFold as SKF,\n                                     KFold, \n                                     RepeatedKFold as RKF, \n                                     cross_val_score);\n\nfrom lightgbm import log_evaluation, early_stopping, LGBMRegressor as LGBMR;\nfrom xgboost import XGBRegressor as XGBR;\nfrom catboost import CatBoostRegressor as CBR;\nfrom sklearn.ensemble import HistGradientBoostingRegressor as HGBR;\nfrom sklearn.metrics import mean_absolute_error as mae, make_scorer;\n\nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:03:51.071670Z","iopub.execute_input":"2023-10-19T19:03:51.072201Z","iopub.status.idle":"2023-10-19T19:03:53.931427Z","shell.execute_reply.started":"2023-10-19T19:03:51.072158Z","shell.execute_reply":"2023-10-19T19:03:53.930297Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\nCPU times: user 1.67 s, sys: 507 ms, total: 2.17 s\nWall time: 2.85 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\n# Defining global configurations and functions:-\n\n# Color printing    \ndef PrintColor(text:str, color = Fore.BLUE, style = Style.BRIGHT):\n    \"Prints color outputs using colorama using a text F-string\";\n    print(style + color + text + Style.RESET_ALL); \n    \ndef GetMemUsage():\n    \"\"\"\n    This function defines the memory usage across the kernel. \n    Source-\n    https://stackoverflow.com/questions/61366458/how-to-find-memory-usage-of-kaggle-notebook\n    \"\"\";\n    \n    pid = getpid();\n    py = Process(pid);\n    memory_use = py.memory_info()[0] / 2. ** 30;\n    return f\"RAM memory GB usage = {memory_use :.4}\";\n\n# Making sklearn pipeline outputs as dataframe:-\nfrom sklearn import set_config; \nset_config(transform_output = \"pandas\");\npd.set_option('display.max_columns', 50);\npd.set_option('display.max_rows', 50);\n\nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:04:59.733586Z","iopub.execute_input":"2023-10-19T19:04:59.733969Z","iopub.status.idle":"2023-10-19T19:04:59.849731Z","shell.execute_reply.started":"2023-10-19T19:04:59.733936Z","shell.execute_reply":"2023-10-19T19:04:59.848539Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\nCPU times: user 109 ms, sys: 186 Âµs, total: 109 ms\nWall time: 108 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time \n\n# Configuration class:-\nclass CFG:\n    \"\"\"\n    Configuration class for parameters and CV strategy for tuning and training\n    Please use caps lock capital letters while filling in parameters\n    \"\"\";\n    \n    # Data preparation:-   \n    version_nb         = 5;\n    test_req           = \"N\";\n    test_frac          = 0.01;\n    load_tr_data       = \"N\";\n    gpu_switch         = \"OFF\"; \n    state              = 42;\n    target             = 'target';\n    \n    path               = f\"/kaggle/input/optiver-memoryreduceddatasets/\";\n    test_path          = f\"/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv\";\n    df_choice          = f\"XTrIntCmpNewFtre.parquet\";\n    mdl_path           = f'/kaggle/working/BaselineML/';\n    inf_path           = f'/kaggle/input/optiverbaselinemodels/';\n     \n    # Model Training:-\n    methods            = [\"LGBMR\", \"CBR\", \"HGBR\"];\n    ML                 = \"N\";\n    n_splits           = 5;\n    n_repeats          = 1;\n    nbrnd_erly_stp     = 100 ;\n    mdlcv_mthd         = 'KF';\n    \n    # Ensemble:-    \n    ensemble_req       = \"N\";\n    enscv_mthd         = \"KF\";\n    metric_obj         = 'minimize';\n    ntrials            = 10 if test_req == \"Y\" else 200;\n    ens_weights        = [0.54, 0.44, 0.02];\n    \n    # Inference:-\n    inference_req      = \"Y\";\n    \n    # Global variables for plotting:-\n    grid_specs = {'visible': True, 'which': 'both', 'linestyle': '--', \n                  'color': 'lightgrey', 'linewidth': 0.75\n                 };\n    title_specs = {'fontsize': 9, 'fontweight': 'bold', 'color': 'tab:blue'};\n\nprint();\nPrintColor(f\"--> Configuration done!\\n\");\ncollect();\n\nPrintColor(f\"\\n\" + GetMemUsage(), color = Fore.RED);","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:06:35.424978Z","iopub.execute_input":"2023-10-19T19:06:35.425379Z","iopub.status.idle":"2023-10-19T19:06:35.540535Z","shell.execute_reply.started":"2023-10-19T19:06:35.425346Z","shell.execute_reply":"2023-10-19T19:06:35.539374Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\n\u001b[1m\u001b[34m--> Configuration done!\n\u001b[0m\n\u001b[1m\u001b[31m\nRAM memory GB usage = 0.2539\u001b[0m\nCPU times: user 106 ms, sys: 2.17 ms, total: 108 ms\nWall time: 106 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time \n\n# Commonly used CV strategies for later usage:-\nall_cv= {'KF'  : KFold(n_splits= CFG.n_splits, shuffle = True, random_state= CFG.state),\n         'RKF' : RKF(n_splits= CFG.n_splits, n_repeats = CFG.n_repeats, random_state= CFG.state),\n         'RSKF': RSKF(n_splits= CFG.n_splits, n_repeats = CFG.n_repeats, random_state= CFG.state),\n         'SKF' : SKF(n_splits= CFG.n_splits, shuffle = True, random_state= CFG.state)\n        };\n\n# Defining the competition metric:-\ndef ScoreMetric(ytrue, ypred)-> float:\n    return mae(ytrue, ypred);\n\n# Designing a custom scorer to use in cross_val_predict and cross_val_score:-\nmyscorer = make_scorer(ScoreMetric, greater_is_better = False, needs_proba=False,);\n\nprint();\ncollect();\n\nPrintColor(f\"\\n\" + GetMemUsage(), color = Fore.RED);","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:08:32.410912Z","iopub.execute_input":"2023-10-19T19:08:32.411318Z","iopub.status.idle":"2023-10-19T19:08:32.531580Z","shell.execute_reply.started":"2023-10-19T19:08:32.411270Z","shell.execute_reply":"2023-10-19T19:08:32.530136Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\n\u001b[1m\u001b[31m\nRAM memory GB usage = 0.2539\u001b[0m\nCPU times: user 112 ms, sys: 2.82 ms, total: 115 ms\nWall time: 113 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\ndef goto_conversion(listOfOdds, total = 1, eps = 1e-6, isAmericanOdds = False):\n    \"Source - https://www.kaggle.com/code/kaito510/goto-conversion-optiver-baseline-models\";\n\n    #Convert American Odds to Decimal Odds\n    if isAmericanOdds:\n        for i in range(len(listOfOdds)):\n            currOdds = listOfOdds[i];\n            isNegativeAmericanOdds = currOdds < 0;\n            if isNegativeAmericanOdds:\n                currDecimalOdds = 1 + (100/(currOdds*-1));\n            else: \n                #Is non-negative American Odds\n                currDecimalOdds = 1 + (currOdds/100);\n            listOfOdds[i] = currDecimalOdds;\n\n    #Error Catchers\n    if len(listOfOdds) < 2:\n        raise ValueError('len(listOfOdds) must be >= 2');\n    if any(x < 1 for x in listOfOdds):\n        raise ValueError('All odds must be >= 1, set isAmericanOdds parameter to True if using American Odds');\n\n    #Computation:-\n    #initialize probabilities using inverse odds\n    listOfProbabilities = [1/x for x in listOfOdds];\n    \n    #compute the standard error (SE) for each probability\n    listOfSe = [pow((x-x**2)/x,0.5) for x in listOfProbabilities];\n    \n    #compute how many steps of SE the probabilities should step back by\n    step = (sum(listOfProbabilities) - total)/sum(listOfSe) ;\n    outputListOfProbabilities = [min(max(x - (y*step),eps),1) for x,y in zip(listOfProbabilities, listOfSe)];\n    return outputListOfProbabilities;\n\ndef zero_sum(listOfPrices, listOfVolumes):\n    \"\"\"\n    Source - https://www.kaggle.com/code/kaito510/goto-conversion-optiver-baseline-models\n    \"\"\";\n    \n    #compute standard errors assuming standard deviation is same for all stocks\n    listOfSe = [x**0.5 for x in listOfVolumes];\n    step = sum(listOfPrices)/sum(listOfSe);\n    outputListOfPrices = [x - (y*step) for x,y in zip(listOfPrices, listOfSe)];\n    return outputListOfPrices;\n\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:08:52.783224Z","iopub.execute_input":"2023-10-19T19:08:52.783948Z","iopub.status.idle":"2023-10-19T19:08:52.923551Z","shell.execute_reply.started":"2023-10-19T19:08:52.783898Z","shell.execute_reply":"2023-10-19T19:08:52.922099Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"CPU times: user 129 ms, sys: 0 ns, total: 129 ms\nWall time: 128 ms\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #003380; border-bottom: 10px solid #80ffff\"> DATA PROCESSING<br><div> ","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style = \"font-family: Cambria Math;font-size: 115%; color: black; background-color: #e6f9ff; border: dashed black 1.0px; padding: 3.5px\" >\nIn this version, we choose the int-float compressed dataset with new features as per the reference notebook <br>\n</div>","metadata":{}},{"cell_type":"code","source":"root_path = '/kaggle/input/optiver-memoryreduceddatasets/'\nname_file = 'XTrIntCmpNewFtre.parquet'\n\n# testing\ndebug = True\ntesting_sample = 100","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:30:17.420870Z","iopub.execute_input":"2023-10-19T19:30:17.421505Z","iopub.status.idle":"2023-10-19T19:30:17.427426Z","shell.execute_reply.started":"2023-10-19T19:30:17.421468Z","shell.execute_reply":"2023-10-19T19:30:17.426105Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"if debug:\n    X = pd.read_parquet(root_path + name_file).sample(n = testing_sample)\nelse:\n    X = pd.read_parquet(root_path + name_file)\n    \ny = pd.read_parquet(CFG.path + f\"Ytrain.parquet\").loc[X.index].squeeze()\nX.index, y.index = range(len(X)), range(len(y))","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:30:17.641946Z","iopub.execute_input":"2023-10-19T19:30:17.642760Z","iopub.status.idle":"2023-10-19T19:30:21.018187Z","shell.execute_reply.started":"2023-10-19T19:30:17.642713Z","shell.execute_reply":"2023-10-19T19:30:21.016857Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"%%time \n\nif (CFG.load_tr_data == \"Y\" or CFG.ML == \"Y\") and CFG.test_req == \"Y\":\n    if isinstance(CFG.test_frac, float):\n        X = pd.read_parquet(CFG.path + CFG.df_choice).sample(frac = CFG.test_frac);\n    else:\n        X = pd.read_parquet(CFG.path + CFG.df_choice).sample(n = CFG.test_frac);\n        \n    y = pd.read_parquet(CFG.path + f\"Ytrain.parquet\").loc[X.index].squeeze();\n    PrintColor(f\"---> Sampled train shapes for code testing = {X.shape} {y.shape}\", \n               color = Fore.RED);\n    X.index, y.index = range(len(X)), range(len(y));\n    \n    PrintColor(f\"\\n---> Train set columns for model development\");\n    pprint(X.columns, width = 100, depth = 1, indent = 5);\n    print();\n\nelif CFG.load_tr_data == \"Y\" or CFG.ML == \"Y\":\n    X = pd.read_parquet(CFG.path + CFG.df_choice);\n    y = pd.read_parquet(CFG.path + f\"Ytrain.parquet\").squeeze();  \n    PrintColor(f\"---> Train shapes for code testing = {X.shape} {y.shape}\");\n\nelif CFG.load_tr_data != \"Y\" or CFG.inference_req == \"Y\":\n    PrintColor(f\"---> Train data is not required as we are infering from the model\");\n    \nprint();\ncollect();\nlibc.malloc_trim(0);\n\nPrintColor(f\"\\n\" + GetMemUsage(), color = Fore.RED);","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:09:36.002602Z","iopub.execute_input":"2023-10-19T19:09:36.002962Z","iopub.status.idle":"2023-10-19T19:09:36.132707Z","shell.execute_reply.started":"2023-10-19T19:09:36.002935Z","shell.execute_reply":"2023-10-19T19:09:36.131591Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\u001b[1m\u001b[34m---> Train data is not required as we are infering from the model\u001b[0m\n\n\u001b[1m\u001b[31m\nRAM memory GB usage = 0.2523\u001b[0m\nCPU times: user 122 ms, sys: 2.14 ms, total: 124 ms\nWall time: 120 ms\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #003380; border-bottom: 10px solid #80ffff\"> MODEL TRAINING AND CV<br><div> ","metadata":{}},{"cell_type":"code","source":"%%time \n\n# Initializing model I-O:-\n\nif CFG.ML == \"Y\":\n    Mdl_Master = \\\n    {'CBR': CBR(**{'task_type'           : \"GPU\" if CFG.gpu_switch == \"ON\" else \"CPU\",\n                   'objective'           : \"MAE\",\n                   'eval_metric'         : \"MAE\",\n                   'bagging_temperature' : 0.5,\n                   'colsample_bylevel'   : 0.7,\n                   'iterations'          : 500,\n                   'learning_rate'       : 0.065,\n                   'od_wait'             : 25,\n                   'max_depth'           : 7,\n                   'l2_leaf_reg'         : 1.5,\n                   'min_data_in_leaf'    : 1000,\n                   'random_strength'     : 0.65, \n                   'verbose'             : 0,\n                   'use_best_model'      : True,\n                  }\n               ), \n\n      'LGBMR': LGBMR(**{'device'            : \"gpu\" if CFG.gpu_switch == \"ON\" else \"cpu\",\n                        'objective'         : 'regression_l1',\n                        'boosting_type'     : 'gbdt',\n                        'random_state'      : CFG.state,\n                        'colsample_bytree'  : 0.7,\n                        'subsample'         : 0.65,\n                        'learning_rate'     : 0.065,\n                        'max_depth'         : 6,\n                        'n_estimators'      : 500,\n                        'num_leaves'        : 150,  \n                        'reg_alpha'         : 0.01,\n                        'reg_lambda'        : 3.25,\n                        'verbose'           : -1,\n                       }\n                    ),\n\n      'XGBR': XGBR(**{'tree_method'        : \"gpu_hist\" if CFG.gpu_switch == \"ON\" else \"hist\",\n                      'objective'          : 'reg:absoluteerror',\n                      'random_state'       : CFG.state,\n                      'colsample_bytree'   : 0.7,\n                      'learning_rate'      : 0.07,\n                      'max_depth'          : 6,\n                      'n_estimators'       : 500,                         \n                      'reg_alpha'          : 0.025,\n                      'reg_lambda'         : 1.75,\n                      'min_child_weight'   : 1000,\n                      'early_stopping_rounds' : CFG.nbrnd_erly_stp,\n                     }\n                  ),\n\n      \"HGBR\" : HGBR(loss              = 'squared_error',\n                    learning_rate     = 0.075,\n                    early_stopping    = True,\n                    max_iter          = 200,\n                    max_depth         = 6,\n                    min_samples_leaf  = 1500,\n                    l2_regularization = 1.75,\n                    scoring           = myscorer,\n                    random_state      = CFG.state,\n                   )\n    };\n\nprint();\ncollect();\n\nPrintColor(f\"\\n\" + GetMemUsage(), color = Fore.RED);\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T13:12:36.417806Z","iopub.execute_input":"2023-10-02T13:12:36.418225Z","iopub.status.idle":"2023-10-02T13:12:36.550278Z","shell.execute_reply.started":"2023-10-02T13:12:36.418198Z","shell.execute_reply":"2023-10-02T13:12:36.549037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\nif CFG.ML == \"Y\":\n    # Initializing the models from configuration class:-\n    methods = CFG.methods;\n\n    # Initializing a folder to store the trained and fitted models:-\n    system('mkdir BaselineML');\n\n    # Initializing the model path for storage:-\n    model_path = CFG.mdl_path;\n\n    # Initializing the cv object:-\n    cv = all_cv[CFG.mdlcv_mthd];\n        \n    # Initializing score dataframe:-\n    Scores = pd.DataFrame(index = range(CFG.n_splits * CFG.n_repeats),\n                          columns = methods).fillna(0).astype(np.float32);\n    \n    FtreImp = pd.DataFrame(index = X.columns, columns = [methods]).fillna(0);\n\nprint();\ncollect();\nlibc.malloc_trim(0);\n\nPrintColor(f\"\\n\" + GetMemUsage(), color = Fore.RED);","metadata":{"execution":{"iopub.status.busy":"2023-10-02T13:12:36.551612Z","iopub.execute_input":"2023-10-02T13:12:36.552037Z","iopub.status.idle":"2023-10-02T13:12:36.666797Z","shell.execute_reply.started":"2023-10-02T13:12:36.552008Z","shell.execute_reply":"2023-10-02T13:12:36.665562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\nif CFG.ML == \"Y\":\n    PrintColor(f\"\\n{'=' * 25} ML Training {'=' * 25}\\n\");\n    \n    # Initializing CV splitting:-       \n    for fold_nb, (train_idx, dev_idx) in tqdm(enumerate(cv.split(X, y)), \n                                              f\"{CFG.mdlcv_mthd} CV {CFG.n_splits}x{CFG.n_repeats}\"\n                                             ): \n        # Creating the cv folds:-    \n        Xtr  = X.iloc[train_idx];   \n        Xdev = X.iloc[dev_idx];\n        ytr  = y.iloc[train_idx];\n        ydev = y.iloc[dev_idx];\n        \n        PrintColor(f\"-------> Fold{fold_nb} <-------\");\n        # Fitting the models:- \n        for method in methods:\n            model = Mdl_Master[method];\n            if method == \"LGBMR\":\n                model.fit(Xtr, ytr, \n                          eval_set = [(Xdev, ydev)], \n                          verbose = 0, \n                          eval_metric = \"mae\",\n                          callbacks = [log_evaluation(0,), \n                                       early_stopping(CFG.nbrnd_erly_stp, verbose = False)], \n                         );\n\n            elif method == \"XGBR\":\n                model.fit(Xtr, ytr, \n                          eval_set = [(Xdev, ydev)], \n                          verbose = 0, \n                          eval_metric = \"mae\",\n                         );  \n\n            elif method == \"CBR\":\n                model.fit(Xtr, ytr, \n                          eval_set = [(Xdev, ydev)], \n                          verbose = 0, \n                          early_stopping_rounds = CFG.nbrnd_erly_stp,\n                         ); \n\n            else:\n                model.fit(Xtr, ytr);\n\n            #  Saving the model for later usage:-\n            joblib.dump(model, CFG.mdl_path + f'{method}V{CFG.version_nb}Fold{fold_nb}.model');\n            \n            # Creating OOF scores:-\n            score = ScoreMetric(ydev, model.predict(Xdev));\n            Scores.at[fold_nb, method] = score;\n            num_space = 6- len(method);\n            PrintColor(f\"---> {method} {' '* num_space} OOF = {score:.5f}\", \n                       color = Fore.MAGENTA);  \n            del num_space, score;\n            \n            # Collecting feature importances:-\n            try:\n                FtreImp[method] = \\\n                FtreImp[method].values + (model.feature_importances_ / (CFG.n_splits * CFG.n_repeats));\n            except:\n                pass;\n            \n            collect();\n            \n        PrintColor(GetMemUsage());\n        print();\n        del Xtr, ytr, Xdev, ydev;\n        collect();\n    \n    clear_output();\n    PrintColor(f\"\\n---> OOF scores across methods <---\\n\");\n    Scores.index.name = \"FoldNb\";\n    Scores.index = Scores.index + 1;\n    display(Scores.style.format(precision = 5).\\\n            background_gradient(cmap = \"Pastel1\")\n           );\n    \n    PrintColor(f\"\\n---> Mean OOF scores across methods <---\\n\");\n    display(Scores.mean());\n    \n    try: FtreImp.to_csv(CFG.mdl_path + f\"FtreImp_V{CFG.version_nb}.csv\");\n    except: pass;\n        \ncollect();\nprint();\nlibc.malloc_trim(0);\n\nPrintColor(f\"\\n\" + GetMemUsage(), color = Fore.GREEN);","metadata":{"execution":{"iopub.status.busy":"2023-10-02T13:12:36.668481Z","iopub.execute_input":"2023-10-02T13:12:36.668808Z","iopub.status.idle":"2023-10-02T13:12:36.795034Z","shell.execute_reply.started":"2023-10-02T13:12:36.668782Z","shell.execute_reply":"2023-10-02T13:12:36.793599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #003380; border-bottom: 10px solid #80ffff\"> MODEL INFERENCING AND SUBMISSION<br><div> ","metadata":{}},{"cell_type":"code","source":"%%time \n\ndef MakeFtre(df : pd.DataFrame, prices: list) -> pd.DataFrame:\n    \"\"\"\n    This function creates new features using the price columns. This was used in a baseline notebook as below-\n    https://www.kaggle.com/code/yuanzhezhou/baseline-lgb-xgb-and-catboost\n    \n    Inputs-\n    df:- pd.DataFrame -- input dataframe\n    cols:- price columns for transformation\n    \n    Returns-\n    df:- pd.DataFrame -- dataframe with extra columns\n    \"\"\";\n    \n    features = ['overall_medvol', \"first5min_medvol\", \"last5min_medvol\",\n                'seconds_in_bucket', 'imbalance_buy_sell_flag',\n                'imbalance_size', 'matched_size', 'bid_size', 'ask_size',\n                'reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap',\n                'imb_s1', 'imb_s2'\n               ];\n    \n    df['imb_s1'] = df.eval('(bid_size-ask_size)/(bid_size+ask_size)').astype(np.float32);\n    df['imb_s2'] = df.eval('(imbalance_size-matched_size)/(matched_size+imbalance_size)').astype(np.float32);\n       \n    for i,a in enumerate(prices):\n        for j,b in enumerate(prices):\n            if i>j:\n                df[f'{a}_{b}_imb'] = df.eval(f'({a}-{b})/({a}+{b})');\n                features.append(f'{a}_{b}_imb'); \n                    \n    for i,a in enumerate(prices):\n        for j,b in enumerate(prices):\n            for k,c in enumerate(prices):\n                if i>j and j>k:\n                    max_ = df[[a,b,c]].max(axis=1);\n                    min_ = df[[a,b,c]].min(axis=1);\n                    mid_ = df[[a,b,c]].sum(axis=1)-min_-max_;\n\n                    df[f'{a}_{b}_{c}_imb2'] = ((max_-mid_)/(mid_-min_)).astype(np.float32);\n                    features.append(f'{a}_{b}_{c}_imb2');\n    \n    return df[features];\n\nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-10-02T13:12:36.796662Z","iopub.execute_input":"2023-10-02T13:12:36.796961Z","iopub.status.idle":"2023-10-02T13:12:36.923383Z","shell.execute_reply.started":"2023-10-02T13:12:36.796937Z","shell.execute_reply":"2023-10-02T13:12:36.922188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\n# Creating the testing environment:-\nif CFG.inference_req == \"Y\":\n    try: \n        del X, y;\n    except: \n        pass;\n        \n    prices = ['reference_price', 'far_price', 'near_price', 'bid_price', 'ask_price', 'wap'];\n    \n    # Making the test environment for inferencing:-\n    import optiver2023;\n    try: \n        env = optiver2023.make_env();\n        iter_test = env.iter_test();\n        PrintColor(f\"\\n---> Curating the inference environment\");\n    except: \n        pass;\n    \n    # Collating a list of models to be used for inferencing:-\n    models = [];\n\n    # Loading the models for inferencing:-\n    if CFG.ML != \"Y\": \n        model_path = CFG.inf_path;\n        PrintColor(f\"---> Loading models from the input data for the kernel - V{CFG.version_nb}\\n\", \n                  color = Fore.RED);\n    elif CFG.ML == \"Y\": \n        model_path = CFG.mdl_path;\n        PrintColor(f\"---> Loading models from the working directory for the kernel\\n\");\n    \n    # Loading the models from the models dataframe:-\n    mdl_lbl = [];\n    for _, _, filename in walk(model_path):\n        mdl_lbl.extend(filename);\n\n    models = [];\n    for filename in mdl_lbl:\n        models.append(joblib.load(model_path + f\"{filename}\"));\n        \n    mdl_lbl    = [m.replace(r\".model\", \"\") for m in mdl_lbl];\n    model_dict = {l:m for l,m in zip(mdl_lbl, models)};\n    PrintColor(f\"\\n---> Trained models\\n\");    \n    pprint(np.array(mdl_lbl), width = 100, indent = 10, depth = 1);  \n       \nprint();\ncollect();  \nlibc.malloc_trim(0);\nPrintColor(f\"\\n\" + GetMemUsage(), color = Fore.RED); ","metadata":{"execution":{"iopub.status.busy":"2023-10-02T13:12:36.924549Z","iopub.execute_input":"2023-10-02T13:12:36.924871Z","iopub.status.idle":"2023-10-02T13:13:12.083691Z","shell.execute_reply.started":"2023-10-02T13:12:36.924844Z","shell.execute_reply":"2023-10-02T13:13:12.082541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\nif CFG.inference_req == \"Y\":\n    print();\n    counter = 0;\n    \n    try:\n        median_vol = pd.read_csv(CFG.path + f\"MedianVolV2.csv\", index_col = ['Unnamed: 0']);\n    except:\n        median_vol = pd.read_csv(CFG.path + f\"MedianVolV2.csv\"); \n    median_vol.index.name = \"stock_id\";\n    median_vol = median_vol[['overall_medvol', \"first5min_medvol\", \"last5min_medvol\"]];\n    \n    for test, revealed_targets, sample_prediction in iter_test:\n        if counter >= 99: num_space = 1;\n        elif counter >= 9: num_space = 2;\n        else: num_space = 3;\n        \n        PrintColor(f\"{counter + 1}. {' ' * num_space} Inference\", color = Fore.MAGENTA);\n        test  = test.merge(median_vol, how = \"left\", left_on = \"stock_id\", right_index = True);\n        Xtest = MakeFtre(test, prices = prices);\n        del num_space;\n        \n        # Curating model predictions across methods and folds:-        \n        preds = pd.DataFrame(columns = CFG.methods, index = Xtest.index).fillna(0);\n        for method in CFG.methods:\n            for mdl_lbl, mdl in model_dict.items():\n                if mdl_lbl.startswith(f\"{method}V{CFG.version_nb}\"):\n                    if CFG.test_req == \"Y\":\n                        print(mdl_lbl);\n                    else:\n                        pass;\n                    preds[method] = preds[method] + mdl.predict(Xtest)/ (CFG.n_splits * CFG.n_repeats);\n        \n        # Curating the weighted average model predictions:-       \n        sample_prediction['target'] = \\\n        np.average(preds.values, weights= CFG.ens_weights, axis=1);\n        \n        # Source - https://www.kaggle.com/code/kaito510/goto-conversion-optiver-baseline-models     \n        sample_prediction['target'] = \\\n        zero_sum(sample_prediction['target'], test.loc[:,'bid_size'] + test.loc[:,'ask_size'])\n        \n        try: \n            env.predict(sample_prediction);\n        except: \n            PrintColor(f\"---> Submission did not happen as we have the file already\");\n            pass;\n        \n        counter = counter+1;\n        collect();\n    \n    PrintColor(f\"\\n---> Submission file\\n\");\n    display(sample_prediction.head(10));\n            \nprint();\ncollect();  \nlibc.malloc_trim(0);\nPrintColor(f\"\\n\" + GetMemUsage(), color = Fore.RED); ","metadata":{"execution":{"iopub.status.busy":"2023-10-02T13:13:12.085257Z","iopub.execute_input":"2023-10-02T13:13:12.085577Z","iopub.status.idle":"2023-10-02T13:13:57.981311Z","shell.execute_reply.started":"2023-10-02T13:13:12.085552Z","shell.execute_reply":"2023-10-02T13:13:57.98017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #003380; border-bottom: 10px solid #80ffff\"> OUTRO<br><div> ","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style = \"font-family: Cambria Math;font-size: 115%; color: black; background-color: #e6f9ff; border: dashed black 1.0px; padding: 3.5px\" >\n<b>Next steps</b> <br>\n1. Exploring better models and ensemble strategy <br>\n2. Purging redundant features from the existing list of features <br>\n3. Fostering improvements in the existing process based on public discussions and kernels<br>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<b>References</b> <br>\n1. https://www.kaggle.com/code/yuanzhezhou/baseline-lgb-xgb-and-catboost <br>\n2. https://www.kaggle.com/code/renatoreggiani/optv-lightgbm -- Median volume column <br> \n3. https://www.kaggle.com/code/kaito510/goto-conversion-optiver-baseline-models -- goto conversion <br>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" align = \"center\" style = \"font-family: Calibri;font-size: 150%; color: black; background-color:#ccf2ff; border: solid black 2.5px; padding: 3.5px\" >\n    <b>If you find this useful, please upvote the kernel and the input kernel and dataset too. <br> Best regards!</b>\n</div>","metadata":{}}]}